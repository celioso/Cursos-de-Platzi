# Curso de Decision Trees y Random Forest con Python y scikit-learn

## ¬øQu√© son los √°rboles de decisi√≥n?

Los **√°rboles de decisi√≥n** son modelos de aprendizaje supervisado que se utilizan para resolver problemas de **clasificaci√≥n** y **regresi√≥n**. Su estructura se asemeja a un √°rbol, donde cada **nodo interno** representa una pregunta o condici√≥n sobre una caracter√≠stica (feature), cada **rama** representa el resultado de esa condici√≥n, y cada **hoja** representa una predicci√≥n final (una clase o un valor num√©rico).

### üîç ¬øC√≥mo funcionan?

1. **Divisi√≥n del conjunto de datos**:
   En cada nodo, el algoritmo selecciona la caracter√≠stica que mejor divide los datos seg√∫n alg√∫n criterio (como Gini, Entrop√≠a o MSE).

2. **Construcci√≥n del √°rbol**:
   El proceso se repite de forma recursiva dividiendo el conjunto en subconjuntos hasta que:

   * Todos los datos en un nodo pertenecen a la misma clase.
   * Se alcanza una profundidad m√°xima.
   * Otras condiciones de parada.

3. **Predicci√≥n**:
   Para predecir con un √°rbol, se sigue una ruta desde la ra√≠z hasta una hoja, tomando decisiones seg√∫n los valores de entrada.

### ‚ú≥Ô∏è Ventajas

* F√°cil de entender e interpretar.
* No requiere escalado de variables.
* Puede manejar datos tanto categ√≥ricos como num√©ricos.
* Permite visualizar c√≥mo se toman las decisiones.

### ‚ö†Ô∏è Desventajas

* Pueden **sobreajustarse** f√°cilmente si no se podan.
* Sensibles a peque√±as variaciones en los datos.
* No suelen ser tan precisos como modelos m√°s complejos (aunque se pueden combinar en **Random Forests** o **Gradient Boosting**).

### üîß Ejemplo en Python con Scikit-learn

```python
from sklearn.tree import DecisionTreeClassifier

modelo = DecisionTreeClassifier()
modelo.fit(X_train, y_train)
predicciones = modelo.predict(X_test)
```

**Archivos de la clase**

[decision-trees-random-forest-slides.pdf](https://static.platzi.com/media/public/uploads/decision-trees-random-forest-slides_a67df04d-0c2a-45ec-9ff0-68222424cc81.pdf)

## Tu primer √°rbol de decisi√≥n con scikit-learn

Aqu√≠ tienes un ejemplo completo de **tu primer √°rbol de decisi√≥n con Scikit-learn**, usando el cl√°sico conjunto de datos **Iris**. Es ideal para aprender porque tiene 4 caracter√≠sticas y 3 clases de flores.

### üå± Paso a paso: √Årbol de Decisi√≥n en Scikit-learn

### 1. üì¶ Importar librer√≠as necesarias

```python
from sklearn.datasets import load_iris
from sklearn.tree import DecisionTreeClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, accuracy_score
import matplotlib.pyplot as plt
from sklearn.tree import plot_tree
```

### 2. üå∏ Cargar dataset Iris

```python
iris = load_iris()
X = iris.data
y = iris.target
```

### 3. ‚úÇÔ∏è Dividir en entrenamiento y prueba

```python
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)
```

### 4. üå≥ Crear y entrenar el √°rbol

```python
modelo = DecisionTreeClassifier(random_state=42)
modelo.fit(X_train, y_train)
```

### 5. üîÆ Hacer predicciones

```python
y_pred = modelo.predict(X_test)
```

### 6. ‚úÖ Evaluar el modelo

```python
print("Accuracy:", accuracy_score(y_test, y_pred))
print("\nReporte de clasificaci√≥n:\n", classification_report(y_test, y_pred, target_names=iris.target_names))
```

### 7. üìà Visualizar el √°rbol de decisi√≥n

```python
plt.figure(figsize=(12, 8))
plot_tree(modelo, filled=True, feature_names=iris.feature_names, class_names=iris.target_names)
plt.show()
```

### üß† ¬øQu√© hace este √°rbol?

* Separa las flores (Setosa, Versicolor, Virginica) seg√∫n el largo y ancho del s√©palo y del p√©talo.
* En cada nodo, hace una pregunta como ‚Äú¬øpetal length (cm) <= 2.45?‚Äù para clasificar.

**Archivos de la clase**

[primer-arbol-decision-template.ipynb](https://static.platzi.com/media/public/uploads/primer_arbol_decision_template_84c03d57-915e-4533-852c-f596f47c81e8.ipynb)
[primer-arbol-decision-completed.ipynb](https://static.platzi.com/media/public/uploads/primer_arbol_decision_completed_c6330ed6-aa2e-4c32-b499-2480b6a5b78f.ipynb)

**Lecturas recomendadas**

[CS109](https://web.stanford.edu/class/archive/cs/cs109/cs109.1166/problem12.html)

[primer_arbol_decision_completed.ipynb - Google Drive](https://drive.google.com/file/d/1t8iSZcNn5Th9I7B_FrzrVXh-68jPwsol/view?usp=sharing)

[primer_arbol_decision_template.ipynb - Google Drive](https://drive.google.com/file/d/1wsxzoUcyLHCJ55YrFW5wMHqYhthWuckR/view?usp=sharing)

## An√°lisis de datos para tu primer √°rbol de decisi√≥n

Aqu√≠ tienes un an√°lisis b√°sico de los datos antes de construir tu primer √°rbol de decisi√≥n. Usaremos el dataset **Iris** como ejemplo, que es ideal para comenzar porque:

* Es peque√±o y limpio.
* Tiene 150 observaciones.
* Tiene 4 caracter√≠sticas num√©ricas.
* Su objetivo (target) es predecir el tipo de flor (Setosa, Versicolor o Virginica).

### üîç 1. Cargar y entender los datos

```python
from sklearn.datasets import load_iris
import pandas as pd

iris = load_iris()
X = pd.DataFrame(iris.data, columns=iris.feature_names)
y = pd.Series(iris.target, name='species')

X['species'] = y
X.head()
```

**Salida esperada (primeras filas):**

| sepal length (cm) | sepal width (cm) | petal length (cm) | petal width (cm) | species |
| ----------------- | ---------------- | ----------------- | ---------------- | ------- |
| 5.1               | 3.5              | 1.4               | 0.2              | 0       |
| 4.9               | 3.0              | 1.4               | 0.2              | 0       |
| ...               | ...              | ...               | ...              | ...     |

* `species`: 0 = Setosa, 1 = Versicolor, 2 = Virginica

### üìä 2. Estad√≠sticas descriptivas

```python
X.describe()
```

Esto te dar√° un resumen de los valores m√≠nimos, m√°ximos, medias, etc. Sirve para:

* Ver si hay valores extremos (outliers).
* Ver si las escalas son muy distintas.
* Observar la distribuci√≥n de cada variable.

### üìà 3. Distribuci√≥n de clases

```python
import matplotlib.pyplot as plt
import seaborn as sns

sns.countplot(x='species', data=X)
plt.title('Distribuci√≥n de clases')
plt.xticks([0, 1, 2], iris.target_names)
plt.show()
```

### üîó 4. Correlaciones

```python
sns.heatmap(X.drop('species', axis=1).corr(), annot=True, cmap='coolwarm')
plt.title('Matriz de correlaci√≥n')
plt.show()
```

Esto ayuda a ver qu√© caracter√≠sticas est√°n m√°s relacionadas entre s√≠.

### üß† 5. Observaciones clave

* **Setosa** es f√°cil de separar por su p√©talo corto y delgado.
* Las clases **Versicolor** y **Virginica** son m√°s parecidas.
* Las caracter√≠sticas m√°s importantes suelen ser el **largo y ancho del p√©talo**.

**Archivos de la clase**

[primer-arbol-decision-template.ipynb](https://static.platzi.com/media/public/uploads/primer_arbol_decision_template_84c03d57-915e-4533-852c-f596f47c81e8.ipynb)
[primer-arbol-decision-completed.ipynb](https://static.platzi.com/media/public/uploads/primer_arbol_decision_completed_c6330ed6-aa2e-4c32-b499-2480b6a5b78f.ipynb)

**Lecturas recomendadas**

[CS109](https://web.stanford.edu/class/archive/cs/cs109/cs109.1166/problem12.html)

[Curso de An√°lisis Exploratorio de Datos - Platzi](https://platzi.com/cursos/analisis-exploratorio-datos/)

[primer_arbol_decision_completed.ipynb - Google Drive](https://drive.google.com/file/d/1t8iSZcNn5Th9I7B_FrzrVXh-68jPwsol/view?usp=sharing)

[primer_arbol_decision_template.ipynb - Google Drive](https://drive.google.com/file/d/1wsxzoUcyLHCJ55YrFW5wMHqYhthWuckR/view?usp=sharing)

## Entrenamiento y evaluaci√≥n de √°rbol de decisi√≥n con scikit-learn

Aqu√≠ tienes un ejemplo **completo** y **explicado paso a paso** de c√≥mo entrenar y evaluar un **√°rbol de decisi√≥n** usando `scikit-learn` con el dataset del **Titanic**:

### üß™ 1. Cargar y preparar los datos

```python
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix

# Cargar el dataset (puede ser desde seaborn, kaggle o archivo local)
titanic = pd.read_csv('titanic.csv')  # o usa seaborn.load_dataset('titanic')

# Selecci√≥n de variables
features = ['Pclass', 'Sex', 'Age', 'Fare']
target = 'Survived'

# Eliminar nulos simples (s√≥lo para simplificar el ejemplo)
titanic = titanic.dropna(subset=features + [target])

# Convertir variables categ√≥ricas a num√©ricas
titanic = pd.get_dummies(titanic, columns=['Sex'], drop_first=True, dtype=int)

# Variables predictoras y variable objetivo
X = titanic[['Pclass', 'Age', 'Fare', 'Sex_male']]
y = titanic[target]
```

### üß† 2. Dividir en conjunto de entrenamiento y prueba

```python
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)
```

### üå≤ 3. Entrenar el √°rbol de decisi√≥n

```python
model = DecisionTreeClassifier(random_state=42)
model.fit(X_train, y_train)
```

### üìä 4. Evaluaci√≥n del modelo

```python
# Predicciones
y_pred = model.predict(X_test)

# M√©tricas
print("Accuracy:", accuracy_score(y_test, y_pred))
print("\nClassification Report:\n", classification_report(y_test, y_pred))
print("\nConfusion Matrix:\n", confusion_matrix(y_test, y_pred))
```

### üå≥ 5. (Opcional) Visualizar el √°rbol

```python
from sklearn.tree import plot_tree
import matplotlib.pyplot as plt

plt.figure(figsize=(20, 10))
plot_tree(model, feature_names=X.columns, class_names=['No', 'Yes'], filled=True)
plt.show()
```

### ‚úÖ Resultado

Con esto obtendr√°s:

* Un modelo de √°rbol de decisi√≥n entrenado.
* M√©tricas de precisi√≥n (`accuracy`, `precision`, `recall`, `f1-score`).
* Visualizaci√≥n clara de c√≥mo el √°rbol toma decisiones.

## ¬øC√≥mo funcionan los √°rboles de decisi√≥n?

Los **√°rboles de decisi√≥n** son algoritmos de aprendizaje supervisado que se utilizan para **clasificaci√≥n** o **regresi√≥n**. Funcionan dividiendo los datos en ramas basadas en preguntas simples sobre las caracter√≠sticas (features), hasta llegar a una predicci√≥n.

### üå≥ ¬øC√≥mo funciona un √°rbol de decisi√≥n?

1. **Inicio (nodo ra√≠z)**:
   El √°rbol comienza con todos los datos en un nodo inicial.

2. **Divisi√≥n (nodos internos)**:
   Se elige la **caracter√≠stica (feature)** que mejor separa los datos seg√∫n un criterio (por ejemplo, **entrop√≠a**, **√≠ndice Gini** o **reducci√≥n de varianza**).

3. **Ramas**:
   Se crean ramas seg√∫n los valores de esa caracter√≠stica. Cada rama lleva a un subconjunto del dataset.

4. **Repetici√≥n**:
   Este proceso se repite recursivamente en cada subconjunto, formando un √°rbol.

5. **Fin (hojas)**:
   Cuando no se puede dividir m√°s (por ejemplo, los datos est√°n completamente separados o se llega a un l√≠mite de profundidad), se hace una predicci√≥n basada en la mayor√≠a de clase (clasificaci√≥n) o en el promedio (regresi√≥n).

### üß† Ejemplo simple (Clasificaci√≥n):

**¬øSobrevivi√≥ una persona en el Titanic?**
Variables:

* Edad
* Sexo
* Clase del boleto

El √°rbol podr√≠a hacer:

* **¬øSex\_female == 1?**

  * S√≠ ‚Üí ¬øPclass <= 2?

    * S√≠ ‚Üí Probabilidad alta de sobrevivir
    * No ‚Üí Probabilidad media
  * No ‚Üí ¬øAge <= 10?

    * S√≠ ‚Üí Probabilidad media
    * No ‚Üí Probabilidad baja

### ‚öôÔ∏è Criterios de divisi√≥n comunes:

* **Gini** (por defecto en `sklearn`): mide impureza
* **Entrop√≠a**: mide la cantidad de informaci√≥n necesaria para clasificar
* **MSE** (para regresi√≥n): error cuadr√°tico medio

### ‚úÖ Ventajas:

* F√°cil de entender e interpretar
* No requiere normalizaci√≥n de datos
* Puede trabajar con variables categ√≥ricas y num√©ricas

### ‚ùå Desventajas:

* Puede sobreajustar (overfitting) si no se poda o se limita la profundidad
* Poca estabilidad: cambios peque√±os en los datos pueden cambiar mucho el √°rbol

## ¬øCu√°ndo usar √°rboles de decisi√≥n?

Debes considerar usar **√°rboles de decisi√≥n** cuando:

### ‚úÖ **1. Quieres interpretabilidad**

* Los √°rboles son **f√°ciles de visualizar y entender**. Puedes explicar decisiones con reglas simples del tipo ‚Äúsi... entonces...‚Äù.
* Ideal cuando necesitas **explicar el modelo a personas no t√©cnicas**.

### ‚úÖ **2. Tus datos incluyen variables categ√≥ricas y num√©ricas**

* Los √°rboles manejan bien **ambos tipos** sin necesidad de normalizaci√≥n ni transformaci√≥n compleja.

### ‚úÖ **3. Tienes relaciones no lineales**

* A diferencia de la regresi√≥n lineal, los √°rboles **capturan interacciones y no linealidades** entre variables autom√°ticamente.

### ‚úÖ **4. Quieres saber qu√© variables son m√°s importantes**

* El modelo calcula autom√°ticamente **importancia de caracter√≠sticas**, lo cual es √∫til para **selecci√≥n de variables** o interpretaci√≥n.

### ‚úÖ **5. Los datos tienen valores faltantes o est√°n mal escalados**

* Los √°rboles son **resistentes** a valores faltantes (algunos algoritmos los manejan bien) y **no necesitan normalizaci√≥n**.

### ‚úÖ **6. Tu problema es de clasificaci√≥n o regresi√≥n**

* Puedes usar √°rboles para:

  * **Clasificaci√≥n** (ej. detecci√≥n de spam, predicci√≥n de enfermedad)
  * **Regresi√≥n** (ej. predicci√≥n de precios, demanda, consumo)

### ‚ùå **¬øCu√°ndo evitar √°rboles de decisi√≥n?**

* Cuando necesitas **alt√≠sima precisi√≥n**: suelen tener peor desempe√±o que m√©todos como Random Forest o XGBoost.
* Cuando el dataset es **muy peque√±o y complejo**: puede sobreajustar.
* Cuando necesitas **predicciones muy estables**: los √°rboles simples pueden variar bastante ante peque√±os cambios en los datos.

### üìå En resumen:

Usa √°rboles de decisi√≥n cuando necesitas un modelo **r√°pido, interpretable y vers√°til**, especialmente en las primeras etapas del an√°lisis o cuando el entendimiento del modelo es prioritario.

**Lecturas recomendadas**

[√Årbol de decisi√≥n en valoraci√≥n de inversiones | 2023 | Economipedia](https://economipedia.com/definiciones/arbol-de-decision-en-valoracion-de-inversiones.html)

## Conociendo problema a resolver y dataset de clasificaci√≥n

Para **resolver un problema de clasificaci√≥n** con **machine learning**, como identificar el tipo de autom√≥vil (por ejemplo: **f√≥sil**, **el√©ctrico** o **h√≠brido**), necesitas tener claro dos cosas fundamentales:

### ‚úÖ 1. **Conocer el problema a resolver**

Esto implica entender:

* Qu√© **queremos predecir** ‚Üí En este caso, el **tipo de autom√≥vil**.
* Qu√© **tipo de problema es** ‚Üí Es un **problema de clasificaci√≥n multiclase**.
* Qu√© datos tenemos disponibles para predecir ‚Üí Variables como peso, potencia, tipo de motor, consumo, emisiones, etc.

### ‚úÖ 2. **Conocer y preparar el dataset**

Esto incluye:

#### a. **Variable objetivo (target)**

Es la que vamos a predecir, en este caso:

```python
'y_tipo'  ‚Üí ['f√≥sil', 'el√©ctrico', 'h√≠brido']
```

Esta variable debe ser **convertida a valores num√©ricos**, por ejemplo usando `LabelEncoder`:

```python
from sklearn.preprocessing import LabelEncoder

le = LabelEncoder()
df['tipo_auto'] = le.fit_transform(df['tipo_auto'])
```

Esto puede traducir:

* f√≥sil ‚Üí 0
* el√©ctrico ‚Üí 1
* h√≠brido ‚Üí 2

#### b. **Variables predictoras (features)**

Estas son las columnas que usar√° el modelo para aprender. Por ejemplo:

```python
X = df[['peso', 'potencia', 'consumo', 'emisiones']]
y = df['tipo_auto']  # variable objetivo codificada
```

### ‚úÖ 3. **Divisi√≥n del dataset**

Siempre se divide el dataset en datos de entrenamiento y prueba:

```python
from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
```

### ‚úÖ 4. **Entrenamiento del modelo**

Por ejemplo, con un √°rbol de decisi√≥n:

```python
from sklearn.tree import DecisionTreeClassifier

modelo = DecisionTreeClassifier()
modelo.fit(X_train, y_train)
```

### ‚úÖ 5. **Evaluaci√≥n**

Evaluamos qu√© tan bien predice:

```python
from sklearn.metrics import accuracy_score

y_pred = modelo.predict(X_test)
print("Precisi√≥n:", accuracy_score(y_test, y_pred))
```

**Archivos de la clase**

[decision-tree-random-forest-project-template.ipynb](https://static.platzi.com/media/public/uploads/decision_tree_random_forest_project_template_fd59d141-d477-4f10-b39e-8127e0fbccb8.ipynb)
[decision-tree-random-forest-project-completed.ipynb](https://static.platzi.com/media/public/uploads/decision_tree_random_forest_project_completed_ede3a4ea-5f79-4ed7-9fbc-bdfd3b16b017.ipynb)

**Lecturas recomendadas**

[Car Evaluation Data Set | Kaggle](https://www.kaggle.com/datasets/elikplim/car-evaluation-data-set)

[decision_tree_random_forest_project_completed.ipynb - Google Drive](https://drive.google.com/file/d/1Ck8R2GXK_ZeW9oYRIdXgVhBqi3ibt_QJ/view?usp=sharing)

[decision_tree_random_forest_project_template.ipynb - Google Drive](https://drive.google.com/file/d/1PFP6e4YfAI8nXq31kzRC8NquONJqLqeK/view?usp=sharing)

## An√°lisis exploratorio de datos para √°rbol de decisi√≥n

El **an√°lisis exploratorio de datos (EDA)** es un paso clave antes de aplicar un algoritmo como un **√°rbol de decisi√≥n**, ya que te permite:

* Entender la estructura y calidad del dataset.
* Detectar valores faltantes o at√≠picos.
* Visualizar relaciones entre variables.
* Evaluar qu√© variables podr√≠an ser importantes para la predicci√≥n.

### ‚úÖ Pasos del An√°lisis Exploratorio de Datos (EDA) para √Årbol de Decisi√≥n

### 1. **Cargar los datos y revisar estructura**

```python
import pandas as pd

df = pd.read_csv('autos.csv')  # ejemplo
print(df.head())
print(df.info())
print(df.describe())
```

### 2. **Identificar la variable objetivo (target)**

Verifica si es una variable **categ√≥rica** (clasificaci√≥n) o **num√©rica** (regresi√≥n).

```python
print(df['tipo_auto'].value_counts())
```

Ejemplo de categor√≠as: `['f√≥sil', 'el√©ctrico', 'h√≠brido']`

### 3. **Visualizar la distribuci√≥n de la variable target**

```python
import seaborn as sns
import matplotlib.pyplot as plt

sns.countplot(x='tipo_auto', data=df)
plt.title('Distribuci√≥n del tipo de autom√≥vil')
plt.show()
```

### 4. **Revisar valores nulos**

```python
print(df.isnull().sum())
```

Soluciones:

* Imputar valores nulos (media, moda, etc.)
* Eliminar columnas o filas con muchos nulos

### 5. **Revisar correlaciones entre variables num√©ricas**

Aunque los √°rboles no necesitan variables escaladas ni normalizadas, es √∫til conocer la relaci√≥n entre variables.

```python
sns.heatmap(df.corr(), annot=True, cmap='coolwarm')
```

### 6. **Codificar variables categ√≥ricas**

Los √°rboles pueden trabajar con etiquetas num√©ricas, as√≠ que debes convertir las categor√≠as:

```python
from sklearn.preprocessing import LabelEncoder

le = LabelEncoder()
df['tipo_auto'] = le.fit_transform(df['tipo_auto'])
```

Aplica lo mismo a otras columnas categ√≥ricas si es necesario.

### 7. **Detectar outliers**

Puedes usar diagramas de caja (boxplots):

```python
sns.boxplot(x=df['potencia'])
plt.title('Potencia - detecci√≥n de outliers')
plt.show()
```

### 8. **An√°lisis bivariado**

Estudia c√≥mo se relacionan las variables predictoras con la variable objetivo:

```python
sns.boxplot(x='tipo_auto', y='consumo', data=df)
```

### 9. **Feature importance (opcional luego del modelo)**

Los √°rboles te permiten saber qu√© variables son m√°s importantes despu√©s del entrenamiento:

```python
from sklearn.tree import DecisionTreeClassifier

X = df.drop('tipo_auto', axis=1)
y = df['tipo_auto']

modelo = DecisionTreeClassifier()
modelo.fit(X, y)

importances = modelo.feature_importances_
for col, imp in zip(X.columns, importances):
    print(f"{col}: {imp:.3f}")
```

## Procesamiento de datos para el entrenamiento de √°rbol de decisi√≥n

El **procesamiento de datos** para entrenar un **√°rbol de decisi√≥n** implica preparar tu dataset de forma que el algoritmo pueda aprender patrones de manera efectiva. Aunque los √°rboles de decisi√≥n son muy flexibles (no requieren escalado de variables, por ejemplo), **s√≠ necesitan ciertos pasos clave** para funcionar correctamente.

### ‚úÖ Pasos de Procesamiento de Datos para √Årbol de Decisi√≥n (Clasificaci√≥n o Regresi√≥n)

### 1. **Separar variables predictoras y objetivo**

```python
X = df.drop('target', axis=1)  # variables predictoras
y = df['target']               # variable objetivo
```

### 2. **Codificar variables categ√≥ricas**

Los √°rboles requieren valores num√©ricos.

**Opci√≥n A: Label Encoding (√∫til si hay orden impl√≠cito o pocas categor√≠as)**

```python
from sklearn.preprocessing import LabelEncoder

le = LabelEncoder()
X['transmision'] = le.fit_transform(X['transmision'])
```

**Opci√≥n B: One-Hot Encoding (√∫til para categor√≠as sin orden)**

```python
X = pd.get_dummies(X, columns=['marca', 'modelo'])
```

### 3. **Manejo de valores nulos**

Los √°rboles no manejan valores faltantes por s√≠ solos.

```python
X = X.fillna(X.median())  # o usar X.dropna() si es apropiado
```

### 4. **Divisi√≥n de datos en entrenamiento y prueba**

```python
from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)
```

### 5. **(Opcional) Balancear clases si es clasificaci√≥n**

Si tienes un problema de clasificaci√≥n desbalanceada:

```python
from sklearn.utils import resample

# Combinar X e y
df_train = pd.concat([X_train, y_train], axis=1)
minority = df_train[df_train['target'] == 'clase_rara']
majority = df_train[df_train['target'] == 'clase_com√∫n']

minority_upsampled = resample(minority,
                              replace=True,
                              n_samples=len(majority),
                              random_state=42)

df_balanced = pd.concat([majority, minority_upsampled])
X_train = df_balanced.drop('target', axis=1)
y_train = df_balanced['target']
```

### 6. **Entrenamiento del √°rbol**

```python
from sklearn.tree import DecisionTreeClassifier

clf = DecisionTreeClassifier(max_depth=5, random_state=42)
clf.fit(X_train, y_train)
```

### 7. **Evaluaci√≥n**

```python
from sklearn.metrics import classification_report

y_pred = clf.predict(X_test)
print(classification_report(y_test, y_pred))
```

### 8. **(Opcional) Visualizar el √°rbol**

```python
from sklearn.tree import plot_tree
import matplotlib.pyplot as plt

plt.figure(figsize=(16, 8))
plot_tree(clf, feature_names=X.columns, class_names=clf.classes_, filled=True)
plt.show()
```

## Entrenamiento de modelo de clasificaci√≥n con √°rbol de decisi√≥n

Aqu√≠ tienes un ejemplo completo y claro de **entrenamiento de un modelo de clasificaci√≥n con √°rbol de decisi√≥n**, usando Python y `scikit-learn`.

### ‚úÖ **Ejemplo paso a paso: Clasificaci√≥n con √Årbol de Decisi√≥n**

Usaremos el dataset `Iris` como ejemplo.

#### **1. Importar librer√≠as**

```python
from sklearn.datasets import load_iris
from sklearn.tree import DecisionTreeClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, accuracy_score
```

#### **2. Cargar datos**

```python
iris = load_iris()
X = iris.data                  # variables predictoras
y = iris.target                # variable objetivo (0, 1, 2)
```

#### **3. Dividir en entrenamiento y prueba**

```python
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)
```

#### **4. Entrenar el √°rbol de decisi√≥n**

```python
clf = DecisionTreeClassifier(criterion='gini', max_depth=3, random_state=42)
clf.fit(X_train, y_train)
```

#### **5. Predecir y evaluar**

```python
y_pred = clf.predict(X_test)

print("Accuracy:", accuracy_score(y_test, y_pred))
print("\nReporte de clasificaci√≥n:\n", classification_report(y_test, y_pred))
```

#### **6. (Opcional) Visualizar el √°rbol**

```python
import matplotlib.pyplot as plt
from sklearn.tree import plot_tree

plt.figure(figsize=(12, 6))
plot_tree(clf, feature_names=iris.feature_names, class_names=iris.target_names, filled=True)
plt.show()
```

### üîç ¬øQu√© puedes modificar?

* Cambia `max_depth`, `criterion`, `min_samples_split`, etc. para ver c√≥mo afecta al rendimiento.
* Usa tus propios datos (`pd.read_csv(...)`) y reemplaza `X` e `y`.

**Lecturas recomendadas**

[1.10. Decision Trees ‚Äî scikit-learn 1.2.1 documentation](https://scikit-learn.org/stable/modules/tree.html)

[sklearn.tree.DecisionTreeClassifier ‚Äî scikit-learn 1.2.1 documentation](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html)

[decision_tree_random_forest_project_completed.ipynb - Google Drive](https://drive.google.com/file/d/1Ck8R2GXK_ZeW9oYRIdXgVhBqi3ibt_QJ/view?usp=sharing)

[decision_tree_random_forest_project_template.ipynb - Google Drive](https://drive.google.com/file/d/1PFP6e4YfAI8nXq31kzRC8NquONJqLqeK/view?usp=sharing)

## ¬øC√≥mo evaluar un modelo de √°rbol de decisi√≥n?

Evaluar un modelo de **√°rbol de decisi√≥n** implica analizar qu√© tan bien predice sobre datos nuevos. Aqu√≠ tienes los pasos m√°s importantes para hacerlo:

### ‚úÖ **1. Dividir los datos**

Antes de entrenar, debes separar tu dataset:

```python
from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
```

### ‚úÖ **2. Entrenar el modelo**

```python
from sklearn.tree import DecisionTreeClassifier

modelo = DecisionTreeClassifier(random_state=42)
modelo.fit(X_train, y_train)
```

### ‚úÖ **3. Realizar predicciones**

```python
y_pred = modelo.predict(X_test)
```

### ‚úÖ **4. Evaluar el rendimiento**

Usa m√©tricas de clasificaci√≥n:

```python
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix

print("Accuracy:", accuracy_score(y_test, y_pred))
print("\nMatriz de confusi√≥n:\n", confusion_matrix(y_test, y_pred))
print("\nReporte de clasificaci√≥n:\n", classification_report(y_test, y_pred))
```

### üîç ¬øQu√© significan estas m√©tricas?

| M√©trica                   | Significado                                              |
| ------------------------- | -------------------------------------------------------- |
| **Accuracy**              | Porcentaje de predicciones correctas                     |
| **Precisi√≥n (precision)** | Qu√© tan precisas son las predicciones positivas          |
| **Recall (sensibilidad)** | Qu√© tanto recupera el modelo de las clases verdaderas    |
| **F1-score**              | Balance entre precisi√≥n y recall                         |
| **Confusion Matrix**      | Muestra predicciones correctas vs. incorrectas por clase |

### ‚úÖ **5. Importancia de variables (opcional)**

Para saber qu√© variables son m√°s √∫tiles:

```python
import pandas as pd

importancia = modelo.feature_importances_
print(pd.DataFrame({'Feature': feature_names, 'Importancia': importancia}))
```

### ‚úÖ **6. Validaci√≥n cruzada (opcional)**

Para tener una mejor idea del rendimiento general:

```python
from sklearn.model_selection import cross_val_score

scores = cross_val_score(modelo, X, y, cv=5)
print("Accuracy promedio:", scores.mean())
```

## Evaluaci√≥n de resultados del modelo de √°rbol de decisi√≥n

La **evaluaci√≥n de resultados** de un modelo de √°rbol de decisi√≥n se realiza para determinar qu√© tan bien generaliza a nuevos datos. A continuaci√≥n te explico las principales herramientas y c√≥mo interpretarlas:

### ‚úÖ 1. **Predicci√≥n del modelo**

Despu√©s de entrenar el modelo:

```python
y_pred = modelo.predict(X_test)
```

### ‚úÖ 2. **M√©tricas comunes de evaluaci√≥n**

### üìä a) **Accuracy (exactitud)**

Mide el porcentaje de predicciones correctas.

```python
from sklearn.metrics import accuracy_score
print("Accuracy:", accuracy_score(y_test, y_pred))
```

> üß† √ötil si las clases est√°n balanceadas. No confiable si una clase domina.

### üìâ b) **Matriz de confusi√≥n**

Muestra cu√°ntas predicciones fueron correctas o incorrectas por clase.

```python
from sklearn.metrics import confusion_matrix
print(confusion_matrix(y_test, y_pred))
```

> üìå Cada fila representa la clase real, cada columna la clase predicha.

### üìÑ c) **Reporte de clasificaci√≥n**

Incluye precisi√≥n, recall y F1-score por clase:

```python
from sklearn.metrics import classification_report
print(classification_report(y_test, y_pred))
```

* **Precision:** % de predicciones positivas correctas.
* **Recall (sensibilidad):** % de positivos reales bien clasificados.
* **F1-score:** Promedio arm√≥nico de precisi√≥n y recall.

### üìà d) **Curva ROC y AUC (para clasificaci√≥n binaria)**

Mide rendimiento del modelo en distintas probabilidades de corte.

```python
from sklearn.metrics import roc_curve, roc_auc_score

y_proba = modelo.predict_proba(X_test)[:, 1]  # Probabilidad clase positiva
fpr, tpr, _ = roc_curve(y_test, y_proba)
auc = roc_auc_score(y_test, y_proba)
print("AUC:", auc)
```

> ‚ö†Ô∏è Solo aplicable para problemas binarios (2 clases).

### ‚úÖ 3. **Evaluaci√≥n con validaci√≥n cruzada (opcional)**

```python
from sklearn.model_selection import cross_val_score

scores = cross_val_score(modelo, X, y, cv=5)
print("Accuracy promedio:", scores.mean())
```

### ‚úÖ 4. **Importancia de caracter√≠sticas**

Permite interpretar qu√© variables influyeron m√°s:

```python
import pandas as pd

pd.DataFrame({
    'Caracter√≠stica': feature_names,
    'Importancia': modelo.feature_importances_
}).sort_values(by='Importancia', ascending=False)
```

**Lecturas recomendadas**

[sklearn.metrics.accuracy_score ‚Äî scikit-learn 1.2.1 documentation](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html)

[decision_tree_random_forest_project_completed.ipynb - Google Drive](https://drive.google.com/file/d/1Ck8R2GXK_ZeW9oYRIdXgVhBqi3ibt_QJ/view?usp=sharing)

[decision_tree_random_forest_project_template.ipynb - Google Drive](https://drive.google.com/file/d/1PFP6e4YfAI8nXq31kzRC8NquONJqLqeK/view?usp=sharing)

## ¬øQu√© son los random forest o bosques aleatorios?

Los **Random Forest** o **Bosques Aleatorios** son un **algoritmo de aprendizaje autom√°tico supervisado** que se utiliza tanto para **clasificaci√≥n** como para **regresi√≥n**.

### üå≤ ¬øQu√© son?

Un **Random Forest** es un **conjunto (ensamble)** de muchos **√°rboles de decisi√≥n** que trabajan juntos. En lugar de confiar en un solo √°rbol de decisi√≥n, este m√©todo construye varios √°rboles y **combina sus resultados** para obtener una predicci√≥n m√°s precisa y robusta.

### üîç ¬øC√≥mo funciona?

1. **Se crean muchos √°rboles de decisi√≥n**, cada uno entrenado con una **muestra aleatoria del dataset** (con reemplazo, t√©cnica llamada *bootstrap*).
2. Para cada √°rbol, al momento de decidir una divisi√≥n, **solo se consideran aleatoriamente un subconjunto de las variables**.
3. Para clasificaci√≥n: se toma el **voto mayoritario** de todos los √°rboles.

   * Para regresi√≥n: se toma el **promedio** de las predicciones de todos los √°rboles.

### üéØ Ventajas:

* ‚úÖ Reduce el **sobreajuste (overfitting)** de un solo √°rbol.
* ‚úÖ Es m√°s **preciso y estable** que un √°rbol de decisi√≥n individual.
* ‚úÖ Funciona bien incluso sin ajustes finos de hiperpar√°metros.
* ‚úÖ Puede manejar **datos faltantes y variables categ√≥ricas**.

### ‚ö†Ô∏è Desventajas:

* ‚ùå Es m√°s lento y consume m√°s memoria que un solo √°rbol.
* ‚ùå Dif√≠cil de interpretar (a diferencia de un solo √°rbol de decisi√≥n).

### üìä Ejemplo de uso:

Si est√°s clasificando tipos de veh√≠culos (el√©ctrico, h√≠brido, gasolina) a partir de datos como peso, potencia, y consumo, un modelo **Random Forest** puede ofrecer muy buena precisi√≥n al combinar decisiones de m√∫ltiples √°rboles.

## Tu primer random forest con scikit-learn

¬°Perfecto! Vamos a crear tu **primer Random Forest con `scikit-learn`**, paso a paso. Usaremos un dataset cl√°sico: **Iris**, que es ideal para clasificaci√≥n.

### ‚úÖ 1. Importar librer√≠as necesarias

```python
from sklearn.datasets import load_iris
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
```

### ‚úÖ 2. Cargar el dataset y dividir en entrenamiento y prueba

```python
# Cargar el dataset Iris
iris = load_iris()
X = iris.data
y = iris.target

# Dividir en entrenamiento (80%) y prueba (20%)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
```

### ‚úÖ 3. Crear y entrenar el modelo Random Forest

```python
# Crear el modelo
model = RandomForestClassifier(n_estimators=100, random_state=42)

# Entrenar el modelo
model.fit(X_train, y_train)
```

### ‚úÖ 4. Realizar predicciones y evaluar

```python
# Predicciones
y_pred = model.predict(X_test)

# M√©tricas
print("Accuracy:", accuracy_score(y_test, y_pred))
print("\nReporte de Clasificaci√≥n:\n", classification_report(y_test, y_pred))
print("\nMatriz de Confusi√≥n:\n", confusion_matrix(y_test, y_pred))
```

### ‚úÖ 5. Visualizar la importancia de las caracter√≠sticas

```python
# Importancia de las variables
importances = model.feature_importances_
features = iris.feature_names

# Mostrar con Seaborn
sns.barplot(x=importances, y=features, palette="viridis")
plt.title("Importancia de caracter√≠sticas en Random Forest")
plt.xlabel("Importancia")
plt.ylabel("Caracter√≠stica")
plt.show()
```

### ‚úÖ Resultado Esperado:

* Una **alta precisi√≥n** (accuracy > 90%) en este dataset.
* Gr√°fico con las variables m√°s relevantes para el modelo.
* Matriz de confusi√≥n para visualizar errores (falsos positivos/negativos).

**Archivos de la clase**

[primer-random-forest-completed.ipynb](https://static.platzi.com/media/public/uploads/primer_random_forest_completed_e98709b3-f62e-4b17-befb-02e3cdf7b810.ipynb)
[primer-random-forest-template.ipynb](https://static.platzi.com/media/public/uploads/primer_random_forest_template_a4b4eae3-7fbe-49c5-9f32-66bb8aca4f38.ipynb)

**Lecturas recomendadas**

[pima-indians-diabetes.csv | Kaggle](https://www.kaggle.com/datasets/kumargh/pimaindiansdiabetescsv)

[primer_random_forest_completed.ipynb - Google Drive](https://drive.google.com/file/d/19eaWQEU_9OH7Hy3VnQErGiRClUVLzNEK/view?usp=sharing)

[primer_random_forest_template.ipynb - Google Drive](https://drive.google.com/file/d/1ksrGgYppmGM8U8uNErNKWM5pn5lP9sd1/view?usp=sharing)

## Entrenamiento de tu primer modelo de random forest con scikit-learn

¬°Perfecto! Aqu√≠ tienes una gu√≠a clara y pr√°ctica para el **entrenamiento de tu primer modelo de Random Forest con `scikit-learn`** usando un dataset real:

### üîß Paso 1: Importar librer√≠as necesarias

```python
from sklearn.ensemble import RandomForestClassifier
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, accuracy_score, confusion_matrix
import matplotlib.pyplot as plt
import seaborn as sns
```

### üì• Paso 2: Cargar y explorar los datos

```python
# Dataset cl√°sico: Iris
iris = load_iris()
X = iris.data
y = iris.target

# Opcional: ver forma de los datos
print("Shape X:", X.shape)
print("Shape y:", y.shape)
```

### ‚úÇÔ∏è Paso 3: Dividir en entrenamiento y prueba

```python
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
```

### üå≤ Paso 4: Crear y entrenar el modelo Random Forest

```python
rf_model = RandomForestClassifier(n_estimators=100, random_state=42)
rf_model.fit(X_train, y_train)
```

### üìà Paso 5: Realizar predicciones

```python
y_pred = rf_model.predict(X_test)
```

### ‚úÖ Paso 6: Evaluar el modelo

```python
print("Accuracy:", accuracy_score(y_test, y_pred))
print("\nClassification Report:\n", classification_report(y_test, y_pred))
print("\nConfusion Matrix:\n", confusion_matrix(y_test, y_pred))
```

### üîç Paso 7: Visualizar importancia de caracter√≠sticas

```python
feature_importances = rf_model.feature_importances_
feature_names = iris.feature_names

sns.barplot(x=feature_importances, y=feature_names)
plt.title("Importancia de las caracter√≠sticas")
plt.xlabel("Importancia")
plt.ylabel("Caracter√≠stica")
plt.show()
```

### üéâ Resultado:

Con el dataset **Iris**, deber√≠as obtener una precisi√≥n bastante alta (cerca o superior al 95%), y podr√°s ver qu√© variables fueron m√°s importantes para la clasificaci√≥n.

**Lecturas recomendadas**

[pima-indians-diabetes.csv | Kaggle](https://www.kaggle.com/datasets/kumargh/pimaindiansdiabetescsv)

[primer_random_forest_completed.ipynb - Google Drive](https://drive.google.com/file/d/19eaWQEU_9OH7Hy3VnQErGiRClUVLzNEK/view?usp=sharing)

[primer_random_forest_template.ipynb - Google Drive](https://drive.google.com/file/d/1ksrGgYppmGM8U8uNErNKWM5pn5lP9sd1/view?usp=sharing)

## Evaluaci√≥n de tu primer modelo de random forest con scikit-learn

¬°Perfecto! Una vez entrenado tu primer modelo de **Random Forest** con `scikit-learn`, es fundamental **evaluarlo correctamente** para entender su rendimiento. Aqu√≠ te explico c√≥mo hacerlo paso a paso:

### ‚úÖ **1. Predicci√≥n en datos de prueba**

```python
y_pred = rf_model.predict(X_test)
```

Tambi√©n puedes obtener las **probabilidades de clase** si lo necesitas:

```python
y_proba = rf_model.predict_proba(X_test)
```

### üìä **2. M√©tricas de evaluaci√≥n**

#### a. **Exactitud (Accuracy)**

```python
from sklearn.metrics import accuracy_score
print("Accuracy:", accuracy_score(y_test, y_pred))
```

#### b. **Reporte de Clasificaci√≥n (precision, recall, f1-score)**

```python
from sklearn.metrics import classification_report
print(classification_report(y_test, y_pred, target_names=iris.target_names))
```

#### c. **Matriz de confusi√≥n**

```python
from sklearn.metrics import confusion_matrix
import seaborn as sns
import matplotlib.pyplot as plt

cm = confusion_matrix(y_test, y_pred)

sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
            xticklabels=iris.target_names,
            yticklabels=iris.target_names)
plt.xlabel('Predicci√≥n')
plt.ylabel('Real')
plt.title('Matriz de Confusi√≥n')
plt.show()
```

### üß† **3. Importancia de caracter√≠sticas**

Para entender qu√© variables son m√°s relevantes:

```python
import pandas as pd

importances = pd.Series(rf_model.feature_importances_, index=iris.feature_names)
importances.sort_values(ascending=True).plot(kind='barh')
plt.title('Importancia de las caracter√≠sticas')
plt.show()
```

### üß™ **4. Validaci√≥n cruzada (opcional)**

Para evaluar el modelo de forma m√°s robusta:

```python
from sklearn.model_selection import cross_val_score

scores = cross_val_score(rf_model, X, y, cv=5)
print("Accuracy promedio con CV:", scores.mean())
```

### üîç Resultado esperado

Con un dataset como el **Iris**, podr√≠as obtener:

* Accuracy > 0.95
* Una matriz de confusi√≥n clara
* Las caracter√≠sticas m√°s importantes (ej. `petal length` o `petal width`)

## ¬øC√≥mo funcionan los random forest?

Los **Random Forest** (o **bosques aleatorios**) son un algoritmo de **aprendizaje autom√°tico supervisado** basado en **√°rboles de decisi√≥n**, pero mejorado gracias a la combinaci√≥n de muchos √°rboles. Su objetivo es hacer predicciones m√°s **precisas**, **robustas** y **menos propensas al sobreajuste** que un √∫nico √°rbol.

### üå≥ ¬øC√≥mo funciona un Random Forest?

1. **Creaci√≥n de m√∫ltiples √°rboles de decisi√≥n (forest):**

   * En lugar de construir un solo √°rbol, el Random Forest construye **muchos √°rboles** (por ejemplo, 100 o 500).
   * Cada √°rbol se entrena con una **muestra aleatoria** del conjunto de datos original (con reemplazo, es decir, **bootstrap**).

2. **Selecci√≥n aleatoria de caracter√≠sticas:**

   * Cuando un √°rbol va a hacer una divisi√≥n en un nodo, **no mira todas las caracter√≠sticas**, sino que selecciona un subconjunto aleatorio.
   * Esto aumenta la **diversidad** entre los √°rboles y mejora la generalizaci√≥n.

3. **Votaci√≥n o promedio de predicciones:**

   * Para **clasificaci√≥n**, cada √°rbol "vota" por una clase, y gana la clase m√°s votada.
   * Para **regresi√≥n**, se promedia la predicci√≥n de todos los √°rboles.

### üéØ Ejemplo simple (clasificaci√≥n)

Supongamos que quieres predecir si un cliente comprar√° o no un producto.

* Entrenas 100 √°rboles, cada uno con diferentes subconjuntos de datos y caracter√≠sticas.
* Un cliente nuevo llega. Cada √°rbol da su predicci√≥n (s√≠ o no).
* El **resultado final** ser√° el que tenga **m√°s votos**.

### ‚öñÔ∏è Ventajas del Random Forest

‚úÖ Reduce el **sobreajuste** comparado con un solo √°rbol
‚úÖ Funciona bien en la mayor√≠a de los problemas (clasificaci√≥n y regresi√≥n)
‚úÖ Puede manejar **datos faltantes** y **variables categ√≥ricas o num√©ricas**
‚úÖ Da una **medida de importancia** de las variables (`feature_importances_`)

### ‚ö†Ô∏è Desventajas

‚ùå Menos interpretables que un solo √°rbol
‚ùå Consumen m√°s recursos (RAM/tiempo)
‚ùå El entrenamiento puede ser m√°s lento con muchos √°rboles o muchos datos

### üîß Par√°metros clave en Scikit-learn

```python
from sklearn.ensemble import RandomForestClassifier

modelo = RandomForestClassifier(
    n_estimators=100,       # n√∫mero de √°rboles
    max_depth=None,         # profundidad m√°xima del √°rbol
    max_features='sqrt',    # n√∫mero de features aleatorios por split
    bootstrap=True,         # si usar muestreo con reemplazo
    random_state=42
)
```

## ¬øCu√°ndo utilizar random forest?

Puedes utilizar **Random Forest** cuando necesitas un modelo robusto y preciso para **clasificaci√≥n** o **regresi√≥n**, especialmente en situaciones donde:

### ‚úÖ **Cu√°ndo usar Random Forest**

#### 1. **Tienes muchos datos y no sabes qu√© modelo usar**

* Random Forest es un buen modelo **por defecto**: funciona bien sin necesidad de demasiada configuraci√≥n.
* Puede manejar **datos con muchas caracter√≠sticas** y detectar cu√°les son realmente importantes.

#### 2. **Tus datos tienen ruido o relaciones no lineales**

* Random Forest no asume relaciones lineales entre variables.
* Es resistente al **sobreajuste**, especialmente comparado con √°rboles de decisi√≥n individuales.

#### 3. **Quisieras una estimaci√≥n de la importancia de las variables**

* Random Forest te da una medida clara de la **importancia de cada feature**, √∫til para interpretar el modelo o reducir la dimensionalidad.

#### 4. **No te importa que el modelo sea poco interpretable**

* A diferencia de una regresi√≥n lineal o un solo √°rbol, el modelo es como una "caja negra".
* Pero si **la precisi√≥n es m√°s importante que la explicaci√≥n**, es una buena opci√≥n.

#### 5. **Tienes datos faltantes o mezcla de datos categ√≥ricos y num√©ricos**

* Random Forest puede tolerar **cierto nivel de datos faltantes**.
* Maneja datos categ√≥ricos codificados (por ejemplo, con One-Hot Encoding) sin problemas.

#### 6. **Tu problema es de clasificaci√≥n multiclase o multietiqueta**

* Funciona bien en escenarios donde hay m√°s de dos clases o m√∫ltiples etiquetas.

### ‚ùå **Cu√°ndo evitar Random Forest**

* Cuando necesitas un modelo **muy interpretable** (por ejemplo, en medicina o leyes).
* Si tienes **poco poder de c√≥mputo**: entrenar muchos √°rboles puede ser costoso.
* Si tu conjunto de datos es **muy peque√±o**, un √°rbol de decisi√≥n o un modelo m√°s simple puede ser mejor.

### üß† Ejemplos de uso en la vida real

* **Banca**: detectar fraudes o evaluar el riesgo crediticio.
* **Medicina**: predecir enfermedades a partir de datos cl√≠nicos.
* **Marketing**: segmentar clientes o predecir abandono.
* **Finanzas**: predecir el precio de una acci√≥n.
* **Ingenier√≠a**: detectar fallos en sensores o equipos.

**Lecturas recomendadas**

[Random Forest (Bosque Aleatorio): combinando √°rboles - IArtificial.net](https://www.iartificial.net/random-forest-bosque-aleatorio/)

## Entrenamiento de modelo de clasificaci√≥n de carros con random forest

Aqu√≠ tienes un ejemplo completo de **entrenamiento de un modelo de clasificaci√≥n de carros usando Random Forest en Python con `scikit-learn`**, desde los datos hasta la predicci√≥n:

### ‚úÖ Supongamos que tienes un dataset con las siguientes columnas:

* `marca`, `anio`, `cilindraje`, `tipo_combustible`, `precio_categoria` (donde esta √∫ltima es la variable **objetivo**: "alto", "medio", "bajo")

### üì¶ 1. Importar librer√≠as

```python
import pandas as pd
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import classification_report, confusion_matrix
```

### üìÑ 2. Datos de ejemplo

```python
# Datos simulados
data = {
    'marca': ['Toyota', 'Mazda', 'Renault', 'Chevrolet', 'Kia'],
    'anio': [2015, 2018, 2020, 2017, 2016],
    'cilindraje': [1.6, 2.0, 1.2, 1.4, 1.6],
    'tipo_combustible': ['Gasolina', 'Gasolina', 'Gasolina', 'Diesel', 'Gasolina'],
    'precio_categoria': ['medio', 'alto', 'bajo', 'medio', 'bajo']
}
df = pd.DataFrame(data)
```

### üßπ 3. Preprocesamiento

```python
# Codificaci√≥n de variables categ√≥ricas
le_marca = LabelEncoder()
le_comb = LabelEncoder()
le_target = LabelEncoder()

df['marca'] = le_marca.fit_transform(df['marca'])
df['tipo_combustible'] = le_comb.fit_transform(df['tipo_combustible'])
df['precio_categoria'] = le_target.fit_transform(df['precio_categoria'])  # Etiquetas 0, 1, 2
```

### ‚úÇÔ∏è 4. Divisi√≥n en train/test

```python
X = df.drop('precio_categoria', axis=1)
y = df['precio_categoria']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)
```

### üå≤ 5. Entrenamiento del modelo Random Forest

```python
model = RandomForestClassifier(n_estimators=100, random_state=42)
model.fit(X_train, y_train)
```

### üß™ 6. Evaluaci√≥n del modelo

```python
y_pred = model.predict(X_test)

print("Matriz de confusi√≥n:")
print(confusion_matrix(y_test, y_pred))
print("\nReporte de clasificaci√≥n:")
print(classification_report(y_test, y_pred, target_names=le_target.classes_))
```

### üß† 7. Predecir nuevos autos

```python
nuevo_auto = pd.DataFrame({
    'marca': le_marca.transform(['Toyota']),
    'anio': [2022],
    'cilindraje': [1.8],
    'tipo_combustible': le_comb.transform(['Gasolina'])
})

pred = model.predict(nuevo_auto)
print(f"Categor√≠a de precio predicha: {le_target.inverse_transform(pred)[0]}")
```

**Archivos de la clase**

[decision-tree-random-forest-project-completed.ipynb](https://static.platzi.com/media/public/uploads/decision_tree_random_forest_project_completed_562b6c49-de86-4fb3-9a11-cdc2f5c37678.ipynb)
[decision-tree-random-forest-project-template.ipynb](https://static.platzi.com/media/public/uploads/decision_tree_random_forest_project_template_8dcf18db-e157-4d47-85a9-ef449f26de4c.ipynb)

**Lecturas recomendadas**

[sklearn.ensemble.RandomForestClassifier ‚Äî scikit-learn 1.2.1 documentation](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html)
[decision_tree_random_forest_project_completed.ipynb - Google Drive](https://drive.google.com/file/d/1Ck8R2GXK_ZeW9oYRIdXgVhBqi3ibt_QJ/view?usp=sharing)
[decision_tree_random_forest_project_template.ipynb - Google Drive](https://drive.google.com/file/d/1PFP6e4YfAI8nXq31kzRC8NquONJqLqeK/view?usp=sharing)

## Evaluaci√≥n de resultados del modelo de clasificaci√≥n con random forest

La **evaluaci√≥n de resultados de un modelo de clasificaci√≥n con Random Forest** en scikit-learn se realiza principalmente con m√©tricas como:

### ‚úÖ 1. **Accuracy (exactitud)**

Mide el porcentaje de predicciones correctas sobre el total.

```python
from sklearn.metrics import accuracy_score

accuracy = accuracy_score(y_test, y_pred)
print(f"Accuracy del modelo: {accuracy:.2f}")
```

### ‚úÖ 2. **Matriz de confusi√≥n**

Muestra cu√°ntos ejemplos se clasificaron correctamente y cu√°les fueron confundidos entre clases.

```python
from sklearn.metrics import confusion_matrix
import seaborn as sns
import matplotlib.pyplot as plt

cm = confusion_matrix(y_test, y_pred)

plt.figure(figsize=(5,4))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=le_target.classes_, yticklabels=le_target.classes_)
plt.xlabel("Predicci√≥n")
plt.ylabel("Real")
plt.title("Matriz de Confusi√≥n")
plt.show()
```

### ‚úÖ 3. **Reporte de clasificaci√≥n**

Incluye precisi√≥n, recall y F1-score para cada clase:

```python
from sklearn.metrics import classification_report

print(classification_report(y_test, y_pred, target_names=le_target.classes_))
```

üîπ **Precision**: De los que predije como clase X, ¬øcu√°ntos eran realmente X?
üîπ **Recall**: De todos los que eran clase X, ¬øcu√°ntos los detect√© correctamente?
üîπ **F1-score**: Promedio ponderado de precisi√≥n y recall.

### ‚úÖ 4. **Importancia de caracter√≠sticas**

Para saber qu√© variables influyen m√°s en el modelo:

```python
importances = model.feature_importances_
for col, imp in zip(X.columns, importances):
    print(f"{col}: {imp:.4f}")
```

### üéØ Ejemplo de salida esperada (si se us√≥ el c√≥digo anterior)

```text
Accuracy del modelo: 0.80

              precision    recall  f1-score   support

        alto       0.75      1.00      0.86         1
        bajo       1.00      0.50      0.67         2
       medio       1.00      1.00      1.00         1

    accuracy                           0.80         4
   macro avg       0.92      0.83      0.84         4
weighted avg       0.88      0.80      0.79         4
```

**Archivos de la clase**

[decision-tree-random-forest-project-completed.ipynb](https://static.platzi.com/media/public/uploads/decision_tree_random_forest_project_completed_2b8cc33a-1f4f-47f4-8f0b-8f881066cd3d.ipynb)
[decision-tree-random-forest-project-template.ipynb](https://static.platzi.com/media/public/uploads/decision_tree_random_forest_project_template_f5d5ec26-0355-4844-8cc1-2e016d08c6e9.ipynb)

**Lecturas recomendadas**

[sklearn.metrics.accuracy_score ‚Äî scikit-learn 1.2.1 documentation](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html)
[decision_tree_random_forest_project_completed.ipynb - Google Drive](https://drive.google.com/file/d/1Ck8R2GXK_ZeW9oYRIdXgVhBqi3ibt_QJ/view?usp=sharing)
[decision_tree_random_forest_project_template.ipynb - Google Drive](https://drive.google.com/file/d/1PFP6e4YfAI8nXq31kzRC8NquONJqLqeK/view?usp=sharing)

**Lecturas recomendadas**

[UCI Machine Learning Repository: Census Income Data Set](https://archive.ics.uci.edu/ml/datasets/Census+Income)

[https://www.linkedin.com/in/laylascheli/](https://www.linkedin.com/in/laylascheli/)