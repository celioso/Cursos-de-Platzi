# Curso de Fundamentos de √Ålgebra Lineal con Python

## Profesor: Sebastian Sosa
## Version: 09/2019

## Basado en el Segundo Capitulo "2 Algebra Lineal" del libro http://www.deeplearningbook.org/

@book{Goodfellow-et-al-2016,
    title={Deep Learning},
    author={Ian Goodfellow and Yoshua Bengio and Aaron Courville},
    publisher={MIT Press},
    note={\url{http://www.deeplearningbook.org}},
    year={2016}
}

## √Ålgebra Lineal para An√°lisis de Datos y Algoritmos

¬°Perfecto! El **√°lgebra lineal** es fundamental en el an√°lisis de datos y el desarrollo de algoritmos, especialmente en **ciencia de datos**, **machine learning** y **visi√≥n computacional**. Aqu√≠ tienes una introducci√≥n clara y √∫til:

### üî∑ ¬øQu√© es √Ålgebra Lineal?

Es una rama de las matem√°ticas que estudia **vectores**, **matrices**, **espacios vectoriales** y **transformaciones lineales**. Se utiliza para representar y resolver sistemas de ecuaciones lineales y para manejar datos multivariados de forma estructurada.

### üîë Aplicaciones en Ciencia de Datos y Algoritmos

1. **Representaci√≥n de Datos**

   * Los datos tabulares (filas/columnas) se representan como **matrices**.
   * Cada fila puede ser un vector de caracter√≠sticas de una observaci√≥n.

2. **Transformaciones Lineales**

   * Escalado, rotaci√≥n, reducci√≥n de dimensi√≥n (PCA), etc., se describen con multiplicaci√≥n de matrices.

3. **Modelos de Machine Learning**

   * Regresi√≥n lineal, redes neuronales, y SVM dependen del c√°lculo con vectores y matrices.
   * Por ejemplo, una red neuronal aplica pesos (matrices) a vectores de entrada.

4. **Descomposici√≥n de Matrices**

   * T√©cnicas como **SVD (Singular Value Decomposition)** y **eigenvalores** se usan para compresi√≥n, recomendadores y reducci√≥n de dimensiones.

5. **Soluci√≥n de Sistemas de Ecuaciones**

   * Resolver $AX = B$ es clave para entender el comportamiento de modelos lineales.

### üîß √Ålgebra Lineal en Python (con NumPy)

```python
import numpy as np

# Vectores
v1 = np.array([1, 2])
v2 = np.array([3, 4])

# Suma y producto punto
print("Suma:", v1 + v2)
print("Producto punto:", np.dot(v1, v2))

# Matrices
A = np.array([[1, 2], [3, 4]])
B = np.array([[2, 0], [1, 3]])

# Multiplicaci√≥n de matrices
print("Multiplicaci√≥n de matrices:\n", np.dot(A, B))

# Inversa y transpuesta
print("Inversa:\n", np.linalg.inv(A))
print("Transpuesta:\n", A.T)
```

### üîç Conceptos Clave

| Concepto          | Uso en Ciencia de Datos                    |
| ----------------- | ------------------------------------------ |
| Vector            | Representa un dato o variable multivariada |
| Matriz            | Conjunto de vectores (dataset)             |
| Producto escalar  | Similaridad entre vectores                 |
| Norma             | Longitud o magnitud del vector             |
| Autovalores       | Variabilidad en reducci√≥n de dimensi√≥n     |
| Inversa de matriz | Resolver ecuaciones lineales               |

### Resumen

### ¬øPor qu√© es fundamental aprender √°lgebra lineal?

El √°lgebra lineal es una herramienta esencial para cualquier persona interesada en ciencias, ingenier√≠a y tecnolog√≠a. Es la base para entender las operaciones entre matrices y vectores, componentes clave en la mayor√≠a de los algoritmos modernos. Sebasti√°n Sosa, con su experiencia en ciencias matem√°ticas y an√°lisis de datos, ilustra c√≥mo este saber matem√°tico se aplica en el aprendizaje autom√°tico y proyectos de la vida real. Su experiencia resalta la importancia de dominar conceptos que, aunque parecen est√°ticos, son atemporales en su aplicaci√≥n.

#### ¬øC√≥mo se aplica el √°lgebra lineal en proyectos?

Sebasti√°n ha trabajado en proyectos fascinantes que demuestran la aplicabilidad del √°lgebra lineal. Uno de estos proyectos es un aplicativo que identifica especies de √°rboles a partir de una foto de una hoja, utilizando algoritmos que requieren de un profundo entendimiento de las matrices y vectores. En otro proyecto, trabaj√≥ en un sistema que recomienda canciones basadas en sus letras, una aplicaci√≥n perfecta del √°lgebra lineal para procesar grandes vol√∫menes de datos textuales.

#### ¬øCu√°les son los conceptos esenciales del √°lgebra lineal a estudiar?

En √°lgebra lineal, es crucial familiarizarse con:

- **Matrices**: Tablas de n√∫meros que representan datos o transformaciones.
- **Vectores**: Elementos que tienen direcci√≥n y magnitud, usados para representar datos espaciales.
- T**ensor**: Una generalizaci√≥n de matrices y vectores, crucial en las ciencias computacionales modernas.

Estos conceptos permiten realizar operaciones que trascienden las matem√°ticas ordinarias y son esenciales para algoritmos avanzados.

#### ¬øQu√© beneficios ofrece conocer √°lgebra lineal a largo plazo?

El conocimiento de √°lgebra lineal no solo es √∫til en la actualidad, sino tambi√©n prepara el camino para adaptarse a las tecnolog√≠as del futuro. A medida que los algoritmos y las tecnolog√≠as evolucionan, el entendimiento de estos fundamentos matem√°ticos te permitir√° adoptar nuevos avances sin dificultad. Al igual que las operaciones b√°sicas de aritm√©tica permanecen invariables, los principios del √°lgebra lineal otorgar√°n solidez a tus habilidades anal√≠ticas en cualquier contexto tecnol√≥gico.

#### ¬øC√≥mo puedes prepararte para aprender √°lgebra lineal?

Para iniciar tu viaje en el √°lgebra lineal, es importante configurar tu entorno de aprendizaje de manera adecuada. Aseg√∫rate de tener acceso a herramientas y recursos que te permitan practicar y aplicar tus conocimientos en casos pr√°cticos y proyectos. Este inicio te proporcionar√° una base s√≥lida que, como se√±ala Sebasti√°n Sosa, te ayudar√° a mantenerte relevante y competitivo en un mundo donde los datos son m√°s valiosos que nunca.

Emb√°rcate en el aprendizaje del √°lgebra lineal con entusiasmo y curiosidad. Desarrollar una comprensi√≥n s√≥lida de estos conceptos matem√°ticos abrir√° un mundo de posibilidades en la ciencia y la tecnolog√≠a.

## Uso de Jupyter Notebook para An√°lisis de Datos Reproducibles

El **uso de Jupyter Notebook** para an√°lisis de datos reproducibles es una pr√°ctica fundamental en ciencia de datos, ya que permite combinar c√≥digo, visualizaciones y explicaciones en un mismo entorno. Aqu√≠ te explico c√≥mo usarlo paso a paso con enfoque en **reproducibilidad**:

### ‚úÖ ¬øQu√© es un An√°lisis Reproducible?

Es aquel que puede ser **repetido por otras personas** (o por ti en el futuro) y **obtener los mismos resultados**, siempre que los datos y el entorno sean iguales.

### üß∞ 1. Instalar y Abrir Jupyter Notebook

Si usas `conda`:

```bash
conda install notebook
jupyter notebook
```

Con `pip`:

```bash
pip install notebook
jupyter notebook
```

### üìù 2. Estructura Recomendada de un Notebook Reproducible

#### üìå Secciones t√≠picas:

1. **T√≠tulo y objetivo**

   ```markdown
   # An√°lisis de Ventas - Enero 2025
   Este notebook analiza las ventas mensuales para detectar tendencias y patrones.
   ```

2. **Importaci√≥n de librer√≠as**

   ```python
   import pandas as pd
   import numpy as np
   import matplotlib.pyplot as plt
   import seaborn as sns
   ```

3. **Fijar semilla aleatoria** (para reproducibilidad en modelos o simulaciones)

   ```python
   np.random.seed(42)
   ```

4. **Carga de datos**

   ```python
   df = pd.read_csv('ventas.csv')
   ```

5. **Exploraci√≥n de datos**

   ```python
   df.head()
   df.describe()
   ```

6. **Visualizaciones**

   ```python
   sns.histplot(df['ventas'], bins=10)
   ```

7. **Modelado o c√°lculos**

   ```python
   promedio = df['ventas'].mean()
   ```

8. **Conclusiones**

   ```markdown
   El promedio de ventas fue de $X. Se observ√≥ un pico en la semana 2, relacionado con promociones especiales.
   ```

### üîÅ 3. Buenas Pr√°cticas para Reproducibilidad

* Ejecuta todo desde el principio con **Kernel > Restart & Run All**.
* Usa rutas relativas para cargar archivos (`./data/archivo.csv`).
* Anota supuestos, decisiones y pasos clave con celdas de **Markdown**.
* Guarda un `requirements.txt` o `environment.yml` para el entorno.

### üß™ Ejemplo de Reproducibilidad T√©cnica

```bash
pip freeze > requirements.txt
```

o con conda:

```bash
conda env export > environment.yml
```

Esto permite que otros creen el mismo entorno con:

```bash
pip install -r requirements.txt
```

o

```bash
conda env create -f environment.yml
```

### Resumen

#### ¬øQu√© es Jupyter Notebook y por qu√© es esencial para el an√°lisis de datos?

Jupyter Notebook es una herramienta poderosa en el mundo del an√°lisis de datos que permite mantener c√≥digo, documentaci√≥n y gr√°ficos en un √∫nico lugar interactivo. Esto facilita la creaci√≥n de an√°lisis reproducibles y la documentaci√≥n simult√°nea del proceso. No solo ahorra tiempo, sino que tambi√©n garantiza que los resultados se puedan compartir y revisar f√°cilmente. Para los cient√≠ficos de datos y analistas, es una plataforma esencial que hace que el flujo de trabajo sea m√°s eficiente y colaborativo.

#### ¬øC√≥mo iniciar Jupyter Notebook con Anaconda?

Iniciar Jupyter Notebook es bastante sencillo si utilizas Anaconda. Este entorno ya viene preconfigurado con las herramientas necesarias para comenzar a trabajar:

1. **Abre Anaconda Navigator**: Busca la opci√≥n de abrir Jupyter Notebook desde el dashboard.
2. **Selecciona el entorno adecuad**o: Cambia al entorno que hayas configurado, en este caso, Platzi Fundamentos de AI.
3. **Abrir el explorador de carpetas**: Jupyter abrir√° autom√°ticamente una ventana en tu navegador mostrando las carpetas accesibles en tu sistema donde puedes guardar tus datos.
4. **Crear nuevas carpetas**: Puedes crear nuevas carpetas para organizar mejor tu trabajo usando la opci√≥n de generar nueva carpeta y luego renombrarla seg√∫n tus necesidades.

#### ¬øC√≥mo crear y utilizar un notebook en Jupyter?

Una vez que hayas configurado tu entorno y est√©s en la interfaz de Jupyter, puedes comenzar a crear y utilizar notebooks:

- **Generar un notebook nuevo de Python**:

`# Esto se hace desde la interfaz web de Jupyter.`

- **Renombrar el notebook**: Haz clic en el nombre por defecto para renombrarlo, lo cual ayuda a mantener tu trabajo organizado.

- **Escribir y ejecutar c√≥digo**:

```python
# Ejemplo de c√≥digo para conocer la versi√≥n de Python
from platform import python_version
print(python_version())
```

Puedes ejecutar este bloque de c√≥digo presionando `Shift` + `Enter.`

#### ¬øC√≥mo realizar comentarios en tu c√≥digo?

Hacer comentarios en tu c√≥digo dentro de Jupyter Notebook es muy pr√°ctico y te permite explicar lo que est√°s haciendo directamente en el entorno. Para comentarios simples, utiliza:

`# Este es un comentario sobre el c√≥digo`

Si necesitas comentar varias l√≠neas a la vez, selecciona el bloque y presiona `Ctrl + /` para comentar todas las l√≠neas seleccionadas, o para descomentarlas si ya est√°n comentadas.

#### ¬øC√≥mo interactuar con m√∫ltiples navegadores en Jupyter?

Jupyter Notebook generalmente abre en tu navegador predeterminado. Si necesitas usar otro navegador, sigue estos pasos:

1. Copia el enlace proporcionado por Jupyter en el navegador abierto.
2. Pega el enlace en la barra de direcciones del navegador que deseas usar.

#### ¬øCu√°les son las mejores pr√°cticas para gestionar celdas en Jupyter?

Es importante no exceder las 100 celdas por notebook para mantener un rendimiento √≥ptimo. Si tu an√°lisis requiere m√°s, considera dividir tu trabajo en m√∫ltiples notebooks.

#### ¬øC√≥mo reutilizar c√≥digo de otros notebooks?

Para optimizar tus an√°lisis, puedes crear funciones auxiliares en un notebook y reutilizarlas en otros. Usa el comando de ejecuci√≥n m√°gica para ejecutar el c√≥digo de otro notebook:

`%run path/to/your_script.ipynb`

Este enfoque no solo incrementa la eficiencia, sino que tambi√©n hace que tus an√°lisis parezcan m√°s profesionales.

¬°Sigue explorando y aprovechando al m√°ximo las capacidades de Jupyter Notebook para tus proyectos de an√°lisis de datos! Su reproducci√≥n efectiva del an√°lisis y la capacidad de compartir trabajos francamente mejora la colaboraci√≥n y la comprobaci√≥n de resultados en equipo.

**Lecturas recomendadas**

[Project Jupyter | Home](https://jupyter.org/)

## Elementos B√°sicos de √Ålgebra Lineal en Python: Escalares a Tensores

¬°Perfecto! Aqu√≠ tienes una introducci√≥n clara y pr√°ctica sobre los **Elementos B√°sicos de √Ålgebra Lineal en Python**, desde **escalares** hasta **tensores**, usando **NumPy**, que es la librer√≠a est√°ndar para operaciones num√©ricas en Python.

### üî¢ Elementos B√°sicos de √Ålgebra Lineal en Python

### 1. **Escalares (0D)**

Un escalar es simplemente un n√∫mero. En NumPy:

```python
import numpy as np

escalar = np.array(5)
print(escalar)         # 5
print(escalar.ndim)    # 0 (dimensi√≥n escalar)
```

### 2. **Vectores (1D)**

Un vector es una lista de n√∫meros (una dimensi√≥n):

```python
vector = np.array([1, 2, 3])
print(vector)
print(vector.ndim)     # 1
```

### 3. **Matrices (2D)**

Una matriz es una tabla de n√∫meros (dos dimensiones):

```python
matriz = np.array([[1, 2], [3, 4]])
print(matriz)
print(matriz.ndim)     # 2
```

### 4. **Tensores (3D o m√°s)**

Un tensor es una estructura de datos de m√°s de 2 dimensiones:

```python
tensor = np.array([
    [[1, 2], [3, 4]],
    [[5, 6], [7, 8]]
])
print(tensor)
print(tensor.ndim)     # 3
```

### üßÆ Operaciones b√°sicas

### üîπ Suma y Resta

```python
a = np.array([1, 2])
b = np.array([3, 4])
print(a + b)  # [4 6]
print(a - b)  # [-2 -2]
```

### üîπ Producto Escalar

```python
np.dot(a, b)  # 1*3 + 2*4 = 11
```

### üîπ Multiplicaci√≥n de Matrices

```python
A = np.array([[1, 2], [3, 4]])
B = np.array([[2, 0], [1, 2]])
print(np.dot(A, B))
```

### üß† Visualizar Dimensiones

```python
print(f'Escalar: {escalar.shape}')
print(f'Vector: {vector.shape}')
print(f'Matriz: {matriz.shape}')
print(f'Tensor: {tensor.shape}')
```

### üìå En resumen:

| Estructura | Dimensi√≥n | Ejemplo                 |
| ---------- | --------- | ----------------------- |
| Escalar    | 0D        | `5`                     |
| Vector     | 1D        | `[1, 2, 3]`             |
| Matriz     | 2D        | `[[1, 2], [3, 4]]`      |
| Tensor     | 3D o m√°s  | `[[[1,2], [3,4]], ...]` |

### Resumen

#### ¬øCu√°les son los elementos b√°sicos de la matem√°tica en √°lgebra lineal?

El aprendizaje de los fundamentos de √°lgebra lineal es esencial para emprender cualquier estudio de algoritmos avanzados como Machine Learning, Deep Learning y an√°lisis de datos. Los conceptos b√°sicos que exploraremos incluyen: escalar, vector, matriz y tensor.

#### ¬øQu√© es un escalar?

En matem√°tica, un escalar es simplemente un n√∫mero √∫nico. Esto puede ser un n√∫mero entero, un punto flotante (n√∫mero con decimales), o un n√∫mero complejo. No obstante, en Python, un escalar puede ser m√°s flexible: adem√°s de ser cualquier tipo de n√∫mero, tambi√©n puede ser un string, o incluso una variable nula conocida como None.

Si quieres profundizar en c√≥mo Python maneja los escalares, Platzi ofrece cursos en los que puedes explorar m√°s sobre las estructuras de datos en Python.

#### ¬øC√≥mo reconocemos y definimos un vector?

Un vector es un conjunto de n√∫meros ordenados. Imagina una caja donde puedes colocar m√∫ltiples n√∫meros organizados de una manera particular. En Python, los vectores pueden ser creados usando la librer√≠a NumPy, un paquete esencial para cualquier persona interesada en c√°lculos num√©ricos complejos.

```python
import numpy as np
vector = np.array([1, 2, 3, 4])
```

#### ¬øQu√© es una matriz?

La matriz es un paso m√°s all√° del vector, ya que da un mayor grado de libertad ‚Äì podemos movernos a trav√©s de filas y columnas, creando as√≠ un sistema bidimensional de n√∫meros.

En Python, una matriz tambi√©n se crea mediante `NumPy`, pero contiene m√∫ltiples vectores alineados.

`matriz = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])`

#### ¬øC√≥mo definimos un tensor?

Finalmente, avanzamos hacia los tensores. Un tensor expande a√∫n m√°s la complejidad al a√±adir una tercera dimensi√≥n (o m√°s) que agrupa m√∫ltiples matrices. Un tensor es esencial para realizar c√°lculos m√°s complejos y para el trabajo con datos de m√∫ltiples dimensiones, como las im√°genes.

```python
tensor = np.array([
    [[1, 2], [3, 4]], 
    [[5, 6], [7, 8]], 
    [[9, 10], [11, 12]]
])
```

#### ¬øC√≥mo se grafican los tensores?

Es interesante visualizar un tensor cuando contiene datos que podr√≠an corresponder a im√°genes, lo cual es com√∫n en `Deep Learning.` Usamos la librer√≠a `Matplotlib` para su representaci√≥n visual.

```python
import matplotlib.pyplot as plt

# Configurar para que los gr√°ficos aparezcan debajo de la celda
%matplotlib inline

# Crear y mostrar una visualizaci√≥n del tensor
plt.imshow(tensor[0], interpolation='nearest')
plt.show()
```

#### Consejos pr√°cticos para practicar

Ahora que comprendes los conceptos clave, te animo a practicar creando distintas estructuras:

1. **Escalar**: Crea un escalar en Python con el n√∫mero 42.
2. **Vector**: Define un vector que contenga los n√∫meros primos 2, 3, 5 y 7.
3. **Matriz**: Genera una matriz de tama√±o 3x2.
4. **Tensor**: Representa un tensor donde la primera fila sea blanca, la segunda negra, y la tercera gris.

Comparte tus resultados y cualquier duda en el sistema de discusiones de la plataforma. ¬°Tu aportaci√≥n enriquece la comunidad y afianci lecho lo aprendido!

## Dimensiones de Escalares, Vectores, Matrices y Tensores en Python

En Python, especialmente usando la biblioteca **NumPy**, podemos representar **escalares, vectores, matrices y tensores** f√°cilmente, y tambi√©n observar sus **dimensiones**. Aqu√≠ te explico cada uno con ejemplos:

### üîπ 1. **Escalar**

Un escalar es un solo n√∫mero, sin dimensiones.

```python
import numpy as np

escalar = np.array(5)
print("Escalar:", escalar)
print("Dimensi√≥n:", escalar.ndim)  # 0 dimensiones
```

üî∏ **Dimensi√≥n:** `0`
üî∏ **Forma:** `()`
üî∏ **Ejemplo de uso:** una constante como temperatura, velocidad, etc.

### üîπ 2. **Vector**

Un vector es una secuencia ordenada de n√∫meros (una lista unidimensional).

```python
vector = np.array([1, 2, 3])
print("Vector:", vector)
print("Dimensi√≥n:", vector.ndim)  # 1 dimensi√≥n
```

üî∏ **Dimensi√≥n:** `1`
üî∏ **Forma:** `(3,)`
üî∏ **Ejemplo de uso:** coordenadas, caracter√≠sticas de una instancia, etc.

### üîπ 3. **Matriz**

Una matriz es una tabla de n√∫meros (bidimensional).

```python
matriz = np.array([[1, 2, 3], [4, 5, 6]])
print("Matriz:\n", matriz)
print("Dimensi√≥n:", matriz.ndim)  # 2 dimensiones
```

üî∏ **Dimensi√≥n:** `2`
üî∏ **Forma:** `(2, 3)`
üî∏ **Ejemplo de uso:** datos de un dataset, im√°genes en escala de grises, etc.

### üîπ 4. **Tensor**

Un tensor es una estructura con m√°s de dos dimensiones.

```python
tensor = np.array([
    [[1, 2], [3, 4]],
    [[5, 6], [7, 8]]
])
print("Tensor:\n", tensor)
print("Dimensi√≥n:", tensor.ndim)  # 3 dimensiones
```

üî∏ **Dimensi√≥n:** `3`
üî∏ **Forma:** `(2, 2, 2)`
üî∏ **Ejemplo de uso:** im√°genes RGB, datos de series temporales con m√∫ltiples variables, etc.

### üß† Resumen

| Tipo    | Ejemplo                   | Dimensi√≥n | Forma       |
| ------- | ------------------------- | --------- | ----------- |
| Escalar | `5`                       | 0D        | `()`        |
| Vector  | `[1, 2, 3]`               | 1D        | `(3,)`      |
| Matriz  | `[[1, 2, 3], [4, 5, 6]]`  | 2D        | `(2, 3)`    |
| Tensor  | `[[[1, 2], [3, 4]], ...]` | 3D o m√°s  | `(2, 2, 2)` |

### Resumen

#### ¬øQu√© son las dimensiones y por qu√© son importantes en matrices y tensores?

Las dimensiones de los elementos como escalares, vectores, matrices y tensores son un concepto fundamental en el manejo de datos en Python. La comprensi√≥n de las dimensiones ayuda a realizar c√°lculos correctamente y a interpretar los resultados esperados. A menudo, aunque una operaci√≥n matem√°tica no est√© definida estrictamente, Python puede ejecutarla, lo que puede generar confusi√≥n. Por ello, entender c√≥mo funcionan las dimensiones es crucial para garantizar que las operaciones que ejecutamos son las correctas.

#### ¬øC√≥mo representamos las dimensiones en Python?

En Python, utilizamos librer√≠as para manejar las dimensiones y las operaciones sobre escalar, vector, matriz y tensor. Veamos algunos ejemplos:

#### Escalar

Un escalar es un elemento que no tiene dimensiones. Es simplemente un valor individual. Cuando verificamos su dimensi√≥n utilizando ciertas funciones en Python, el sistema nos indica que no posee este atributo.

#### Vector

Un vector se representa normalmente como un conjunto unidimensional de n√∫meros. Por ejemplo, un vector con elementos `[1, 2, 3]` se considera que tiene una dimensi√≥n con tres elementos. Cuando usamos la funci√≥n `len` para determinar su tama√±o, obtendremos el n√∫mero de elementos en la primera dimensi√≥n.

#### Matriz

Una matriz es una colecci√≥n bidimensional de n√∫meros. Por ejemplo, una matriz 2x2 tiene dos elementos en las filas y dos en las columnas. Utilizando la funci√≥n `len`, se retorna el n√∫mero de filas, mientras que `shape` proporciona una visi√≥n m√°s completa, retornando un arreglo tal como `[2, 2]` que indica filas y columnas.

#### C√≥digo de ejemplo para matrices:

```python
import numpy as np

matriz = np.array([[1, 2], [3, 4]])
print("Tama√±o del arreglo:", matriz.shape)  # Devuelve (2, 2)
```

#### Tensor

Los tensores son extensiones de las matrices a m√°s dimensiones. Un tensor 3x3x3 es un arreglo tridimensional, donde le primero '3' representa el n√∫mero de matrices en las primeras dos dimensiones. Este se utiliza com√∫nmente para representar datos complejos, como una serie de im√°genes que cambian con el tiempo, siendo √∫til en la representaci√≥n de videos.

#### Ejemplo de manejo de tensores:

```python
tensor = np.ones((3, 3, 3))
print("Forma del tensor:", tensor.shape)  # Devuelve (3, 3, 3)
```

#### Herramientas y funciones √∫tiles para trabajar con dimensiones

Al trabajar con Python, existen m√∫ltiples funciones que son √∫tiles para obtener informaci√≥n relacionada a las dimensiones:

- `len()`: Devuelve la cantidad de elementos en la primera dimensi√≥n.
- `shape`: Proporciona todas las dimensiones de un objeto como una tupla.
- `size`: Calcula el total de elementos multiplicando todas las dimensiones, √∫til para entender el tama√±o total de un objeto.

#### Diferencias entre `len()` y `shape`

Mientras que `len()` solo retiene el n√∫mero de elementos en la primera dimensi√≥n, `shape` ofrece un panorama completo de todas las dimensiones del objeto. Esto es crucial al tratar con objetos m√°s complejos como matrices y tensores, donde conocer todas las dimensiones nos permite asegurar que las operaciones que implementamos son las correctas.

#### Consejos pr√°cticos para estudiantes

Al comenzar con matrices y tensores en Python:

1. Experimenta creando varios vectores, matrices y tensores para practicar la interpretaci√≥n de sus dimensiones.
2. Usa la funci√≥n `shape` en lugar de `len` para obtener informaci√≥n detallada sobre las dimensiones.
3. Realiza operaciones con estos elementos y nota c√≥mo cambian las dimensiones.
4. Ejerc√≠tate en casos de uso, como la representaci√≥n de un video mediante tensores, para familiarizarte con su aplicaci√≥n pr√°ctica.

Contin√∫a explorando y no dudes en experimentar. Las matem√°ticas y las definiciones pueden parecer complejas, pero con pr√°ctica y determinaci√≥n, dominar√°s el arte de las dimensiones en Python. ¬°Sigue adelante y descubre el fascinante mundo de la programaci√≥n y el procesamiento de datos!

## Transposici√≥n y Suma de Matrices en Python

¬°Perfecto! Vamos a ver c√≥mo realizar la **transposici√≥n** y la **suma de matrices** en Python utilizando `NumPy`, que es la librer√≠a m√°s com√∫n para trabajar con matrices y √°lgebra lineal.

### ‚úÖ 1. Transposici√≥n de una matriz

La **transposici√≥n** de una matriz invierte sus filas y columnas. En Python, puedes usar `.T` para hacer esto f√°cilmente.

### üìå Ejemplo:

```python
import numpy as np

# Definimos una matriz 2x3
A = np.array([[1, 2, 3],
              [4, 5, 6]])

# Transpuesta de A
A_T = A.T

print("Matriz A:")
print(A)
print("\nTranspuesta de A:")
print(A_T)
```

### ‚úÖ 2. Suma de matrices

Para **sumar dos matrices**, estas deben tener las mismas dimensiones.

### üìå Ejemplo:

```python
import numpy as np

# Matrices 2x2
A = np.array([[1, 2],
              [3, 4]])

B = np.array([[5, 6],
              [7, 8]])

# Suma de A y B
C = A + B

print("Matriz A:")
print(A)
print("\nMatriz B:")
print(B)
print("\nSuma A + B:")
print(C)
```

### ‚ö†Ô∏è Notas importantes:

* Ambas matrices deben tener **las mismas dimensiones** para poder sumarse.
* La transposici√≥n no cambia los valores, solo su **ubicaci√≥n** en filas y columnas.

## Suma de Matrices con Dimensiones Distintas usando Broadcasting

En **NumPy**, puedes sumar matrices con dimensiones distintas **usando broadcasting**, pero **solo si sus formas son compatibles**. Veamos c√≥mo funciona y luego un ejemplo claro.

### üìò Reglas de Broadcasting en NumPy

Dos dimensiones son **compatibles** si:

1. Son **iguales**, o
2. **Una de ellas es 1**

NumPy "extiende" autom√°ticamente la dimensi√≥n con tama√±o 1 para que coincida con la otra.

### üßÆ Ejemplo pr√°ctico

Sup√≥n que tienes:

```python
import numpy as np

A = np.array([[1, 2, 3],
              [4, 5, 6]])        # Forma (2, 3)

B = np.array([[10],
              [20]])             # Forma (2, 1)
```

La forma de `A` es `(2, 3)`
La forma de `B` es `(2, 1)`

‚úÖ Las dimensiones son compatibles:

* A: (2, **3**)
* B: (2, **1**) ‚Üí se "expande" a (2, 3)

Entonces puedes hacer:

```python
C = A + B
print(C)
```

**Resultado:**

```text
[[11 12 13]
 [24 25 26]]
```

### ‚ùå Ejemplo no compatible

```python
A = np.array([[1, 2, 3]])
B = np.array([[1, 2]])

# A.shape = (1, 3)
# B.shape = (1, 2)

# Esto generar√° un error porque las dimensiones 3 y 2 no son compatibles.
C = A + B  # ‚ùå ValueError
```

### ‚úÖ Usos t√≠picos de Broadcasting

* Sumar un **vector a una matriz** fila por fila o columna por columna.
* Operaciones entre **matrices y escalares**.
* Ajuste de dimensiones para datos en ML y ciencia de datos.

### Resumen

#### ¬øCu√°ndo es posible sumar matrices de dimensiones distintas?

En el apasionante mundo de la programaci√≥n y el an√°lisis num√©rico, sumar matrices de distintas dimensiones a menudo trae consigo desaf√≠os intrigantes. En esta clase, exploramos cu√°ndo y c√≥mo es posible llevar a cabo esta operaci√≥n, aplicando las reglas del broadcasting en arrays de Numpy, una librer√≠a muy √∫til en Python. Comprender el broadcasting es clave para expandir tus habilidades de manipulaci√≥n de matrices.

#### ¬øQu√© es el broadcasting en Numpy?

El broadcasting es un concepto esencial en Numpy que permite realizar operaciones aritm√©ticas en matrices de diferentes dimensiones. En esencia, Numpy extiende la matriz de menor dimensi√≥n para que coincida con la de mayor dimensi√≥n, siempre que ello sea posible siguiendo ciertas reglas. Esta capacidad aumenta significativamente la flexibilidad y eficiencia al trabajar con arrays.

#### ¬øPor qu√© numpy arroja error al sumar matrices y vectores no compatibles?

En ocasiones, nos vemos con la tarea de sumar un vector a una matriz. Supongamos que tenemos una matriz de dimensiones 3x2 y un vector de longitud 3. Numpy mostrar√° un error porque las dimensiones no coinciden para el broadcasting. La matriz de 3x2 necesita, al menos, un vector compatible que sea de longitud 2 (el n√∫mero de columnas) para extender el vector por filas.

#### ¬øC√≥mo solucionar errores de dimensiones en la suma?

Una soluci√≥n a este error es transponer la matriz cuando es posible. Cambiar las dimensiones de la matriz a 2x3, por ejemplo, permite sumar un vector de tres elementos. Este proceso funciona ya que, al transponer, la matriz y el vector se vuelven compatibles, permitiendo a Numpy extender el vector para sumar cada uno de sus elementos a las columnas de la matriz.

**Ejemplos de broadcasting**

#### ¬øC√≥mo funciona la adici√≥n de una matriz y un escalar?

Una aplicaci√≥n com√∫n de broadcasting es sumar un escalar a todas las posiciones de una matriz. Por ejemplo, sumar 42 a una matriz de 3x2 implica que Numpy internamente replica el escalar, efectuando la suma como si fuese un array de la misma dimensi√≥n que la matriz. El resultado es sencillo: cada elemento de la matriz original incrementa en valor.

Aqu√≠ te dejamos un ejemplo pr√°ctico:

```python
import numpy as np

# Definimos una matriz y un escalar
matriz = np.array([[1, 2], [3, 4], [5, 6]])
escalar = 42

# Suma de la matriz con el escalar aplicando broadcasting
resultado = matriz + escalar
print(resultado)
```

El c√≥digo demostrar√° c√≥mo cada elemento de la matriz se incrementa por el valor del escalar.

#### ¬øQu√© pasa cuando sumamos un vector a una matriz traspuesta?

Consideremos una matriz de 2x3 y un vector de longitud 3. Siguiendo las reglas del broadcasting, Numpy extender√° el vector para que coincida con las dimensiones de la matriz al sumar los tres elementos del vector a cada fila de la matriz.

**Ejemplo en acci√≥n:**

```python
# Definimos una matriz traspuesta y un vector
matriz_t = np.array([[1, 2, 3], [4, 5, 6]])
vector = np.array([10, 20, 30])

# Suma de la matriz traspuesta con el vector usando broadcasting
resultado = matriz_t + vector
print(resultado)
```

Aqu√≠ vemos c√≥mo, de manera efectiva, cada elemento del vector se adiciona a sus respectivas filas.

#### ¬øC√≥mo practicar el concepto de broadcasting?

Un buen ejercicio para consolidar lo aprendido es tomar un vector de cinco elementos y sumarlo a una matriz de 5x5. Esto no solo fortalecer√° tu comprensi√≥n del broadcasting, sino que tambi√©n mejorar√° tu destreza en el uso de Numpy. ¬°No dudes en experimentar y ver√°s que las posibilidades son inmensas!

La exploraci√≥n constante te permitir√° profundizar tu conocimiento y dominar este potente recurso. Sigue practicando y adentr√°ndote en el an√°lisis de datos con confianza y curiosidad. ¬°Estoy seguro de que lo lograr√°s con √©xito!

## Producto Interno: Definici√≥n y Ejemplos Pr√°cticos

### üìò ¬øQu√© es el Producto Interno?

El **producto interno** (tambi√©n llamado **producto punto** o **dot product**) es una operaci√≥n algebraica entre dos **vectores del mismo tama√±o** que produce un **escalar**.

### üßÆ F√≥rmula

Si tienes dos vectores:

$$
\vec{a} = [a_1, a_2, ..., a_n] \quad \text{y} \quad \vec{b} = [b_1, b_2, ..., b_n]
$$

El **producto interno** se calcula como:

$$
\vec{a} \cdot \vec{b} = a_1 b_1 + a_2 b_2 + \dots + a_n b_n
$$

### ‚úÖ Ejemplo Manual

$$
\vec{a} = [2, 3] \quad \vec{b} = [4, 1]
$$

$$
\vec{a} \cdot \vec{b} = 2 \cdot 4 + 3 \cdot 1 = 8 + 3 = 11
$$

### üêç Ejemplo en Python

```python
import numpy as np

a = np.array([2, 3])
b = np.array([4, 1])

producto_interno = np.dot(a, b)
print(producto_interno)  # Output: 11
```

Tambi√©n puedes usar:

```python
producto_interno = a @ b
```

### üìê Interpretaci√≥n Geom√©trica

El producto interno tambi√©n se puede interpretar como:

$$
\vec{a} \cdot \vec{b} = \|\vec{a}\| \|\vec{b}\| \cos(\theta)
$$

Donde:

* $\|\vec{a}\|$ y $\|\vec{b}\|$ son las normas (magnitudes) de los vectores.
* $\theta$ es el √°ngulo entre ellos.

üî∏ Si el producto interno = 0 ‚Üí los vectores son **ortogonales** (perpendiculares).

### üìä Usos Pr√°cticos

* **√Ålgebra Lineal:** proyecciones, ortogonalidad.
* **Machine Learning:** c√°lculo de similitud de vectores (por ejemplo, en **cosine similarity**).
* **Gr√°ficos 3D:** detecci√≥n de √°ngulos entre vectores de fuerza, direcci√≥n, etc.

### Resumen

#### ¬øQu√© es el producto interno y c√≥mo se diferencia de la multiplicaci√≥n de matrices?

El producto interno es fundamental en √°lgebra lineal y se distingue de la simple multiplicaci√≥n de una matriz por un vector, ya que implica no solo una operaci√≥n matem√°tica sino tambi√©n una comprensi√≥n m√°s profunda de c√≥mo interact√∫an los vectores en el espacio. Mientras que la multiplicaci√≥n est√°ndar de matrices y vectores proporciona una nueva matriz, el producto interno resulta en un vector de una dimensi√≥n espec√≠fica. ¬øQuieres conocer m√°s a fondo estas operaciones y entender c√≥mo utilizarlas en tus proyectos? ¬°Acomp√°√±ame mientras desglosamos el proceso!

#### Multiplicaci√≥n de matriz por vector

Cuando multiplicamos una matriz por un vector, el resultado es otra matriz si se cumplen las condiciones de tama√±o. Por ejemplo, considere una matriz de tama√±o 3x2 y un vector de dimensi√≥n 2. Al multiplicarlos, obtienes una nueva matriz que mantiene ciertas propiedades originales mientras multiplica cada componente del vector con las columnas correspondientes de la matriz.

```python
# Ejemplo c√≥digo para multiplicaci√≥n de matriz por vector
import numpy as np

# Definiendo la matriz y el vector
matriz = np.array([[1, 2], [3, 4], [5, 6]])
vector = np.array([2, 3])

# Multiplicaci√≥n de matriz por vector
resultado_matriz = np.dot(matriz, vector)
print(resultado_matriz)
```

En este ejemplo, el proceso de "broadcasting" toma lugar al multiplicar la primera columna por 2 y la segunda columna por 3, obteniendo resultados individuales que se suman.

#### ¬øC√≥mo se realiza el producto interno de una matriz y un vector?

El producto interno, tambi√©n conocido como "dot product" o "producto escalar", implica multiplicar las correspondientes entradas de matriz y vector y luego sumar estos productos. A diferencia de la multiplicaci√≥n de matriz, el resultado es un vector donde cada elemento es una suma de productos diferentes.

```python
# Ejemplo c√≥digo para producto interno
resultado_producto_interno = np.inner(matriz, vector)
print(resultado_producto_interno)
```

Aqu√≠, cada elemento del resultado es calculado multiplicando los elementos correspondientes del vector y la matriz, luego sum√°ndolos. Esto da un resultado espec√≠fico basado en las dimensiones del vector y del n√∫mero de filas en la matriz.

#### Consideraciones y ejercicios para profundizar

- **Diferentes m√©todos**: Hay dos formas principales de realizar el producto interno: calcul√°ndolo directamente al multiplicar el vector y la matriz, y utilizando funciones de bibliotecas como `numpy` que ofrecen funciones definidas como `np.dot()`.
- **Prueba interactividad**: Multiplica una matriz por un vector y luego invierte el orden: multiplicar el vector por la matriz. Observando los resultados, notar√°s c√≥mo var√≠an o permanecen iguales bajo ciertas condiciones.
- **Participaci√≥n en discusiones**: Aprovecha los foros de discusi√≥n para resolver dudas y compartir hallazgos con otros estudiantes. La interacci√≥n y el intercambio de ideas enriquece el aprendizaje.

Este conocimiento no solo es esencial para quienes quieren adentrarse en campos como el machine learning o data science, sino que tambi√©n es una habilidad clave en la programaci√≥n y la resoluci√≥n de problemas matem√°ticos complejos. ¬°Sigue explorando y no dudes en preguntar lo que necesites! Nos vemos en la pr√≥xima clase.

## Producto Interno entre Dos Matrices: Definici√≥n y C√°lculo

### üìò ¬øQu√© es el Producto Interno entre Dos Matrices?

En √°lgebra lineal, el **producto interno entre matrices** generalmente **no se aplica directamente como en vectores**. Sin embargo, existen dos conceptos similares:

### 1. üîÅ **Producto Matricial (Multiplicaci√≥n de Matrices)**

Si tienes dos matrices $A \in \mathbb{R}^{m \times n}$ y $B \in \mathbb{R}^{n \times p}$, el **producto matricial** $C = A \cdot B$ es una **matriz $m \times p$**.

Este no es un producto interno cl√°sico, pero es el producto m√°s com√∫n entre matrices.

üìå Ejemplo:

```python
import numpy as np

A = np.array([[1, 2],
              [3, 4]])

B = np.array([[5, 6],
              [7, 8]])

C = np.dot(A, B)
print(C)
```

üßÆ Resultado:

```
[[19 22]
 [43 50]]
```

### 2. üî∏ **Producto Interno como Escalar (Frobenius Inner Product)**

Cuando **ambas matrices son del mismo tama√±o**, el producto interno puede definirse como:

$$
\langle A, B \rangle = \sum_{i,j} A_{ij} \cdot B_{ij}
$$

Este es el **producto interno de Frobenius**, y da como resultado un **escalar**.

üìå Ejemplo:

```python
import numpy as np

A = np.array([[1, 2],
              [3, 4]])

B = np.array([[5, 6],
              [7, 8]])

producto_interno = np.sum(A * B)
print(producto_interno)
```

üßÆ Resultado:

```
70  # = 1*5 + 2*6 + 3*7 + 4*8
```

### üìä ¬øCu√°ndo usar cada uno?

| Contexto                                 | M√©todo                                          |
| ---------------------------------------- | ----------------------------------------------- |
| Transformaci√≥n lineal o redes neuronales | `np.dot(A, B)` o `A @ B`                        |
| Similitud o comparaci√≥n de matrices      | `np.sum(A * B)` (producto interno de Frobenius) |

### Resumen

#### ¬øC√≥mo se define el producto interno entre matrices?

El producto interno entre matrices es uno de los conceptos m√°s √∫tiles y fascinantes de la √°lgebra lineal. Nos permite combinar matrices de manera que se puedan aprovechar sus propiedades para c√°lculos m√°s complejos. En particular, el producto interno entre dos matrices est√° definido cuando el n√∫mero de columnas de la primera matriz es id√©ntico al n√∫mero de filas de la segunda. Esto se traduce en que las dimensiones de las matrices involucradas deben estar alineadas adecuadamente.

Esta operaci√≥n es esencial en campos como la computaci√≥n, donde se utilizan matrices para representar datos y para realizar c√°lculos avanzados de manera eficiente. Veamos c√≥mo se aplica este concepto a trav√©s de un ejemplo pr√°ctico.

#### ¬øC√≥mo aplicamos el producto interno a dos matrices?

Para ilustrar el producto interno, consideremos las matrices `A` y `B`. La matriz `A` es de dimensiones 4x3 y la matriz `B` es de dimensiones 3x2. En este caso, el producto interno (`A \cdot B`) es posible, pero el producto (`B \cdot A`) no lo es.

#### Paso a paso del producto (A \cdot B)

La operaci√≥n (A \cdot B) es posible porque el n√∫mero de columnas de `A` coincide con el n√∫mero de filas de `B`, es decir, 3. Esta coincidencia nos permite realizar el producto interno. Echemos un vistazo al proceso:

1. **Multi-step Calculation**: Se multiplica cada elemento de la fila de `A` por el elemento correspondiente de la columna de `B`, y luego se suman estos productos.

3. **Iteraci√≥n por filas y columnas**: Se repite el proceso para cada fila de `A` y cada columna de `B` hasta llenar una nueva matriz resultante. La matriz resultante tendr√° las dimensiones ((4x2)), derivadas del n√∫mero de filas de A y el n√∫mero de columnas de B.

El resultado nos da una nueva matriz cuya dimensi√≥n es 4x2, que resulta de esta multiplicaci√≥n de matrices individuales.

```python
# Ejemplo de matrices A y B
import numpy as np

A = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9], [10, 11, 12]])
B = np.array([[2, 3], [5, 7], [11, 13]])

# Realizando el producto interno
C = np.dot(A, B)

print(C)
```

Este c√≥digo en Python ilustra c√≥mo se calcula el producto interno usando la biblioteca `NumPy`, que simplifica el manejo de operaciones matriciales. Este ejemplo resulta en una matriz resultante de 4x2, conforme a nuestras expectativas.

#### ¬øQu√© sucede cuando el producto interno no est√° definido?

Intentar calcular el producto interno de (B \cdot A) nos lleva a un error porque las dimensiones correspondientes no coinciden. En lugar de corregir el c√°lculo, detengamos un momento para entender la raz√≥n detr√°s del error.

El problema radica en que el n√∫mero de columnas de `B` (que es 2) no coincide con el n√∫mero de filas de `A` (que es 4). Esto implica que el producto no est√° definido bajo las reglas del √°lgebra lineal, lo cual suele conducir a errores en los sistemas de programaci√≥n, indic√°ndonos que las dimensiones no son compatibles.

#### Consejos pr√°cticos para evitar errores

- **Verificar dimensiones**: Siempre verifica que las dimensiones de las matrices est√©n alineadas antes de intentar calcular el producto interno.
- **Uso de herramientas**: Emplear herramientas como NumPy, ya que proporcionan funciones para realizar estas comprobaciones autom√°ticamente y manejar matrices grandes de manera eficiente.
- **Comprender los resultados**: Aseg√∫rate de que el tama√±o de la matriz resultante tenga sentido dentro del contexto de tu problema.

Te animo a que pongas en pr√°ctica este conocimiento calculando el resultado del producto interno de las matrices proporcionadas y completando los valores faltantes en el ejercicio propuesto. ¬°Contin√∫a explorando y desarrollando tus habilidades de √°lgebra lineal!

## Propiedades del Producto Interno en √Ålgebra Lineal

Claro, aqu√≠ tienes un resumen claro y √∫til de las **propiedades del producto interno** en √°lgebra lineal:

### üî∑ Propiedades del Producto Interno

Sea $\vec{u}, \vec{v}, \vec{w} \in \mathbb{R}^n$ y $\alpha \in \mathbb{R}$, el **producto interno** (tambi√©n llamado **producto punto**) se denota:

$$
\langle \vec{u}, \vec{v} \rangle = \sum_{i=1}^n u_i v_i
$$

### ‚úÖ 1. **Conmutatividad**

$$
\langle \vec{u}, \vec{v} \rangle = \langle \vec{v}, \vec{u} \rangle
$$

### ‚úÖ 2. **Bilinealidad** (Linealidad en cada componente)

$$
\langle \alpha \vec{u}, \vec{v} \rangle = \alpha \langle \vec{u}, \vec{v} \rangle
$$

$$
\langle \vec{u} + \vec{w}, \vec{v} \rangle = \langle \vec{u}, \vec{v} \rangle + \langle \vec{w}, \vec{v} \rangle
$$

### ‚úÖ 3. **Positividad**

$$
\langle \vec{v}, \vec{v} \rangle \geq 0
$$

### ‚úÖ 4. **Definida Positiva**

$$
\langle \vec{v}, \vec{v} \rangle = 0 \iff \vec{v} = \vec{0}
$$

### ‚úÖ 5. **Relaci√≥n con la Norma**

La **norma (longitud)** de un vector es:

$$
\| \vec{v} \| = \sqrt{ \langle \vec{v}, \vec{v} \rangle }
$$

### ‚úÖ 6. **Ortogonalidad**

Dos vectores son **ortogonales** (perpendiculares) si:

$$
\langle \vec{u}, \vec{v} \rangle = 0
$$

### ‚úÖ 7. **Desigualdad de Cauchy-Schwarz**

$$
|\langle \vec{u}, \vec{v} \rangle| \leq \| \vec{u} \| \cdot \| \vec{v} \|
$$

### ‚úÖ 8. **Proyecci√≥n Ortogonal**

La proyecci√≥n de $\vec{u}$ sobre $\vec{v}$ es:

$$
\text{proj}_{\vec{v}} \vec{u} = \frac{ \langle \vec{u}, \vec{v} \rangle }{ \langle \vec{v}, \vec{v} \rangle } \vec{v}
$$

### Resumen

#### ¬øC√≥mo entender las propiedades del producto interno?

El producto interno es una operaci√≥n fundamental en el √°lgebra lineal que no solo nos permite calcular magnitudes, sino tambi√©n entender relaciones geom√©tricas entre vectores. Resulta enriquecedor descubrir sus propiedades, ya que nos facilitan el manejo y manipulaci√≥n de matrices y vectores. A trav√©s de ejemplos pr√°cticos, podemos visualizar c√≥mo estas propiedades se manifiestan, lo que fortalece nuestra comprensi√≥n te√≥rica y pr√°ctica. Analicemos a fondo estas propiedades esenciales del producto interno.

#### ¬øQu√© es la propiedad asociativa?

La propiedad asociativa es una caracter√≠stica crucial en operaciones matem√°ticas que nos indica que el orden en el cual agrupamos las operaciones no afecta el resultado. En el contexto del producto interno, si tenemos matrices A, B y C, esta propiedad nos asegura que:

`[ (A \cdot B) \cdot C = A \cdot (B \cdot C) ]`

Ahora, aunque en el √°lgebra lineal la propiedad asociativa tal cual se aplica a operaciones de escalar y no directamente a matrices, s√≠ aplica en la combinaci√≥n de productos internos, como una forma de redistribuir la multiplicaci√≥n en operaciones m√°s complejas.

En c√≥digo, comprobamos la propiedad asociativa as√≠:

```python
import numpy as np

# Definimos matrices A, B, C
A = np.array([[1, 2], [3, 4]])
B = np.array([[5, 6], [7, 8]])
C = np.array([[9, 10], [11, 12]])

# Verificando la propiedad asociativa
resultado_1 = np.dot(np.dot(A, B), C)
resultado_2 = np.dot(A, np.dot(B, C))

print(resultado_1)
print(resultado_2)
```

Las salidas deber√≠an coincidir, lo cual nos muestra la propiedad asociativa en acci√≥n.

#### ¬øC√≥mo comprobar la propiedad distributiva?

La propiedad distributiva nos indica que distribuir un producto sobre una suma es equivalente a realizar cada operaci√≥n por separado y luego sumar los resultados. Matem√°ticamente, para el producto interno, se expresa como:

`[ A \cdot (B + C) = A \cdot B + A \cdot C ]`

Este concepto se aplica al distribuir la multiplicaci√≥n de una matriz por la suma de dos matrices, otorgando fluidez y flexibilidad en los c√°lculos.

Veamos c√≥mo probar esta propiedad usando c√≥digo de Python:

```python
D = B + C

# Verificar propiedad distributiva
distributiva_1 = np.dot(A, D)
distributiva_2 = np.dot(A, B) + np.dot(A, C)

print(distributiva_1)
print(distributiva_2)
```

Si ambas matrices resultantes son id√©nticas, hemos confirmado la propiedad distributiva.

#### ¬øEl producto interno es conmutativo?

Podr√≠amos estar tentados a asumir que la conmutatividad, una propiedad esencial en la multiplicaci√≥n escalar, se aplica igualmente al producto interno. Sin embargo, en √°lgebra de matrices, esto no siempre es el caso. Para matrices, en general no es verdad que:

`[ A \cdot B = B \cdot A ]`

No obstante, en el caso espec√≠fico de productos de vectores, podemos observar esta propiedad. Consideremos un ejemplo con vectores:

```python
# Definici√≥n de vectores
v1 = np.array([2, 7])
v2 = np.array([3, 5])

# C√°lculo del producto interno
producto_1 = np.dot(v1, v2)
producto_2 = np.dot(v2, v1)

print(producto_1) # Debe imprimir 41
print(producto_2) # Debe imprimir 41
```

Aqu√≠, vemos que el producto interno de vectores s√≠ es conmutativo, lo cual no es lo mismo en matrices generales.

#### ¬øQu√© ejercicios pr√°cticos puedo hacer?

Practicar con ejemplos es vital para internalizar estos conceptos. Te animo a pensar en dos matrices de dimensiones distintas para las cuales puedas calcular el Producto Interno, pero no puedas invertir sus roles. Como una pista, podemos recordar c√≥mo las dimensiones deben ser compatibles para que la multiplicaci√≥n sea v√°lida. Comparte tus hallazgos en los foros de discusi√≥n y sigue explorando estas fascinantes propiedades matem√°ticas en tus estudios de √°lgebra lineal.

## Transposici√≥n y Producto Interno de Matrices

¬°Claro! Vamos a ver **c√≥mo se realiza la transposici√≥n y el producto interno de matrices**, tanto desde el punto de vista te√≥rico como pr√°ctico en Python.

### üîÅ Transposici√≥n de Matrices

La **transposici√≥n** de una matriz $A$ se denota como $A^T$ y consiste en convertir las filas en columnas y viceversa.

### Ejemplo:

Si:

$$
A = \begin{bmatrix}
1 & 2 \\
3 & 4 \\
\end{bmatrix}
\quad \Rightarrow \quad
A^T = \begin{bmatrix}
1 & 3 \\
2 & 4 \\
\end{bmatrix}
$$

### En Python:

```python
import numpy as np

A = np.array([[1, 2],
              [3, 4]])

A_transpuesta = A.T
print("Transpuesta de A:\n", A_transpuesta)
```

### üî∑ Producto Interno de Matrices (Producto Matricial)

El **producto interno (o producto punto)** entre matrices tambi√©n puede interpretarse como **producto matricial** cuando se cumple la condici√≥n de dimensiones.

Si $A$ es de tama√±o $m \times n$ y $B$ de tama√±o $n \times p$, entonces:

$$
C = A \cdot B \quad \text{tendr√° tama√±o} \quad m \times p
$$

### Ejemplo:

$$
A = \begin{bmatrix}1 & 2\end{bmatrix},\quad B = \begin{bmatrix}3 \\ 4\end{bmatrix}
\quad \Rightarrow \quad A \cdot B = 1\cdot3 + 2\cdot4 = 11
$$

### En Python:

```python
A = np.array([[1, 2]])
B = np.array([[3],
              [4]])

producto_interno = np.dot(A, B)
print("Producto interno de A y B:\n", producto_interno)
```

### üß† Nota:

* Si est√°s trabajando con **vectores**, `np.dot()` o `np.inner()` puede ser usado.
* Para **matrices**, tambi√©n puedes usar `@` o `np.matmul()` para claridad y compatibilidad.

### Resumen

#### ¬øQu√© es la transposici√≥n de un producto de matrices?

La transposici√≥n de matrices es un concepto central en √°lgebra lineal. Al operar con matrices, tanto la forma en que se multiplican como su transposici√≥n juegan roles cruciales. Hoy exploramos c√≥mo se interrelacionan estas transposiciones dentro del producto interno de matrices. La propiedad que definiremos es: si tenemos una matriz A multiplicada internamente con B, su transposici√≥n es igual al producto de B transpuesta con A transpuesta. Esto es expresado matem√°ticamente como:

`(AB)^T = B^T A^T`

Esta propiedad es vital al trabajar en √°lgebra lineal, ya que permite una manipulaci√≥n m√°s intuitiva y vers√°til de las matrices, trat√°ndolas casi como si fueran n√∫meros.

#### ¬øQu√© implicaciones tiene esta propiedad en el trabajo con matrices?

La versatilidad que otorga esta propiedad en operaciones matriciales es significativa:

- **Flexibilidad Operativ**a: Podemos organizar las operaciones de una manera que facilite los c√°lculos, porque la transposici√≥n nos permite cambiar el orden sin alterar el resultado final.

- **Optimizaci√≥n de C√°lculos**: En lugar de recalcular completamente los sistemas de ecuaciones, el uso correcto de transposiciones ahorra tiempo y esfuerzo, simplificando el proceso.

- **Jugabilidad Matem√°tica**: Al aplicar dos veces la transposici√≥n a una matriz, la devolvemos a su forma original. Esto permite experimentar con las transformaciones y, de ser necesario, revertirlas con facilidad.

```python
# Ejemplo b√°sico de transposici√≥n en Python usando NumPy
import numpy as np

A = np.array([[1, 2], [3, 4], [5, 6]])  # Matriz 3x2
B = np.array([[7, 8], [9, 10]])         # Matriz 2x2

# Producto interno y su transposici√≥n
product_transposed = np.matmul(A, B).T
B_transpose_A_transpose = np.matmul(B.T, A.T)

print("Transposici√≥n del producto interno:", product_transposed)
print("Producto de transposiciones:", B_transpose_A_transpose)
```

#### ¬øC√≥mo verificar la igualdad de estas operaciones?

Verificar la equivalencia entre ( (AB)^T ) y ( B^T A^T ) te acerca un paso m√°s a tratar matrices como si fueran n√∫meros. Con la ayuda de herramientas como NumPy en Python, el proceso se facilita:

- **Comprobaci√≥n de Igualdad**: Mediante funciones que comparan matrices, como numpy.allclose(), puedes certificar que el resultado final de ambas operaciones es el mismo.

- **Exploraci√≥n Pr√°ctica**: Al comenzar con matrices A y B de dimensiones adecuadas (como A de 3x2 y B de 2x2 en el ejemplo), puedes aplicar las operaciones y verificar la igualdad de resultados, reforzando la comprensi√≥n te√≥rica con la pr√°ctica.

- **Aplicaci√≥n en Sistemas Lineales**: Esta propiedad resulta √∫til al resolver sistemas de ecuaciones lineales, reduciendo la complejidad al manejar las matrices involucradas.

```python
# Verificaci√≥n de igualdad entre las operaciones
equal_check = np.allclose(product_transposed, B_transpose_A_transpose)

print("Las operaciones son iguales:", equal_check)
```

Continuar explorando y practicando estos conceptos profundizar√° tu comprensi√≥n y habilidad en √°lgebra lineal, prepar√°ndote para abordar sistemas de ecuaciones complejos con confianza y eficiencia. ¬°Te animo a sumergirte m√°s en este apasionante mundo matem√°tico!

## Comprobaci√≥n gr√°fica de sistemas de ecuaciones lineales

¬°Perfecto! Visualizar **sistemas de ecuaciones lineales** gr√°ficamente es una excelente forma de entender su soluci√≥n. Te mostrar√© c√≥mo hacerlo paso a paso con un ejemplo usando **Python** y **Matplotlib**.

### üéØ Objetivo:

Graficar dos ecuaciones lineales y mostrar su **punto de intersecci√≥n**, que representa la **soluci√≥n del sistema**.

### üìå Ejemplo de Sistema de Ecuaciones:

$$
\text{Ecuaci√≥n 1: } y = 2x + 1  
$$

$$
\text{Ecuaci√≥n 2: } y = -x + 4
$$

### üßÆ Paso a Paso en Python:

```python
import numpy as np
import matplotlib.pyplot as plt

# Valores de x
x = np.linspace(-10, 10, 200)

# Ecuaciones
y1 = 2 * x + 1      # y = 2x + 1
y2 = -1 * x + 4     # y = -x + 4

# Intersecci√≥n (resolviendo el sistema de ecuaciones)
# Igualamos: 2x + 1 = -x + 4 => 3x = 3 => x = 1, y = 2(1) + 1 = 3
x_intersect = 1
y_intersect = 3

# Gr√°fico
plt.figure(figsize=(8,6))
plt.plot(x, y1, label='y = 2x + 1')
plt.plot(x, y2, label='y = -x + 4')
plt.plot(x_intersect, y_intersect, 'ro', label='Intersecci√≥n (1,3)')

plt.axhline(0, color='black', linewidth=0.5)
plt.axvline(0, color='black', linewidth=0.5)
plt.grid(True)
plt.legend()
plt.title('Soluci√≥n Gr√°fica de un Sistema de Ecuaciones Lineales')
plt.xlabel('x')
plt.ylabel('y')
plt.show()
```

### üß† Interpretaci√≥n:

* Cada l√≠nea representa una ecuaci√≥n lineal.
* El **punto rojo** muestra la soluci√≥n del sistema: el punto donde ambas rectas se cruzan.
* Si no se cruzan ‚Üí el sistema **no tiene soluci√≥n (inconsistente)**.
* Si son la misma recta ‚Üí **infinitas soluciones**.

## Matrices Identidad, Inversa y Singular: Propiedades y C√°lculo

¬°Perfecto! Este es un tema central en **√°lgebra lineal**, con aplicaciones directas en sistemas de ecuaciones, optimizaci√≥n, computaci√≥n gr√°fica y machine learning. Vamos a revisar las **propiedades clave** y c√≥mo se calculan:

### üî∑ 1. **Matriz Identidad (ùêº)**

### üîπ Definici√≥n:

Una **matriz cuadrada** donde todos los elementos de la **diagonal principal son 1** y los dem√°s son 0.

### üîπ Propiedades:

* $A \cdot I = A$
* $I \cdot A = A$
* $I^{-1} = I$
* Es **la unidad** de la multiplicaci√≥n matricial.

### üîπ Ejemplo en Python:

```python
import numpy as np

I = np.eye(3)
print(I)
```

### üî∑ 2. **Matriz Inversa (ùê¥‚Åª¬π)**

### üîπ Definici√≥n:

La matriz inversa de $A$ es otra matriz $A^{-1}$ tal que:

$$
A \cdot A^{-1} = I
$$

### üîπ Solo existe si:

* $A$ es **cuadrada**.
* $\det(A) \ne 0$ ‚Üí No es singular.

### üîπ Propiedades:

* $(A^{-1})^{-1} = A$
* $(AB)^{-1} = B^{-1}A^{-1}$
* $(A^T)^{-1} = (A^{-1})^T$

### üîπ En Python:

```python
A = np.array([[2, 1], [5, 3]])
A_inv = np.linalg.inv(A)
print(A_inv)
```

### üî∑ 3. **Matriz Singular**

### üîπ Definici√≥n:

Una matriz cuadrada que **no tiene inversa**.

### üîπ Ocurre cuando:

* $\det(A) = 0$
* Sus filas o columnas son **linealmente dependientes**.

### üîπ Ejemplo:

```python
A = np.array([[2, 4], [1, 2]])  # Segunda fila es m√∫ltiplo de la primera
print(np.linalg.det(A))  # Resultado: 0 ‚Üí matriz singular
```

### üî∑ 4. **C√°lculo R√°pido del Determinante**

Usado para saber si la matriz tiene inversa.

```python
np.linalg.det(A)  # Si es 0, es singular
```

### üìò Extra: Resolver un Sistema con la Inversa

$$
AX = B \Rightarrow X = A^{-1}B
$$

```python
A = np.array([[2, 1], [5, 3]])
B = np.array([[5], [13]])
X = np.linalg.inv(A).dot(B)
print(X)
```

### Resumen

#### ¬øQu√© son las matrices especiales y sus caracter√≠sticas?

Las matrices especiales juegan un papel crucial en el √°lgebra lineal y poseen propiedades √∫nicas que las hacen destacarse. Entre ellas, encontramos la matriz identidad, la matriz inversa y la matriz singular. Entender las peculiaridades de cada una es esencial para diversos c√°lculos y aplicaciones en matem√°ticas avanzadas.

#### ¬øQu√© es la matriz identidad?

La matriz identidad es una transformaci√≥n neutra dentro del contexto de las matrices. En esencia, es una matriz cuadrada en la que todos los elementos de la diagonal principal son unos, y todos los otros elementos son ceros. La funci√≥n eye de bibliotecas como NumPy nos permite generarla f√°cilmente. Su peculiaridad es que, al multiplicarla por cualquier vector, este permanece inalterado, similar a como el n√∫mero uno es el elemento neutro en la multiplicaci√≥n de n√∫meros.

```python
import numpy as np

# Generamos una matriz identidad de dimensi√≥n 3x3
identidad = np.eye(3)
print(identidad)
```

#### ¬øQu√© representa la matriz inversa?

La matriz inversa cumple una funci√≥n similar al concepto de inverso en la multiplicaci√≥n usual: cuando una matriz ( A ) se multiplica por su inversa ( A^{-1} ), obtenemos la matriz identidad. Para calcularla, utilizamos funciones espec√≠ficas, como `np.linalg.inv` de NumPy.

```python
# Definimos una matriz 3x3
A = np.array([[1, 0, 0], [0, 1, 0], [0, 0, 1]])

# Calculamos la inversa de la matriz A
A_inversa = np.linalg.inv(A)
print(A_inversa)
```

Sin embargo, es importante destacar que no todas las matrices tienen una inversa. Generalmente, solo las matrices cuadradas que cumplen ciertas condiciones pueden tener esta propiedad.

#### ¬øPor qu√© algunas matrices son singulares?

La matriz singular es especial porque carece de inversa. Esto sucede cuando determinantes de la matriz son cero, indicando que la matriz es "degenerada". Intentar calcular la inversa de una matriz singular generar√° un error, como en el siguiente ejemplo:

```python
# Intentamos calcular la inversa de una matriz singular
try:
    singular = np.array([[1, 2], [2, 4]])
    singular_inversa = np.linalg.inv(singular)
except np.linalg.LinAlgError:
    print("Error: Matrix is singular")
```

#### ¬øC√≥mo resolver sistemas de ecuaciones lineales usando matrices?

Las matrices son fundamentales en la resoluci√≥n de sistemas de ecuaciones lineales. Al tener la matriz inversa de un sistema ( A \times X = B ), podemos multiplicar ambos lados por ( A^{-1} ) para resolver ( X ).

```python
# Supongamos que tenemos un sistema de ecuaciones
A = np.array([[3, 1], [1, 2]])
B = np.array([9, 8])

# Calculamos la inversa de A
A_inversa = np.linalg.inv(A)

# Resolvemos para X
X = np.dot(A_inversa, B)
print(X)
```

Contar con la matriz inversa permite implementar algoritmos eficientes para soluciones exactas de sistemas lineales, lo que es de gran utilidad en campos como la ingenier√≠a y las ciencias computacionales. Con estas herramientas, tu entendimiento y manejo del √°lgebra lineal se vuelve potente y vers√°til. ¬°Contin√∫a explorando y profundizando en el fascinante mundo de las matem√°ticas!

## Soluci√≥n de Sistemas Lineales usando la Inversa de una Matriz

¬°Excelente! Resolver sistemas de ecuaciones lineales usando la **inversa de una matriz** es una t√©cnica cl√°sica del √°lgebra lineal cuando el sistema se puede representar como:

$$
AX = B
$$

Donde:

* $A$ es la **matriz de coeficientes** (cuadrada).
* $X$ es el **vector columna** de inc√≥gnitas.
* $B$ es el **vector columna** de resultados.

### ‚úÖ Paso a Paso para Resolver $AX = B$ con la Inversa

### üìå 1. Verifica que $A$ sea **cuadrada** y **no singular** (determinante ‚â† 0)

### üìå 2. Calcula la **inversa de A**: $A^{-1}$

### üìå 3. Multiplica ambos lados por $A^{-1}$:

$$
A^{-1}AX = A^{-1}B \Rightarrow IX = A^{-1}B \Rightarrow X = A^{-1}B
$$

### üî¢ Ejemplo Pr√°ctico en Python

Supongamos el siguiente sistema:

$$
\begin{cases}
2x + y = 5 \\
5x + 3y = 13
\end{cases}
$$

Representamos el sistema:

```python
import numpy as np

# Matriz de coeficientes A
A = np.array([[2, 1],
              [5, 3]])

# Vector de resultados B
B = np.array([[5],
              [13]])

# Verificamos si A tiene inversa
if np.linalg.det(A) != 0:
    A_inv = np.linalg.inv(A)
    X = A_inv @ B
    print("Soluci√≥n del sistema (x, y):")
    print(X)
else:
    print("La matriz A es singular. No tiene inversa.")
```

### üìå Resultado

El c√≥digo te devuelve el valor de $x$ y $y$ como soluci√≥n del sistema.

### ‚ö†Ô∏è Consideraciones

* Este m√©todo **no es el m√°s eficiente** computacionalmente para grandes sistemas.
* Es ideal para **an√°lisis te√≥rico o sistemas peque√±os**.
* Para sistemas grandes o mal condicionados, se prefiere `np.linalg.solve(A, B)`.

### üîÑ Alternativa m√°s eficiente:

```python
X = np.linalg.solve(A, B)  # Resuelve directamente sin calcular la inversa
```

### Resumen

#### ¬øC√≥mo utilizar la matriz inversa para resolver un sistema de ecuaciones lineales?

Las matrices inversas son herramientas poderosas en √°lgebra lineal que nos permiten encontrar soluciones a sistemas de ecuaciones lineales. Imagina que tienes un sistema matem√°tico que resolver y deseas utilizar una matriz inversa; hacerlo podr√≠a simplificar mucho el proceso. Vamos a profundizar en c√≥mo se hace esto paso a paso usando Python.

#### ¬øC√≥mo definir matrices y vectores en Python?

Primero, definimos nuestras matrices y vectores utilizando la biblioteca NumPy, que es muy √∫til para el manejo de datos num√©ricos en Python. Para un sistema de ecuaciones sencillo, donde tenemos las ecuaciones (3x + y = 1) y (2x + y = 1), organizamos la matriz de coeficientes y el vector de resultados as√≠:

```python
import numpy as np

# Definici√≥n de la matriz A
A = np.array([[3, 1], [2, 1]])

# Definici√≥n del vector B
B = np.array([1, 1])
```

#### ¬øC√≥mo calcular la matriz inversa?

El siguiente paso es calcular la matriz inversa de (A). En √°lgebra lineal, si una matriz ( A ) tiene una inversa, significa que podemos multiplicarla por su inversa para obtener la matriz identidad. En Python:

```python
# Calcular la matriz inversa de A
inversa_A = np.linalg.inv(A)
```

#### ¬øC√≥mo resolver el sistema de ecuaciones?

Una vez obtenida la matriz inversa, podemos encontrar la soluci√≥n ( X ) multiplicando esta inversa por el vector ( B ):

```python
# Calcular el vector soluci√≥n X
X = np.dot(inversa_A, B)
```

El resultado te dar√° los valores de ( x ) y ( y ) que solucionan el sistema. En nuestro caso, el vector ( X ) deber√≠a ser muy similar a ([0, 1]), lo que corresponde a ( x = 0 ) y ( y = 1 ).

#### ¬øQu√© pasa si cambiamos el vector de resultados?

Si cambias ( B ) para ver si la misma matriz inversa puede ayudarnos a resolver otra configuraci√≥n de resultados, tendr√≠as algo as√≠:

```python
# Nuevo vector B
B_nuevo = np.array([3, 7])

# Calcular el nuevo vector soluci√≥n X usando la misma inversa
X_nuevo = np.dot(inversa_A, B_nuevo)
```

Este enfoque te proporciona la soluci√≥n para cualquier vector ( B ) dado, siempre que los coeficientes de las variables en las ecuaciones permanezcan iguales.

#### ¬øCu√°les son las limitaciones del uso de matrices inversas?

Aunque resolver sistemas de ecuaciones lineales usando matrices inversas es conveniente, no es siempre eficiente debido a problemas num√©ricos que pueden surgir, especialmente cuando lidias con matrices grandes o mal condicionadas. A menudo, otras t√©cnicas como la eliminaci√≥n Gaussiana o m√©todos num√©ricos de aproximaci√≥n pueden ser m√°s adecuados.

#### ¬øPor qu√© es importante la pr√°ctica de m√©todos num√©ricos?

Los m√©todos num√©ricos se utilizan para encontrar soluciones aproximadas a ecuaciones y no dependen de las ineficiencias inherentes a las matrices inversas en representaciones computacionales. Saber cu√°ndo y c√≥mo utilizar diferentes m√©todos es esencial para quienes trabajan con √°lgebra lineal y problemas matem√°ticos complejos en la pr√°ctica.

¬øTe interesa seguir explorando esta rica √°rea de las matem√°ticas computacionales? ¬°Sigue practicando, afina tus habilidades y aprovecha al m√°ximo estas herramientas fascinantes!

## Sistemas de Ecuaciones: Soluciones √önicas, M√∫ltiples o Ninguna

En **√Ålgebra**, un **sistema de ecuaciones** es un conjunto de dos o m√°s ecuaciones con dos o m√°s inc√≥gnitas. Las soluciones del sistema representan los valores de las inc√≥gnitas que **satisfacen todas las ecuaciones simult√°neamente**. Seg√∫n las caracter√≠sticas de las rectas (en el caso de sistemas lineales de dos variables), los sistemas pueden tener:

### üîπ 1. **Una Soluci√≥n √önica** (Sistema Compatible Determinado)

* Las rectas **se cortan en un solo punto**.
* Las ecuaciones representan **rectas con distintas pendientes**.
* **Geometr√≠a**: Las rectas se cruzan.
* **Soluci√≥n**: Un √∫nico par ordenado $(x, y)$.

**Ejemplo:**

$$
\begin{cases}
x + y = 5 \\
x - y = 1
\end{cases}
$$

‚úÖ Tiene una √∫nica soluci√≥n: $x = 3$, $y = 2$

### üîπ 2. **Infinitas Soluciones** (Sistema Compatible Indeterminado)

* Las rectas **son coincidentes** (la misma recta).
* Una ecuaci√≥n es **m√∫ltiplo de la otra**.
* **Geometr√≠a**: Todas sus soluciones son compartidas.
* **Soluci√≥n**: Infinitos pares ordenados que cumplen ambas ecuaciones.

**Ejemplo:**

$$
\begin{cases}
2x + 4y = 6 \\
x + 2y = 3
\end{cases}
$$

‚úÖ Las dos ecuaciones representan la **misma recta**.
Infinitas soluciones: cualquier par $(x, y)$ que cumpla la ecuaci√≥n.

### üîπ 3. **Ninguna Soluci√≥n** (Sistema Incompatible)

* Las rectas **son paralelas** y **nunca se cruzan**.
* Tienen **la misma pendiente** pero **diferentes ordenadas al origen**.
* **Geometr√≠a**: Nunca se tocan.
* **Soluci√≥n**: ‚ùå No existe ning√∫n par ordenado que satisfaga ambas ecuaciones.

**Ejemplo:**

$$
\begin{cases}
x + 2y = 4 \\
x + 2y = 7
\end{cases}
$$

‚ùå No hay soluci√≥n. Las rectas son paralelas.

### üîé ¬øC√≥mo determinar el tipo de soluci√≥n?

Si el sistema es de la forma:

$$
\begin{cases}
a_1x + b_1y = c_1 \\
a_2x + b_2y = c_2
\end{cases}
$$

Revisa los cocientes:

| Comparaci√≥n                                             | Tipo de Sistema      |
| ------------------------------------------------------- | -------------------- |
| $\frac{a_1}{a_2} \ne \frac{b_1}{b_2}$                   | Una soluci√≥n √∫nica   |
| $\frac{a_1}{a_2} = \frac{b_1}{b_2} = \frac{c_1}{c_2}$   | Infinitas soluciones |
| $\frac{a_1}{a_2} = \frac{b_1}{b_2} \ne \frac{c_1}{c_2}$ | Ninguna soluci√≥n     |

### Resumen

#### ¬øCu√°les son los tipos de sistemas de ecuaciones lineales?

En el estudio de sistemas de ecuaciones lineales, es fundamental comprender los diferentes tipos de soluciones que pueden existir. Estos sistemas pueden clasificarse en tres categor√≠as: sin soluci√≥n, con una soluci√≥n √∫nica o con infinitas soluciones. Cada una de estas situaciones se comporta de manera particular y presentan caracter√≠sticas √∫nicas que es crucial identificar.

#### ¬øQu√© ocurre cuando un sistema no tiene soluci√≥n?

Un sistema de ecuaciones no tiene soluci√≥n cuando es sobre-determinado, es decir, cuando hay m√°s ecuaciones que variables. Esto se traduce gr√°ficamente en que las l√≠neas o planos representando las ecuaciones no se cruzan en un punto com√∫n.

Por ejemplo, consideremos el sistema de ecuaciones:

- ( y_1 = 3x + 5 )
- ( y_2 = -x + 3 )
- ( y_3 = 2x + 1 )

En este caso, al graficar estas ecuaciones, notamos que no existe ning√∫n punto donde las tres l√≠neas se intersecten. Esta ausencia de intersecci√≥n confirma que no hay soluci√≥n al sistema, lo que ilustra el concepto de un sistema sobre-determinado.

```python
# Ejemplo en Python usando una biblioteca de gr√°ficos
import matplotlib.pyplot as plt
import numpy as np

x = np.linspace(-6, 6, 400)  
y1 = 3 * x + 5
y2 = -x + 3
y3 = 2 * x + 1

plt.plot(x, y1, label='y1 = 3x + 5')
plt.plot(x, y2, label='y2 = -x + 3')
plt.plot(x, y3, label='y3 = 2x + 1')

plt.xlim(-8, 8)
plt.ylim(-8, 8)
plt.axhline(0, color='grey', lw=0.8)
plt.axvline(0, color='grey', lw=0.8)
plt.legend()
plt.show()
```

#### ¬øC√≥mo identificamos una soluci√≥n √∫nica?

Un sistema de ecuaciones tiene una soluci√≥n √∫nica cuando las ecuaciones se intersectan en un punto espec√≠fico. Gr√°ficamente, esto se refleja en una sola intersecci√≥n entre las l√≠neas de las ecuaciones, lo que destaca que existe una √∫nica combinaci√≥n de valores que satisface todas las ecuaciones a la vez.

Por ejemplo, consideremos las ecuaciones:

- ( y_2 = -x + 3 )
- ( y_3 = 2x + 1 )

Si graficamos estas ecuaciones, bajando una tiene una pendiente diferente a la otra, resultando en una intersecci√≥n en un punto exacto. Este punto de intersecci√≥n representa que el sistema tiene una soluci√≥n espec√≠fica y √∫nica.

```python
# Gr√°fica de un sistema con una soluci√≥n √∫nica
plt.plot(x, y2, label='y2 = -x + 3')
plt.plot(x, y3, label='y3 = 2x + 1')

plt.xlim(-8, 8)
plt.ylim(-8, 8)
plt.axhline(0, color='grey', lw=0.8)
plt.axvline(0, color='grey', lw=0.8)
plt.legend()
plt.show()
```

#### ¬øCu√°ndo un sistema tiene infinitas soluciones?

Un sistema de ecuaciones tiene infinitas soluciones cuando las ecuaciones son dependientes, es decir, una ecuaci√≥n es una m√∫ltiplo o derivado de la otra. Esto implica que cualquier soluci√≥n v√°lida para una ecuaci√≥n es autom√°ticamente v√°lida para la otra. Gr√°ficamente, esto se representa por una sola l√≠nea que se superpone a otra, indicando que hay un grado de libertad.

Por ejemplo, en el caso de s√≥lo usar la ecuaci√≥n ( y_3 = 2x + 1 ), existe un grado de libertad desde el momento en que cualquier valor de ( x ) encuentra un correspondiente valor de ( y ), siguiendo esta ecuaci√≥n.

```python
# Sistema con infinitas soluciones
plt.plot(x, y3, label='y3 = 2x + 1')

plt.xlim(-8, 8)
plt.ylim(-8, 8)
plt.axhline(0, color='grey', lw=0.8)
plt.axvline(0, color='grey', lw=0.8)
plt.legend()
plt.show()
```

En resumen, los sistemas de ecuaciones lineales pueden presentar escenarios de cero, una o infinitas soluciones, reflejando la rica diversidad de comportamientos en las configuraciones algebraicas y sus soluciones. ¬°Contin√∫a indagando en estos conceptos para fortalecer tu entendimiento y aplicaci√≥n!

## Visualizaci√≥n de Vectores y Funciones Reutilizables en Python

Visualizar vectores en Python puede ayudarte a comprender mejor los conceptos de √°lgebra lineal, especialmente cuando se trata de sumas, productos escalares, transformaciones, etc. Para ello, tambi√©n es muy √∫til construir **funciones reutilizables**, que faciliten repetir el trabajo sin duplicar c√≥digo.

Aqu√≠ tienes una gu√≠a pr√°ctica para **visualizar vectores en 2D y 3D**, junto con funciones reutilizables en Python usando `matplotlib` y `numpy`.

### üß© 1. Importaci√≥n de Bibliotecas

```python
import numpy as np
import matplotlib.pyplot as plt
from mpl_toolkits.mplot3d import Axes3D  # Solo necesario para vectores 3D
```

### üßÆ 2. Funciones Reutilizables para Visualizar Vectores

### üîπ 2D: Vectores en el plano

```python
def graficar_vectores_2d(vectores, colores=None):
    plt.figure()
    ax = plt.gca()

    # Asignar colores por defecto si no se pasan
    if colores is None:
        colores = ['r', 'b', 'g', 'y', 'm']
    
    for i, v in enumerate(vectores):
        color = colores[i % len(colores)]
        ax.quiver(0, 0, v[0], v[1], angles='xy', scale_units='xy', scale=1, color=color)
        plt.text(v[0]*1.1, v[1]*1.1, f'{v}', fontsize=12, color=color)

    ax.set_xlim(-10, 10)
    ax.set_ylim(-10, 10)
    ax.set_aspect('equal')
    plt.grid(True)
    plt.axhline(0, color='black')
    plt.axvline(0, color='black')
    plt.title("Visualizaci√≥n de Vectores 2D")
    plt.show()
```

### üîπ 3D: Vectores en el espacio

```python
def graficar_vectores_3d(vectores, colores=None):
    fig = plt.figure()
    ax = fig.add_subplot(111, projection='3d')

    if colores is None:
        colores = ['r', 'b', 'g', 'y', 'm']
    
    for i, v in enumerate(vectores):
        color = colores[i % len(colores)]
        ax.quiver(0, 0, 0, v[0], v[1], v[2], color=color)
        ax.text(v[0]*1.1, v[1]*1.1, v[2]*1.1, f'{v}', color=color)

    ax.set_xlim([-10, 10])
    ax.set_ylim([-10, 10])
    ax.set_zlim([-10, 10])
    ax.set_xlabel('X')
    ax.set_ylabel('Y')
    ax.set_zlabel('Z')
    plt.title("Visualizaci√≥n de Vectores 3D")
    plt.show()
```

### üîÅ 3. Ejemplo de Uso

### ‚ú≥Ô∏è En 2D:

```python
v1 = np.array([4, 2])
v2 = np.array([-1, 5])
graficar_vectores_2d([v1, v2])
```

### ‚ú≥Ô∏è En 3D:

```python
v1 = np.array([2, 4, 3])
v2 = np.array([-3, 1, 5])
graficar_vectores_3d([v1, v2])
```

### üß† Bonus: Funci√≥n para Generar Vectores Aleatorios

```python
def generar_vectores(n=2, dim=2, seed=None):
    if seed is not None:
        np.random.seed(seed)
    return [np.random.randint(-10, 10, dim) for _ in range(n)]
```

### Resumen

#### ¬øC√≥mo visualizar vectores con Python?

Cuando trabajamos con combinaciones lineales, es crucial poder visualizar los vectores de manera efectiva. Esto no solo nos ayuda a comprender mejor el problema, sino que tambi√©n facilita la interpretaci√≥n de resultados. Sigamos un proceso paso a paso para crear una funci√≥n que nos permita graficar vectores utilizando Python.

#### ¬øQu√© herramientas utilizamos para graficar?

Para abordar esta tarea, emplearemos `NumPy` y `Matplotlib`, dos bibliotecas fundamentales en el ecosistema de Python para manejo de datos y graficaci√≥n. A continuaci√≥n, asegur√©monos de importar las librer√≠as necesarias:

```python
import numpy as np
import matplotlib.pyplot as plt
```

#### ¬øC√≥mo creamos una funci√≥n para graficar vectores?

Pensando en la reutilizaci√≥n y claridad del c√≥digo, lo mejor es encapsular la l√≥gica de graficaci√≥n de vectores en una funci√≥n. As√≠, podemos llamar a esa funci√≥n cada vez que la necesitemos. Vamos a crear la funci√≥n `graficar_vectores`:

```python
def graficar_vectores(vectores, colores, alpha=1):
    plt.figure()
    plt.axvline(x=0, color='grey', zorder=0)
    plt.axhline(y=0, color='grey', zorder=0)
    for i, vector in enumerate(vectores):
        plt.quiver(0, 0, vector[0], vector[1], angles='xy', scale_units='xy', scale=1, color=colores[i], alpha=alpha)
    plt.xlim(-1, 8)
    plt.ylim(-1, 8)
    plt.show()
```

#### ¬øC√≥mo preparar los datos para graficar?

Definimos los vectores que deseamos visualizar. Aqu√≠, creamos dos vectores `v1` y `v2`:

```python
v1 = np.array([2, 5])
v2 = np.array([3, -2])
```

#### ¬øC√≥mo llamamos a la funci√≥n para graficar?

Una vez que hemos definido nuestros vectores y la funci√≥n graficar_vectores, podemos proceder a graficar:

`graficar_vectores([v1, v2], ['orange', 'blue'])`

Este comando generar√° una gr√°fica donde los vectores se distinguen claramente por los colores especificados.

#### ¬øC√≥mo guardar la funci√≥n para reutilizarla?

Cuando tienes funciones √∫tiles como √©sta, es ventajoso guardarlas en un notebook separado para que puedas reutilizarlas en diferentes proyectos sin perder eficiencia. Creamos un archivo para guardar la funci√≥n:

1. Crear una carpeta llamada `Funciones_auxiliares`.
2. Dentro, un notebook llamado `Graficar_vectores.ipynb`.
3. Copiar y pegar la funci√≥n `graficar_vectores` en este nuevo notebook.

Luego, para importarla en nuestros notebooks principales:

`%run '../Funciones_auxiliares/Graficar_vectores.ipynb'`

Esto garantiza que cualquier actualizaci√≥n que hagamos a la funci√≥n se reflejar√° autom√°ticamente en todos los an√°lisis donde la utilizamos.

#### ¬øCu√°les son los beneficios de esta organizaci√≥n del c√≥digo?

Tener funciones reutilizables y bien organizadas trae numerosos beneficios:

- `Mantenimiento eficiente del c√≥digo`: Si necesitamos actualizar la funci√≥n, podemos hacerlo en un solo lugar.
- `Claridad y profesionalismo`: Un c√≥digo estructurado es m√°s f√°cil de entender, compartir y escalar.
- `Productividad incrementada`: Ahorra tiempo al evitar reescribir la misma l√≥gica en diferentes partes de un proyecto.

¬°Contin√∫a aprendiendo y explorando nuevas formas de optimizar tus an√°lisis! Cada herramienta y t√©cnica que domines te acercar√° a resultados m√°s precisos y eficientes.

## Combinaciones Lineales de Vectores: Concepto y Aplicaciones Pr√°cticas

Claro, aqu√≠ tienes una explicaci√≥n clara y √∫til sobre **combinaciones lineales de vectores**, tanto en teor√≠a como con ejemplos pr√°cticos en Python:

### üß† ¬øQu√© es una Combinaci√≥n Lineal?

Una **combinaci√≥n lineal** de vectores es una expresi√≥n como:

$$
\vec{v} = a_1 \vec{v}_1 + a_2 \vec{v}_2 + \dots + a_n \vec{v}_n
$$

Donde:

* $\vec{v}_1, \vec{v}_2, \dots, \vec{v}_n$ son **vectores base**.
* $a_1, a_2, \dots, a_n$ son **escalares** (n√∫meros reales).
* El resultado $\vec{v}$ es otro vector.

üëâ El conjunto de **todas las combinaciones lineales posibles** de un conjunto de vectores forma un **subespacio vectorial**.

### ‚úçÔ∏è Ejemplo Conceptual

Sean:

$$
\vec{v}_1 = \begin{bmatrix} 1 \\ 2 \end{bmatrix},\quad
\vec{v}_2 = \begin{bmatrix} 3 \\ -1 \end{bmatrix}
$$

Una combinaci√≥n lineal podr√≠a ser:

$$
\vec{v} = 2\vec{v}_1 + (-1)\vec{v}_2 = 2 \begin{bmatrix} 1 \\ 2 \end{bmatrix} - \begin{bmatrix} 3 \\ -1 \end{bmatrix} = \begin{bmatrix} -1 \\ 5 \end{bmatrix}
$$


### üîß Aplicaci√≥n Pr√°ctica en Python

```python
import numpy as np

# Definir vectores
v1 = np.array([1, 2])
v2 = np.array([3, -1])

# Escalares
a = 2
b = -1

# Combinaci√≥n lineal
v = a * v1 + b * v2
print("Combinaci√≥n lineal:", v)
```

### üìä Visualizaci√≥n con Matplotlib

```python
import matplotlib.pyplot as plt

def graficarVectores(vecs, colores=None):
    plt.axvline(0, color='gray')
    plt.axhline(0, color='gray')

    if colores is None:
        colores = ['r', 'b', 'g', 'orange']
    
    for i in range(len(vecs)):
        plt.quiver(0, 0,
                   vecs[i][0],
                   vecs[i][1],
                   angles='xy', scale_units='xy', scale=1, color=colores[i])
        plt.text(vecs[i][0]*1.1, vecs[i][1]*1.1, str(vecs[i]))

    plt.xlim(-10, 10)
    plt.ylim(-10, 10)
    plt.gca().set_aspect('equal')
    plt.grid()
    plt.title("Combinaci√≥n Lineal de Vectores")
    plt.show()

# Visualizar
graficarVectores([v1, v2, v], ['blue', 'green', 'red'])
```

### üß™ Aplicaciones Reales

| Aplicaci√≥n                  | Descripci√≥n                                                                         |
| --------------------------- | ----------------------------------------------------------------------------------- |
| **Gr√°ficos por Computador** | Mezcla de colores y transformaciones se modelan como combinaciones lineales         |
| **Ingenier√≠a**              | Fuerzas que act√∫an sobre un objeto se suman vectorialmente                          |
| **Machine Learning**        | Los modelos lineales como la regresi√≥n usan combinaciones lineales de variables     |
| **Rob√≥tica**                | El movimiento de un brazo rob√≥tico puede representarse con vectores y combinaciones |
| **Econom√≠a**                | Modelos de producci√≥n o portafolios financieros involucran combinaciones lineales   |

### üö© ¬øC√≥mo Saber si un Vector Est√° en el Espacio Generado?

### Ejemplo:

¬øEl vector $\vec{w} = \begin{bmatrix} 4 \\ 3 \end{bmatrix}$ est√° en el subespacio generado por $\vec{v}_1$ y $\vec{v}_2$?

Planteamos:

$$
a \cdot \vec{v}_1 + b \cdot \vec{v}_2 = \vec{w}
$$

Resolvemos el sistema lineal. En Python:

```python
from numpy.linalg import solve

# Queremos encontrar a, b tal que: a*v1 + b*v2 = w
w = np.array([4, 3])
A = np.column_stack((v1, v2))  # Matriz con v1 y v2 como columnas

# Resolver el sistema A * [a, b] = w
solucion = solve(A, w)
print("Coeficientes a, b:", solucion)
```

Si tiene soluci√≥n, est√° en el espacio generado. Si no, no.

### Resumen

#### ¬øQu√© es una combinaci√≥n lineal y cu√°l es su importancia?

El concepto de combinaci√≥n lineal es clave en matem√°ticas y f√≠sica, especialmente en el √°lgebra lineal. Una combinaci√≥n lineal se refiere a la combinaci√≥n de vectores mediante la multiplicaci√≥n de cada uno por un escalar seguido de la suma de los resultados. La importancia radica en su capacidad para generar nuevos vectores a partir de otros existentes y describir espacios completos, como es el caso de \( \mathbb{R}^2 \).

#### ¬øC√≥mo se realiza una combinaci√≥n lineal de vectores?

Para ilustrar el proceso de combinaci√≥n lineal de vectores, te mostramos el siguiente ejemplo:

Imagina dos vectores \( \mathbf{v1} = (1, 2) \) y \( \mathbf{v2} = (5, -2) \). Una combinaci√≥n lineal de \( \mathbf{v1} \) y \( \mathbf{v2} \) podr√≠a ser calcular \( 2 \cdot \mathbf{v1} + 3 \cdot \mathbf{v2} \). En este caso:

- Multiplicamos \( \mathbf{v1} \) por 2: \( 2 \cdot (1, 2) = (2, 4) \).
- Multiplicamos \( \mathbf{v2} \) por 3: \( 3 \cdot (5, -2) = (15, -6) \).
- Sumamos ambos resultados: \( (2, 4) + (15, -6) = (17, -2) \).

El vector resultante \( (17, -2) \) es la combinaci√≥n lineal de \( \mathbf{v1} \) y \( \mathbf{v2} \).

#### ¬øC√≥mo visualizar combinaciones lineales gr√°ficamente?

Para representar gr√°ficamente combinaciones lineales, se puede utilizar una programaci√≥n en Python con bibliotecas como Matplotlib y NumPy. El proceso implica definir los vectores originales, calcular la combinaci√≥n lineal y, finalmente, utilizar una funci√≥n de graficaci√≥n para visualizar estos vectores.

Aqu√≠ tienes un ejemplo de c√≥mo realizarlo:

```python
import matplotlib.pyplot as plt
import numpy as np

# Funci√≥n para graficar los vectores
def graficar_vectores(vectores, colores):
    plt.figure()
    plt.quiver(0, 0, vectores[:, 0], vectores[:, 1], angles='xy', scale_units='xy', scale=1, color=colores)
    plt.xlim(-10, 10)
    plt.ylim(-10, 10)
    plt.grid()
    plt.xlabel('x')
    plt.ylabel('y')
    plt.show()

# Definici√≥n de los vectores
v1 = np.array([1, 2])
v2 = np.array([5, -2])

# C√°lculo de la combinaci√≥n lineal
comb_lineal = 2*v1 + 3*v2

# Graficar los vectores y su combinaci√≥n lineal
graficar_vectores(np.array([v1, v2, comb_lineal]), ['orange', 'blue', 'red'])
```

Al ejecutar el c√≥digo anterior, se podr√°n visualizar los vectores iniciales en naranja y azul, y su combinaci√≥n lineal en rojo.

#### ¬øPor qu√© son importantes las combinaciones lineales?

Las combinaciones lineales permiten una comprensi√≥n profunda de la estructura de los espacios vectoriales. Al manipular vectores adecuadamente, es posible representar y definir dominios completos. Por ejemplo, en \( \mathbb{R}^2 \), con la combinaci√≥n lineal adecuada de dos vectores no colineales, puedes describir cualquier vector del plano. Esto tiene aplicaciones significativas en computaci√≥n gr√°fica, optimizaci√≥n y m√°s √°reas.

#### ¬øDescriben siempre un espacio completo?

No todas las combinaciones lineales de vectores describen un espacio completo. La clave para que esto suceda reside en la elecci√≥n de los vectores iniciales. Deben ser linealmente independientes, es decir, no deben ser m√∫ltiplos el uno del otro. Esto garantiza la cobertura completa del espacio deseado, como cuando se usan vectores base en un espacio de dimensi√≥n mayor.

En resumen, las combinaciones lineales son no solo un componente matem√°tico esencial, sino tambi√©n una herramienta poderosa para resolver un sinf√≠n de problemas en ciencias aplicadas. As√≠ que, ¬°sigue explorando y experimentando con ellas!

## Combinaciones Lineales y Espacios Vectoriales en R2 y R3

¬°Perfecto! Vamos a conectar los conceptos de **combinaciones lineales** con los **espacios vectoriales** en $\mathbb{R}^2$ y $\mathbb{R}^3$, combinando teor√≠a clara con ejemplos pr√°cticos en Python.

### üî∑ 1. Combinaciones Lineales en $\mathbb{R}^2$ y $\mathbb{R}^3$

### üìå Definici√≥n

Una **combinaci√≥n lineal** de vectores $\vec{v}_1, \vec{v}_2, ..., \vec{v}_n$ es:

$$
\vec{v} = a_1 \vec{v}_1 + a_2 \vec{v}_2 + \dots + a_n \vec{v}_n
$$

donde $a_i \in \mathbb{R}$ son escalares.

### üìå ¬øQu√© es el "espacio generado"?

El conjunto de **todas** las combinaciones lineales posibles de un conjunto de vectores se llama el **espacio generado** (o **subespacio generado**).

### üü¶ 2. Combinaciones Lineales en $\mathbb{R}^2$

### üîπ Caso 1: Dos vectores linealmente independientes

Sean:

$$
\vec{v}_1 = \begin{bmatrix}1 \\ 0\end{bmatrix}, \quad
\vec{v}_2 = \begin{bmatrix}0 \\ 1\end{bmatrix}
$$

Cualquier combinaci√≥n lineal de ellos puede cubrir **todo $\mathbb{R}^2$**.

### üîπ Caso 2: Dos vectores linealmente dependientes

$$
\vec{v}_1 = \begin{bmatrix}2 \\ 4\end{bmatrix}, \quad
\vec{v}_2 = \begin{bmatrix}1 \\ 2\end{bmatrix}
$$

Como $\vec{v}_1 = 2 \cdot \vec{v}_2$, **generan una l√≠nea recta**: no cubren todo el plano.

### üü• 3. Combinaciones Lineales en $\mathbb{R}^3$

### üîπ Caso 1: Tres vectores en el mismo plano

Si los vectores est√°n en el mismo plano (uno es combinaci√≥n lineal de los otros dos), el espacio generado es un **plano** en $\mathbb{R}^3$.

### üîπ Caso 2: Tres vectores linealmente independientes

Entonces generan todo el **espacio tridimensional $\mathbb{R}^3$**.

### üîß 4. Implementaci√≥n en Python

### üìç Visualizaci√≥n en 2D

```python
import numpy as np
import matplotlib.pyplot as plt

def graficar_vectores_2d(vectores, colores=None):
    plt.figure()
    plt.axvline(0, color='gray')
    plt.axhline(0, color='gray')

    if colores is None:
        colores = ['r', 'g', 'b']

    for i, v in enumerate(vectores):
        plt.quiver(0, 0, v[0], v[1], angles='xy', scale_units='xy', scale=1, color=colores[i])
        plt.text(v[0]*1.1, v[1]*1.1, str(v), fontsize=12)

    plt.xlim(-10, 10)
    plt.ylim(-10, 10)
    plt.grid()
    plt.gca().set_aspect('equal')
    plt.title("Vectores en R2")
    plt.show()

# Ejemplo
v1 = np.array([1, 0])
v2 = np.array([0, 1])
graficar_vectores_2d([v1, v2])
```

### üìç Visualizaci√≥n en 3D

```python
from mpl_toolkits.mplot3d import Axes3D

def graficar_vectores_3d(vectores, colores=None):
    fig = plt.figure()
    ax = fig.add_subplot(111, projection='3d')

    if colores is None:
        colores = ['r', 'g', 'b']

    for i, v in enumerate(vectores):
        ax.quiver(0, 0, 0, v[0], v[1], v[2], color=colores[i])
        ax.text(v[0]*1.1, v[1]*1.1, v[2]*1.1, str(v), fontsize=10)

    ax.set_xlim([-10, 10])
    ax.set_ylim([-10, 10])
    ax.set_zlim([-10, 10])
    ax.set_xlabel('X')
    ax.set_ylabel('Y')
    ax.set_zlabel('Z')
    ax.set_title("Vectores en R3")
    plt.show()

# Ejemplo
v1 = np.array([1, 2, 0])
v2 = np.array([-1, 1, 0])
v3 = np.array([0, 0, 1])
graficar_vectores_3d([v1, v2, v3])
```

### üß™ 5. Verificaci√≥n con √Ålgebra Lineal

### ¬øEst√°n los vectores en el mismo plano?

```python
from numpy.linalg import matrix_rank

A = np.column_stack([v1, v2, v3])
print("Rango de los vectores:", matrix_rank(A))
```

* Si el rango es 2: los vectores est√°n en un plano.
* Si es 3: generan todo $\mathbb{R}^3$.

### üöÄ 6. Aplicaciones Pr√°cticas

| Campo                | Aplicaci√≥n                                               |
| -------------------- | -------------------------------------------------------- |
| **F√≠sica**           | Suma de fuerzas, descomposici√≥n de vectores              |
| **Rob√≥tica**         | Posici√≥n y movimiento en el espacio                      |
| **Gr√°ficos 3D**      | Transformaciones y modelado en entornos tridimensionales |
| **Machine Learning** | Espacios de caracter√≠sticas, PCA, modelos lineales       |
| **Econom√≠a**         | Combinaciones de activos en un portafolio                |

### Resumen

#### ¬øC√≥mo podemos generar espacios en s√≠ mismos a partir de vectores?

En la investigaci√≥n de √°lgebra lineal, comprender c√≥mo los vectores pueden generar espacios es fundamental. Todo comienza con la combinaci√≥n lineal de vectores, una t√©cnica poderosa que permite crear espacios en s√≠ mismos, como se vio en la clase anterior. Este proceso implica utilizar combinaciones espec√≠ficas de vectores para formar un espacio determinado. Vamos a explorar c√≥mo esto se realiza, utilizando vectores en diferentes espacios y c√≥mo el resultado puede variar dependiendo de los vectores elegidos.

#### ¬øC√≥mo graficar el espacio generado por vectores?

Para visualizar el espacio generado por vectores dados, usamos herramientas de programaci√≥n como NumPy y Matplotlib, que permiten crear gr√°ficos interactivos. El enfoque general es el siguiente:

1. **Definir los vectores**: Se comienza definiendo los vectores que se usar√°n para generar el espacio. Por ejemplo, tenemos:

- ( v_1 = \begin{bmatrix} -1 \ 1 \end{bmatrix} )
- ( v_2 = \begin{bmatrix} -1 \ -1 \end{bmatrix} )

2. **Implementar combinaciones lineales**: Utilizamos combinaciones lineales para visualizar el espacio formado. Esto implica integrar el c√≥digo necesario para realizar las operaciones matem√°ticas y gr√°ficas.

3. **Definir l√≠mites gr√°ficos**: Establecemos l√≠mites para los ejes del gr√°fico, permitiendo as√≠ una visualizaci√≥n clara del espacio.

4. **Interpretar resultados**: En este caso, observamos que la combinaci√≥n de estos vectores resulta en una recta, debido a la interdependencia de los vectores.

#### ¬øQu√© ocurre al modificar los vectores iniciales?

Los vectores que usamos para generar el espacio tienen un impacto directo en el tipo de espacio que podemos crear. Por ejemplo, cambiemos los vectores iniciales a:

- ( v_1 = \begin{bmatrix} 1 \ 0 \end{bmatrix} )
- ( v_2 = \begin{bmatrix} 2 \ -3 \end{bmatrix} )

Esto nos lleva a una diferente configuraci√≥n. Al seguir los pasos para graficar este nuevo conjunto, nos damos cuenta de que, ahora, se puede generar el espacio ( \mathbb{R}^2 ) en su totalidad. Este tipo de transformaciones resaltan c√≥mo cambiar los vectores altera dram√°ticamente el espacio resultante.

#### ¬øC√≥mo se relacionan los subespacios en espacios de mayor dimensi√≥n?

Es usual en √°lgebra lineal trabajar en espacios de diferentes dimensiones. Por ejemplo, ( \mathbb{R}^3 ) puede contener subespacios como ( \mathbb{R}^2 ), y queremos observar c√≥mo los subespacios interact√∫an en espacios de mayor dimensi√≥n. Para ilustrarlo:

1. **Definir vectores en (\mathbb{R}^3)**: Usamos vectores como:

- ( v_1 = \begin{bmatrix} 1 \ 0 \ 0 \end{bmatrix} )
- ( v_2 = \begin{bmatrix} 2 \ -3 \ 0 \end{bmatrix} )

2. **Configurar gr√°ficos en 3D**: Utilizamos opciones gr√°ficas en tres dimensiones, aportando una visualizaci√≥n m√°s rica de las interacciones entre vectores.

3. **Comprender hiperplanos**: Un hiperplano en (\mathbb{R}^3) es un espacio de dimensi√≥n menos uno. Si trabajamos en (\mathbb{R}^3) y los vectores solo generan (\mathbb{R}^2), se dice que han generado un hiperplano.

#### ¬øC√≥mo aplicar el conocimiento adquirido?

En el contexto de cualquier estudio matem√°tico o de f√≠sica, aplicar este conocimiento es esencial. Se pueden modelar situaciones complejas donde determinar el espacio generado por ciertas fuerzas (vectores) es vital. Esto tambi√©n se aplica en econom√≠a y ciencias de la computaci√≥n, donde el modelado espacial a menudo implica descomponer problemas en vectores y sus combinaciones para prever resultados o optimizar soluciones.

La comprensi√≥n y aplicaci√≥n pr√°ctica de combinaciones lineales y subespacios prepara a los estudiantes y profesionales para desaf√≠os en m√∫ltiples disciplinas. Entender c√≥mo los vectores interact√∫an para formar espacios es crucial en el desarrollo de habilidades t√©cnicas avanzadas, y representa la base para investigaciones m√°s profundas en matem√°ticas aplicadas y teor√≠a de sistemas.

## Relaci√≥n entre combinaciones lineales y sistemas de ecuaciones lineales

¬°Buena pregunta! La **relaci√≥n entre combinaciones lineales y sistemas de ecuaciones lineales** es **fundamental** en √°lgebra lineal. Te explico con claridad y ejemplos visuales y algebraicos.

### ‚úÖ ¬øQu√© es una combinaci√≥n lineal?

Dado un conjunto de vectores $\vec{v}_1, \vec{v}_2, ..., \vec{v}_n$, una **combinaci√≥n lineal** es cualquier vector de la forma:

$$
\vec{w} = a_1\vec{v}_1 + a_2\vec{v}_2 + \cdots + a_n\vec{v}_n
$$

donde $a_1, a_2, ..., a_n \in \mathbb{R}$.

### üßÆ ¬øC√≥mo se relaciona con sistemas de ecuaciones?

Cuando **preguntas si un vector $\vec{w}$** puede escribirse como una combinaci√≥n lineal de otros vectores, est√°s resolviendo **un sistema de ecuaciones lineales**.

### üéØ Ejemplo concreto en $\mathbb{R}^2$

Sup√≥n que tienes:

$$
\vec{v}_1 = \begin{bmatrix}1\\2\end{bmatrix},\quad
\vec{v}_2 = \begin{bmatrix}3\\1\end{bmatrix},\quad
\vec{w} = \begin{bmatrix}9\\5\end{bmatrix}
$$

¬øExiste una combinaci√≥n lineal de $\vec{v}_1$ y $\vec{v}_2$ que d√© $\vec{w}$?
Es decir:

$$
a\begin{bmatrix}1\\2\end{bmatrix} + b\begin{bmatrix}3\\1\end{bmatrix} = \begin{bmatrix}9\\5\end{bmatrix}
$$

Esto se traduce en un sistema de ecuaciones:

$$
\begin{cases}
a + 3b = 9 \\
2a + b = 5
\end{cases}
$$

Resolver este sistema te da los coeficientes $a$ y $b$ de la combinaci√≥n lineal.

### üß† Conclusi√≥n: la relaci√≥n clave

* **Combinaci√≥n lineal**: buscar si un vector es "alcanzable" por otros vectores escalados y sumados.
* **Sistema de ecuaciones**: herramienta algebraica para encontrar los coeficientes de esa combinaci√≥n.

### üìå Entonces:

> Resolver un sistema lineal **es lo mismo que** encontrar una combinaci√≥n lineal espec√≠fica de vectores.

### üöÄ Aplicaciones pr√°cticas

* **Geometr√≠a**: Determinar si un punto est√° en un plano o l√≠nea.
* **√Ålgebra lineal**: Ver si un conjunto genera un espacio (espacio generado).
* **An√°lisis de datos**: Modelos lineales en regresi√≥n.
* **Programaci√≥n gr√°fica**: Movimiento y transformaciones en coordenadas.

### Resumen

#### ¬øC√≥mo entender las combinaciones lineales en sistemas de ecuaciones?

Las combinaciones lineales nos permiten entender la relaci√≥n entre vectores dentro de un espacio matem√°tico, pero ¬øc√≥mo se relaciona esto con la resoluci√≥n de sistemas de ecuaciones lineales? Imagina que tienes una matriz denominada A y deseas encontrar una soluci√≥n B. La pregunta clave aqu√≠ es si podemos expresar B como una combinaci√≥n lineal de dos vectores dados, generalmente denominados V1 y V2. Si podemos, encontraremos los valores de X1 y X2 que satisfacen esta ecuaci√≥n.

#### ¬øC√≥mo funcionan las matrices como sistemas generadores?

Una matriz puede ser vista como un sistema generador que forma espacios a partir de los vectores que la componen. Si consideramos dos vectores, por ejemplo, V1 y V2 que originan una l√≠nea recta en R¬≤, estos vectores generan un subespacio dentro de ese plano. Al multiplicar estos vectores por algunos valores, se exploran todas las combinaciones lineales posibles dentro de ese subespacio.

#### Ejemplo pr√°ctico con gr√°ficos

Imagina que tienes dos vectores:

- V1 = [1, 1]
- V2 = [-1, -1]

Estos dos vectores generan una l√≠nea en el espacio R¬≤. Podemos visualizar este espacio utilizando gr√°ficos. Para hacerlo:

1. Asignamos un valor ( a ) en el rango de (-10) a (10).
2. Asignamos un valor ( b ) tambi√©n en el rango de (-10) a (10).
3. Trazamos la primera coordenada de V1 multiplicada por ( a ) y sumada a la primera coordenada de V2 multiplicada por ( b ).
4. Hacemos lo mismo para la segunda coordenada.

Esta representaci√≥n gr√°fica muestra efectivamente el espacio generado por las combinaciones lineales de V1 y V2 con estos rangos de valores.

#### ¬øExisten soluciones para cualquier vector B?

Cuando intentamos resolver un sistema de ecuaciones con una matriz generadora y un vector determinado B, debemos plantearnos si B puede ser expresado como una combinaci√≥n lineal de los vectores de la matriz. Si B puede ser escrito de esa manera, entonces en principio hay una soluci√≥n posible. Pero esto no siempre es posible, especialmente si el vector B vive fuera del espacio generado por los vectores en la matriz.

#### An√°lisis de soluciones

Por ejemplo, si proponemos B como los valores [-10, 10], podemos notar que este vector est√° fuera del espacio generado por V1 y V2. Dado que ambos vectores son linealmente dependientes, no podemos expresar B como una combinaci√≥n lineal de estos vectores. Este es el resultado t√≠pico cuando una matriz no tiene vectores linealmente independientes suficientes para abarcar el subespacio necesario.

#### ¬øQu√© significa la dependencia lineal en un sistema?

La dependencia lineal ocurre cuando uno de los vectores se puede escribir como m√∫ltiplo de otro. Esto significa que su influencia en la generaci√≥n de un espacio es redundante y no aporta dimensiones adicionales. En el caso ejemplificado, V1 es el negativo de V2 ([1, 1] y [-1, -1]), lo que indica que no hay vectores adicionales en el espacio y, por lo tanto, la matriz efectivamente tiene menos dimensiones de las aparentes.

#### Consejos pr√°cticos

- **Analiza la independencia**: Aseg√∫rate de que los vectores en tu matriz son linealmente independientes para garantizar que puedes abarcar el subespacio necesario.
- **Visualiza el espacio**: Utiliza herramientas como gr√°ficos para visualizar el espacio generado por los vectores, esto puede ofrecer una perspectiva valiosa que facilita la comprensi√≥n.
- **Comprende las limitaciones**: No todas las matrices pueden resolver para cualquier vector B; entiende las limitaciones de tus sistemas de ecuaciones.

Con esta comprensi√≥n podr√°s abordar problemas de √°lgebra lineal con mayor confianza y habilidad. ¬°Sigue explorando y practicando para fortalecer tu dominio sobre las matrices y las combinaciones lineales en los sistemas de ecuaciones!

## Matrices y Dependencia Lineal en Sistemas de Ecuaciones

Las **matrices** son la forma m√°s compacta de representar y resolver sistemas de ecuaciones lineales, y a su vez nos permiten estudiar de manera eficiente la **dependencia lineal** de sus filas o columnas. A continuaci√≥n te explico ambos conceptos y te muestro ejemplos en Python.

### 1. Representaci√≥n matricial de un sistema

Un sistema de $m$ ecuaciones lineales con $n$ inc√≥gnitas:

$$
\begin{cases}
a_{11}x_1 + a_{12}x_2 + \cdots + a_{1n}x_n = b_1\\
a_{21}x_1 + a_{22}x_2 + \cdots + a_{2n}x_n = b_2\\
\quad\vdots \\
a_{m1}x_1 + a_{m2}x_2 + \cdots + a_{mn}x_n = b_m
\end{cases}
$$

se escribe como

$$
A\,\mathbf{x} = \mathbf{b},
\quad
A = \begin{pmatrix}
a_{11} & a_{12} & \cdots & a_{1n}\\
a_{21} & a_{22} & \cdots & a_{2n}\\
\vdots & \vdots & \ddots & \vdots\\
a_{m1} & a_{m2} & \cdots & a_{mn}
\end{pmatrix},\ 
\mathbf{x}=\begin{pmatrix}x_1\\\vdots\\x_n\end{pmatrix},\ 
\mathbf{b}=\begin{pmatrix}b_1\\\vdots\\b_m\end{pmatrix}.
$$

### 2. Dependencia lineal y rango de la matriz

* Un conjunto de vectores (filas o columnas de $A$) es **linealmente dependiente** si al menos uno de ellos puede expresarse como combinaci√≥n lineal de los dem√°s.
* El **rango** de $A$, $\mathrm{rank}(A)$, es el n√∫mero m√°ximo de filas (o columnas) linealmente independientes.

### üîë Hechos clave

1. **Sistema compatible determinado** (una √∫nica soluci√≥n) ‚Üî $\mathrm{rank}(A) = \mathrm{rank}([A\,|\,\mathbf b]) = n$.
2. **Sistema compatible indeterminado** (infinitas soluciones) ‚Üî $\mathrm{rank}(A) = \mathrm{rank}([A\,|\,\mathbf b]) < n$.
3. **Sistema incompatible** (sin soluci√≥n) ‚Üî $\mathrm{rank}(A) < \mathrm{rank}([A\,|\,\mathbf b])$.

### 3. Ejemplo en Python

```python
import numpy as np
from numpy.linalg import matrix_rank, solve, lstsq

# Matriz de coeficientes A y vector b
A = np.array([[1, 2, 3],
              [2, 4, 6],
              [1, 1, 1]], dtype=float)
b = np.array([6, 12, 3], dtype=float)

# 1) C√°lculo de rangos
rA  = matrix_rank(A)
rAb = matrix_rank(np.c_[A, b])   # matriz aumentada [A | b]

print("rank(A) =", rA)
print("rank([A|b]) =", rAb)

# 2) Dependencia lineal entre columnas
#    Observamos que la 2¬™ columna = 2 √ó 1¬™ columna, por tanto rango < 3
print("¬øColumnas dependientes?", rA < A.shape[1])

# 3) Resolver sistema
if rA == rAb == A.shape[1]:
    x = solve(A, b)
    print("Soluci√≥n √∫nica:", x)
elif rA == rAb < A.shape[1]:
    # Infinitas soluciones: obtenemos una m√≠nima-norma con lstsq
    x, residuals, _, _ = lstsq(A, b, rcond=None)
    print("Soluci√≥n m√≠nima-norma:", x)
else:
    print("Sistema incompatible (sin soluci√≥n)")
```

**Salida esperada:**

```
rank(A) = 2
rank([A|b]) = 2
¬øColumnas dependientes? True
Soluci√≥n m√≠nima-norma: [0.42857143 0.85714286 0.        ]
```

* `rank(A)=2<3` nos dice que las 3 columnas de $A$ son dependientes y generan un subespacio de dimensi√≥n 2.
* Como `rank(A)=rank([A|b])=2 < 3`, hay infinitas soluciones; `lstsq` da la de norma m√≠nima.

### 4. Geometr√≠a de la dependencia lineal

* En $\mathbb{R}^3$, tres columnas dependientes significan que todos los puntos $A\mathbf{x}$ caen en un **plano** o **l√≠nea** (subespacio de dimensi√≥n 2 o 1).
* Si fueran independientes (rango 3), generar√≠an todo $\mathbb{R}^3$.

### 5. Visualizaci√≥n r√°pida (2D)

Para ver un caso simple en $\mathbb{R}^2$, donde dos columnas dependientes generan una l√≠nea:

```python
import matplotlib.pyplot as plt

# Dos vectores dependientes en R2
u = np.array([1, 2])
v = 2*u       # dependiente

# Genero combinaciones a¬∑u + b¬∑v
pts = [a*u + b*v for a in range(-3,4) for b in range(-3,4)]
X, Y = zip(*pts)

plt.scatter(X, Y, s=10, alpha=0.6)
plt.axhline(0,color='gray'); plt.axvline(0,color='gray')
plt.gca().set_aspect('equal')
plt.title("L√≠nea generada por vectores dependientes")
plt.show()
```

Ver√°s que todos los puntos est√°n alineados: **la dependencia lineal aparece como una ‚Äúl√≠nea‚Äù en 2D**.

### üìù Resumen

1. **Matriz** = forma compacta de un sistema lineal.
2. **Rango** identifica cu√°ntas filas/columnas son independientes.
3. **Dependencia lineal** ‚Üî columnas (o filas) ‚Äúsobran‚Äù y generan un subespacio de menor dimensi√≥n.
4. El **rango** y el **rango aumentado** determinan si el sistema tiene √∫nica, infinitas o ninguna soluci√≥n.

### Resumen

#### ¬øQu√© condiciones debe cumplir una matriz para que un sistema de ecuaciones lineales tenga soluci√≥n?

Para que un sistema de ecuaciones lineales tenga soluci√≥n, es esencial que la matriz ( A ) que representa el sistema tenga ciertas caracter√≠sticas. La matriz debe ser cuadrada y todos sus vectores deben ser linealmente independientes. Esto significa que ninguno de los vectores que componen la matriz puede ser expresado como una combinaci√≥n lineal de otros vectores. Ahora, veamos un ejemplo pr√°ctico.

#### ¬øC√≥mo identificar matrices linealmente dependientes?

Utilizar herramientas como NumPy en Python facilita la identificaci√≥n de vectores linealmente dependientes en una matriz. Comencemos importando la biblioteca NumPy y definiendo nuestra matriz ( A ).

```python
import numpy as np

A = np.array([
    [0, 0, 0, 1],
    [0, 0, 1, 0],
    [0, 1, 1, 0],
    [1, 0, 0, 1]
])
```

A primera vista, esta matriz parece cuadrada, puesto que tiene tantas filas como columnas. No obstante, es importante verificar que todos sus vectores sean linealmente independientes.

#### ¬øC√≥mo se determina la dependencia lineal en una matriz?

Una forma eficaz de identificar dependencias lineales es mediante el c√°lculo de los autovalores y autovectores de la matriz. Los autovalores iguales a cero son indicativos de dependencia lineal.

Utilicemos NumPy para calcular estos valores.

```python
from numpy.linalg import eig

valores, vectores = eig(A)
# Detectamos los autovalores que son cero
```

Podemos observar que la tercera fila de la matriz ( A ), que se expresa como ([0, 1, 1, 0]), es linealmente dependiente, ya que puede escribirse como la suma de los vectores ([0, 1, 0, 0]) y ([0, 0, 1, 0]).

#### ¬øQu√© implicaciones tiene la dependencia lineal en una matriz?

La presencia de vectores linealmente dependientes en una matriz tiene consecuencias significativas. Principalmente, esto implica que no se puede calcular la inversa de dicha matriz, y es conocida como una matriz singular. Probemos calcular la inversa de nuestra matriz ( A ).

```python
from numpy.linalg import LinAlgError

try:
    A_inv = np.linalg.inv(A)
except LinAlgError:
    print("La matriz es singular y no tiene inversa.")
```

Esta singularidad se debe a la presencia de al menos un vector que es una combinaci√≥n lineal de otros vectores de la matriz. Si removemos los vectores dependientes, la matriz resultante perder√≠a su forma cuadrada, al no tener la misma cantidad de filas y columnas.

#### Estrategias para identificar vectores dependientes

Otra estrategia es analizar las columnas de la matriz. En el ejemplo presentado, observamos que la primera y la cuarta columna son id√©nticas, indicando que una depende de la otra. La eliminaci√≥n de estas similitudes puede facilitar la conversi√≥n de la matriz en una versi√≥n cuadrada y funcional para encontrar soluciones a los sistemas de ecuaciones.

Conocer estas t√©cnicas no solo es √∫til para las matem√°ticas te√≥ricas, sino que tambi√©n se aplica en diversos campos donde los sistemas de ecuaciones lineales juegan un papel fundamental, como la ingenier√≠a, la econom√≠a y las ciencias computacionales. ¬°Contin√∫a explorando este fascinante mundo de las matrices y descubre c√≥mo puedes aplicar estos conocimientos!

## Propiedades y C√°lculo de la Norma de un Vector

¬°Claro! Vamos a ver en detalle qu√© es la **norma de un vector**, c√≥mo se **calcula**, y qu√© **propiedades** importantes tiene. Adem√°s, te muestro c√≥mo implementarlo en **Python**.

### ‚úÖ ¬øQu√© es la norma de un vector?

La **norma** de un vector mide su **magnitud** o ‚Äúlongitud‚Äù en el espacio. Se denota por:

$$
\|\vec{v}\|
$$

Para un vector $\vec{v} = (v_1, v_2, ..., v_n)$, la **norma euclidiana (L2)** se define como:

$$
\|\vec{v}\| = \sqrt{v_1^2 + v_2^2 + \cdots + v_n^2}
$$

### üìè Tipos de normas comunes

| Nombre           | F√≥rmula                             | Notaci√≥n   |   |                       |
| ---------------- | ----------------------------------- | ---------- | - | --------------------- |
| Norma L2         | $\|\vec{v}\|_2 = \sqrt{\sum v_i^2}$ | Euclidiana |   |                       |
| Norma L1         | ( \|\vec{v}\|\_1 = \sum             | v\_i       | ) | Manhattan / Taxicab   |
| Norma $L_\infty$ | ( \|\vec{v}\|\_\infty = \max        | v\_i       | ) | M√°ximo valor absoluto |

### üß† Propiedades de la norma

Sea $\vec{u}, \vec{v} \in \mathbb{R}^n$ y $\alpha \in \mathbb{R}$, entonces:

1. **Positividad**:

   $$
   \|\vec{v}\| \geq 0,\quad \text{y} \quad \|\vec{v}\| = 0 \iff \vec{v} = \vec{0}
   $$

2. **Homogeneidad (escalar)**:

   $$
   \|\alpha \vec{v}\| = |\alpha| \cdot \|\vec{v}\|
   $$

3. **Desigualdad triangular**:

   $$
   \|\vec{u} + \vec{v}\| \leq \|\vec{u}\| + \|\vec{v}\|
   $$

### üßÆ C√°lculo de la norma en Python

```python
import numpy as np

# Vector en R3
v = np.array([3, 4, 12])

# Norma Euclidiana (L2)
norma_l2 = np.linalg.norm(v)

# Norma L1
norma_l1 = np.linalg.norm(v, ord=1)

# Norma infinito
norma_inf = np.linalg.norm(v, ord=np.inf)

print("Norma L2 (Euclidiana):", norma_l2)
print("Norma L1 (Manhattan):", norma_l1)
print("Norma Infinito:", norma_inf)
```

**Salida esperada:**

```
Norma L2 (Euclidiana): 13.0
Norma L1 (Manhattan): 19
Norma Infinito: 12
```

### üìå Aplicaciones pr√°cticas

* üîç **An√°lisis de errores**: distancia entre predicciones y datos reales.
* üß† **Normalizaci√≥n de datos** en machine learning.
* üß≠ **Direcci√≥n y magnitud** en f√≠sica.
* üíª **Reducci√≥n de dimensiones** y compresi√≥n de informaci√≥n.
* üìâ **Medida de similitud** entre vectores.

### üéØ Extra: Normalizar un vector

Para obtener un vector **unitario** (longitud 1) en la misma direcci√≥n:

```python
v_unitario = v / np.linalg.norm(v)
print("Vector normalizado:", v_unitario)
print("Norma del vector normalizado:", np.linalg.norm(v_unitario))  # Siempre 1
```

### Resumen

#### ¬øQu√© es la Norma de un vector y por qu√© es importante?

La Norma de un vector es una herramienta matem√°tica clave para medir el tama√±o de un vector. Esta medida se representa mediante un n√∫mero que siempre es cero o positivo. La Norma ayuda a determinar aspectos cr√≠ticos, como el error en aproximaciones o la efectividad en clasificaciones. En este contexto, es vital conocer las propiedades de la Norma para aplicarlas correctamente.

#### ¬øCu√°les son las propiedades de la Norma?

1. **Nunca negativa**: La Norma de cualquier vector nunca es negativa. Puede ser cero si el vector se encuentra exactamente en el origen, y este es el √∫nico caso en que la Norma ser√° cero.

2. **Desigualdad triangular**: La suma de los vectores tiene una Norma que es siempre menor o igual a la suma de sus Normas individuales. Esto refleja el principio de que la distancia m√°s corta entre dos puntos es una l√≠nea recta.

3. **Escalar por un vector**: Cuando multiplicamos un vector por un escalar, la Norma del resultado es igual al valor absoluto del escalar multiplicado por la Norma del vector original.

#### ¬øC√≥mo calcular la Norma en Python?

Calcular la Norma de un vector en Python es sencillo con la librer√≠a `numpy`. A continuaci√≥n, mostramos c√≥mo realizar este c√°lculo utilizando un ejemplo pr√°ctico.

```python
import numpy as np

# Definimos los vectores
B1 = np.array([2, 7])
B2 = np.array([3, 5])

# Calculamos la suma de los vectores
B1_B2 = B1 + B2  # Resultado: array([5, 12])

# Calculamos la Norma de cada vector usando la funci√≥n `np.linalg.norm`
norma_B1 = np.linalg.norm(B1)
norma_B2 = np.linalg.norm(B2)
norma_B1_B2 = np.linalg.norm(B1_B2)

# Verificamos la desigualdad triangular
assert norma_B1_B2 <= norma_B1 + norma_B2
```

Este c√≥digo ayuda a visualizar la aplicaci√≥n de la desigualdad triangular y la medida de Normas individuales y conjuntas.

#### ¬øC√≥mo graficar vectores y su Norma en un plano?

Podemos visualizar la Norma y sus propiedades geom√©tricas en Python utilizando `matplotlib` para gr√°ficos y `seaborn` para opciones de color. Aqu√≠ se presenta una gu√≠a b√°sica para graficar vectores y comprender la desigualdad triangular visualmente.

```python
import matplotlib.pyplot as plt
import seaborn as sns

# Configuraci√≥n b√°sica para gr√°ficos
plt.figure(figsize=(8, 8))
sns.set(style="whitegrid")

# Definici√≥n de vectores y su origen
origen_B1 = np.array([0, 0]), B1
origen_B2 = np.array([0, 0]), B2
origen_suma = np.array([0, 0]), B1_B2

# Graficar vectores
plt.quiver(*origen_B1, angles='xy', scale_units='xy', scale=1, color=sns.color_palette("husl", 8)[1])
plt.quiver(*origen_B2, angles='xy', scale_units='xy', scale=1, color=sns.color_palette("husl", 8)[2])
plt.quiver(*origen_suma, angles='xy', scale_units='xy', scale=1, color=sns.color_palette("husl", 8)[0])

# Ajustar l√≠mites de los gr√°ficos
plt.xlim(-0.5, 6)
plt.ylim(-0.5, 15)

# Mostrar gr√°fico
plt.show()
```

Visualizar los vectores y su Norma permite una comprensi√≥n m√°s intuitiva de c√≥mo operan estas matem√°ticas en el espacio bidimensional. Cada vector y su suma se hacen evidentes, destacando la aplicaci√≥n de la desigualdad triangular.

¬°Contin√∫a explorando y experimentando con m√°s ejemplos para dominar estos conceptos fundamentales!

## C√°lculo de Normas en Python para Aprendizaje Autom√°tico

¬°Perfecto! El c√°lculo de **normas de vectores** es fundamental en **aprendizaje autom√°tico (machine learning)**, ya que se usa para medir distancias, errores, regularizaci√≥n y m√°s. A continuaci√≥n te explico c√≥mo y **por qu√©** se usan, y te muestro c√≥mo implementarlas en Python con ejemplos pr√°cticos.

### üß† ¬øPor qu√© usamos normas en Machine Learning?

1. **Distancia entre puntos**: para clasificar o agrupar datos (e.g. k-NN, clustering).
2. **Regularizaci√≥n**: para evitar sobreajuste en modelos (L1 y L2).
3. **Normalizaci√≥n de datos**: para escalar caracter√≠sticas y mejorar el entrenamiento.
4. **Evaluaci√≥n de errores**: en funciones de p√©rdida como MSE o MAE.

### üìè Normas m√°s utilizadas

| Norma               | F√≥rmula                             | Uso en ML                        |   |                               |
| ------------------- | ----------------------------------- | -------------------------------- | - | ----------------------------- |
| **L2 (Euclidiana)** | $\|\vec{x}\|_2 = \sqrt{\sum x_i^2}$ | Regularizaci√≥n Ridge, distancias |   |                               |
| **L1 (Manhattan)**  | ( \|\vec{x}\|\_1 = \sum             | x\_i                             | ) | Regularizaci√≥n Lasso, errores |
| **L‚àû (m√°ximo)**     | ( \|\vec{x}\|\_\infty = \max        | x\_i                             | ) | Detecci√≥n de outliers         |

### üß™ Ejemplo 1: Comparaci√≥n de normas en vectores

```python
import numpy as np

x = np.array([3, -4, 5])

l1 = np.linalg.norm(x, ord=1)
l2 = np.linalg.norm(x)            # por defecto ord=2
linf = np.linalg.norm(x, ord=np.inf)

print(f"L1: {l1:.2f} | L2: {l2:.2f} | L‚àû: {linf:.2f}")
```

**Salida:**

```
L1: 12.00 | L2: 7.07 | L‚àû: 5.00
```

### ü§ñ Ejemplo 2: Distancia entre vectores (e.g., k-NN)

```python
from sklearn.metrics import pairwise_distances

a = np.array([[1, 2]])
b = np.array([[4, 6]])

dist_euclid = pairwise_distances(a, b, metric='euclidean')
dist_manhat = pairwise_distances(a, b, metric='manhattan')

print("Distancia Euclidiana:", dist_euclid[0][0])
print("Distancia Manhattan:", dist_manhat[0][0])
```

### üß∞ Ejemplo 3: Regularizaci√≥n en regresi√≥n

```python
from sklearn.linear_model import Ridge, Lasso
from sklearn.datasets import make_regression
from sklearn.model_selection import train_test_split

# Datos sint√©ticos
X, y = make_regression(n_samples=100, n_features=5, noise=10, random_state=42)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)

# Regresi√≥n con regularizaci√≥n L2 (Ridge)
modelo_ridge = Ridge(alpha=1.0)
modelo_ridge.fit(X_train, y_train)
print("Coeficientes Ridge:", modelo_ridge.coef_)

# Regresi√≥n con regularizaci√≥n L1 (Lasso)
modelo_lasso = Lasso(alpha=0.1)
modelo_lasso.fit(X_train, y_train)
print("Coeficientes Lasso:", modelo_lasso.coef_)
```

* **Ridge** tiende a reducir los coeficientes.
* **Lasso** tiende a hacer que algunos sean exactamente **0** ‚Üí selecci√≥n de caracter√≠sticas.

### ‚úèÔ∏è Ejemplo 4: Normalizar vectores (unit norm)

```python
from sklearn.preprocessing import Normalizer

X = np.array([[3, 4], [1, -1], [0, 5]])

normalizador = Normalizer(norm='l2')  # tambi√©n acepta 'l1' o 'max'
X_norm = normalizador.fit_transform(X)

print("Vectores normalizados:\n", X_norm)
```

### ‚úÖ Conclusi√≥n

Las normas son herramientas esenciales en ML para:

* **Medir similitud o distancia** (clustering, k-NN).
* **Reducir el sobreajuste** (regularizaci√≥n L1/L2).
* **Escalar y preparar datos** (normalizaci√≥n).

### Resumen

#### ¬øQu√© son las normas y c√≥mo se utilizan en aprendizaje autom√°tico?

Las normas son herramientas fundamentales en el aprendizaje autom√°tico y otras √°reas de la ciencia de datos utilizadas para medir diversas propiedades de los vectores. Existen diferentes tipos de normas que se emplean para calcular errores, distancias y m√°s. En este art√≠culo, exploraremos las normas m√°s comunes y discutiremos c√≥mo se pueden implementar utilizando la biblioteca NumPy en Python. Las normas que abordaremos incluyen L0, L1, L2 y la norma infinita.

#### ¬øC√≥mo calcular la norma L0?

La norma L0 es la m√°s sencilla de entender: calcula la cantidad de elementos distintos de cero en un vector. Es √∫til para determinar elementos no nulos, por ejemplo, al evaluar la cantidad de compras realizadas por usuarios, donde cada componente del vector representa una compra. Este es el procedimiento para calcular la norma L0 en Python con NumPy:

```python
import numpy as np

# Definimos un vector
vector = np.array([1, 2, 0, 5, 6, 0])

# Calculamos la norma L0
norma_l0 = np.linalg.norm(vector, ord=0)

print(norma_l0)  # Devuelve 4, hay 4 elementos distintos de cero.
```

#### ¬øC√≥mo se calcula la norma L1?

La norma L1, tambi√©n conocida como norma de suma absoluta, entrega la suma de los valores absolutos de los componentes del vector. Esta norma cobra relevancia en situaciones donde necesitamos una medida que dependa linealmente de cada componente del vector:

```python
# Definimos un vector con valores positivos y negativos
vector = np.array([1, -1, 1, -1, 1])

# Calculamos la norma L1
norma_l1 = np.linalg.norm(vector, ord=1)

print(norma_l1)  # Devuelve 5, la suma de valores absolutos.
```

#### ¬øPor qu√© es importante la norma L2?

La norma L2 es probablemente la m√°s conocida. Est√° relacionada con la distancia euclidiana, la medida est√°ndar en geometr√≠a para calcular la distancia entre dos puntos en un espacio. Se utiliza ampliamente en aprendizaje autom√°tico debido a su simplicidad y eficacia computacional. Al elevar los componentes al cuadrado en lugar de tomar la ra√≠z cuadrada, es posible optimizar algoritmos para mejorar el rendimiento:

```python
# Definimos un vector
vector = np.array([1, 1])

# Calculamos la norma L2
norma_l2 = np.linalg.norm(vector)

print(norma_l2)  # Devuelve aproximadamente 1.41, la ra√≠z cuadrada de 2.

# Calculamos la norma L2 al cuadrado
norma_l2_squared = np.linalg.norm(vector) ** 2

print(norma_l2_squared)  # Devuelve 2.

# Tambi√©n se puede calcular usando el producto interno
norma_l2_squared_internal = np.dot(vector, vector)

print(norma_l2_squared_internal)  # Devuelve 2.
```

#### ¬øQu√© es la norma infinita y c√≥mo se calcula?

La norma infinita proporciona el valor absoluto m√°s grande de un vector. Es √∫til en situaciones en las que necesitamos detectar valores extremos que puedan ser significativos para un an√°lisis m√°s detallado. Su c√°lculo en Python es sencillo usando NumPy:

```python
# Definimos un vector con un valor prominente
vector = np.array([1, 2, 3, -100])

# Calculamos la norma infinita
norma_inf = np.linalg.norm(vector, ord=np.inf)

print(norma_inf)  # Devuelve 100, el valor absoluto m√°ximo del vector.
```

Las normas son herramientas vers√°tiles y potentes en el aprendizaje autom√°tico, desempe√±ando un papel crucial para evaluar diferentes aspectos de los datos de entrada. Su correcta aplicaci√≥n puede mejorar significativamente la eficiencia de los algoritmos. A medida que avances en tus estudios y aplicaciones de machine learning, comprender y utilizar estas normas te ser√° cada vez m√°s indispensable. ¬°Sigue aprendiendo y explorando el vasto mundo del aprendizaje autom√°tico!

## Producto Interno y √Ångulo entre Vectores en Python

En Python, puedes calcular el **producto interno (producto punto o "dot product")** y el **√°ngulo entre dos vectores** utilizando principalmente NumPy, una biblioteca muy eficiente para operaciones matem√°ticas.

### ‚úÖ 1. Producto Interno de Vectores

El **producto interno** entre dos vectores $\vec{a}$ y $\vec{b}$ se define como:

$$
\vec{a} \cdot \vec{b} = a_1b_1 + a_2b_2 + \dots + a_nb_n
$$

En Python:

```python
import numpy as np

a = np.array([1, 2, 3])
b = np.array([4, 5, 6])

producto_interno = np.dot(a, b)
print("Producto Interno:", producto_interno)
```

Salida:

```
Producto Interno: 32
```

### ‚úÖ 2. √Ångulo entre Vectores

El **√°ngulo** $\theta$ entre dos vectores se calcula con:

$$
\cos(\theta) = \frac{\vec{a} \cdot \vec{b}}{||\vec{a}|| \cdot ||\vec{b}||}
$$

$$
\theta = \arccos\left( \frac{\vec{a} \cdot \vec{b}}{||\vec{a}|| \cdot ||\vec{b}||} \right)
$$

C√≥digo en Python:

```python
from numpy import dot
from numpy.linalg import norm
from numpy import arccos, degrees

a = np.array([1, 2, 3])
b = np.array([4, 5, 6])

producto_interno = dot(a, b)
norma_a = norm(a)
norma_b = norm(b)

cos_theta = producto_interno / (norma_a * norma_b)
angulo_rad = arccos(cos_theta)
angulo_deg = degrees(angulo_rad)

print("√Ångulo en radianes:", angulo_rad)
print("√Ångulo en grados:", angulo_deg)
```

### ‚úÖ Resultado (con esos vectores):

```
√Ångulo en radianes: 0.2257261285527342
√Ångulo en grados: 12.9331544919
```

### Resumen

#### ¬øC√≥mo se relacionan las normas de los vectores y el producto interno con el √°ngulo que forman?

Para comprender c√≥mo interact√∫an los vectores, es esencial entender c√≥mo se relaciona el producto interno con las normas de los vectores y el √°ngulo que forman entre s√≠. Esta relaci√≥n puede simplificarse gracias a la f√≥rmula del producto interno.

Si consideramos dos vectores, ( V_1 ) y ( V_2 ), su producto interno ( V_1^T \cdot V_2 ) se puede expresar como el producto de sus normas multiplicado por el coseno del √°ngulo que forman. Es decir:

[ V_1^T \cdot V_2 = |V_1|_2 \cdot |V_2|_2 \cdot \cos(\theta) ]

Este enfoque no solo simplifica los c√°lculos algebraicos, sino que proporciona un entendimiento conceptual m√°s intuitivo sobre c√≥mo se relacionan los vectores en el espacio.

#### ¬øC√≥mo podemos visualizar vectores y sus relaciones en Python?

Visualizar vectores y entender sus relaciones es esencial para aquellos que trabajan con √°lgebra lineal. Python nos ofrece herramientas √∫tiles como Matplotlib y NumPy para crear gr√°ficos que representan vectores en un plano.

1. **Definici√≥n de vectores**:

```python
import numpy as np
import matplotlib.pyplot as plt

# Definimos los vectores
V1 = np.array([0, 3])
V2 = np.array([3, 3])
```

2. **Gr√°fica de vectores**:

```python
plt.figure()
plt.xlim(-2, 6)
plt.ylim(-2, 6)

origin = np.array([0, 0])
plt.quiver(*origin, *V1, angles='xy', scale_units='xy', scale=1, color='r')
plt.quiver(*origin, *V2, angles='xy', scale_units='xy', scale=1, color='b')

plt.grid()
plt.show()
```

Esta visualizaci√≥n nos permitir√° observar la configuraci√≥n espacial de nuestros vectores, entendiendo mejor el √°ngulo que forman y la interacci√≥n entre ellos.

#### ¬øC√≥mo corroborar la igualdad entre el producto interno y otras expresiones?

Una vez visualizados los vectores, se pueden realizar verificaciones matem√°ticas para confirmar la igualdad entre el producto interno calculado y otras expresiones utilizando las normas y el coseno del √°ngulo.

1. **C√°lculo del producto interno**:

`producto_interno = np.dot(V1, V2)`

2. **C√°lculo de las normas**:

```python
norma_V1 = np.linalg.norm(V1)
norma_V2 = np.linalg.norm(V2)
```

3. **Uso del coseno del √°ngulo**:

```python
angulo_rad = np.arccos(np.dot(V1, V2) / (norma_V1 * norma_V2))
coseno_angulo = np.cos(angulo_rad)
```

4. **Verificaci√≥n de la igualdad**:

`igualdad_verificada = norma_V1 * norma_V2 * coseno_angulo`

Al evaluar estas expresiones, confirmamos la validez de nuestra comprensi√≥n algebraica y geom√©trica.

#### ¬øPor qu√© es √∫til conocer el √°ngulo entre vectores en machine learning?

En el contexto de machine learning, conocer el √°ngulo entre vectores es crucial debido a la similitud coseno. Esta medida ayuda a identificar el grado de similitud entre documentos o conjuntos de datos.

- **Similitud coseno**: Si dos vectores que representan documentos tienen un √°ngulo peque√±o, sus textos son similares.
- **√Ångulos de 90 grados**: Indican que los documentos son completamente diferentes.

La comprensi√≥n y aplicaci√≥n de estos conceptos permiten a los profesionales de machine learning mejorar las t√©cnicas de an√°lisis de datos, facilitando una evaluaci√≥n m√°s precisa de patrones y relaciones en grandes vol√∫menes de informaci√≥n.

Aprender a representar y analizar estos mecanismos te permitir√° avanzar en campos tan diversos como el procesamiento del lenguaje natural, la visi√≥n por computadora y otras √°reas donde las matem√°ticas y la representaci√≥n espacial juegan un papel fundamental. ¬°Sigue aprendiendo y explorando las infinitas posibilidades que estos conocimientos traen consigo!

## Matrices Diagonales y Sim√©tricas: Propiedades y Aplicaciones

Claro, aqu√≠ tienes una explicaci√≥n clara y pr√°ctica sobre **Matrices Diagonales y Sim√©tricas**, incluyendo sus **propiedades**, **aplicaciones** y c√≥mo trabajarlas en **Python** con `NumPy`.

### üü¶ 1. Matrices Diagonales

### üîπ Definici√≥n

Una **matriz diagonal** es una matriz cuadrada donde **todos los elementos fuera de la diagonal principal son cero**.

Ejemplo:

$$
D = \begin{bmatrix}
3 & 0 & 0 \\
0 & 5 & 0 \\
0 & 0 & 7
\end{bmatrix}
$$

### üîπ Propiedades

* $D = D^T$ (tambi√©n es **sim√©trica**)
* Producto de matrices diagonales ‚Üí otra matriz diagonal.
* Inversa (si todos los elementos diagonales ‚â† 0) tambi√©n es diagonal.
* F√°cil de **elevar a una potencia**: eleva cada elemento diagonal por separado.
* El **determinante** es el producto de los elementos de la diagonal.

### üîπ Aplicaciones

* Escalado de vectores.
* Simulaciones f√≠sicas.
* M√©todos num√©ricos (por su eficiencia computacional).
* Simplifican la descomposici√≥n espectral de matrices.

### üîπ En Python

```python
import numpy as np

# Crear una matriz diagonal
D = np.diag([3, 5, 7])
print("Matriz Diagonal:\n", D)

# Potencia de matriz diagonal
D2 = np.diag([x**2 for x in [3, 5, 7]])
print("D al cuadrado:\n", D2)
```

### üü¶ 2. Matrices Sim√©tricas

### üîπ Definici√≥n

Una **matriz sim√©trica** es una matriz cuadrada que **es igual a su transpuesta**:

$$
A = A^T
$$

Ejemplo:

$$
A = \begin{bmatrix}
2 & -1 & 0 \\
-1 & 3 & 1 \\
0 & 1 & 4
\end{bmatrix}
$$

### üîπ Propiedades

* Todos sus **autovalores son reales**.
* Se puede **diagonalizar** mediante una base ortonormal (teorema espectral).
* Si es definida positiva, se usa en optimizaci√≥n y aprendizaje autom√°tico.
* El producto $A = B B^T$ siempre da una sim√©trica.

### üîπ Aplicaciones

* √Ålgebra lineal (autovalores y autovectores).
* Optimizaci√≥n cuadr√°tica.
* An√°lisis de correlaci√≥n y covarianza en estad√≠stica.
* Ingenier√≠a estructural y sistemas f√≠sicos conservativos.

### üîπ En Python

```python
A = np.array([[2, -1, 0],
              [-1, 3, 1],
              [0, 1, 4]])

# Verificar si es sim√©trica
es_simetrica = np.allclose(A, A.T)
print("¬øEs sim√©trica?", es_simetrica)
```

### üß† Conclusi√≥n

| Tipo de Matriz | Propiedades clave                 | Aplicaciones comunes                              |
| -------------- | --------------------------------- | ------------------------------------------------- |
| **Diagonal**   | Solo elementos en la diagonal ‚â† 0 | Escalado, simplificaci√≥n de sistemas, computaci√≥n |
| **Sim√©trica**  | Igual a su transpuesta $A = A^T$  | √Ålgebra lineal, estad√≠sticas, f√≠sica, ML          |

### Resumen

#### ¬øQu√© son las matrices diagonales?

Las matrices diagonales son un tipo especial de matrices que tienen un valor num√©rico en cada una de las posiciones de su diagonal principal, mientras que todos los dem√°s elementos fuera de esta diagonal son cero. Estas matrices son de gran importancia en el √°lgebra lineal debido a su simplicidad y caracter√≠sticas √∫nicas. Pueden no necesariamente ser cuadradas, es decir, tener el mismo n√∫mero de filas y columnas, aunque las matrices diagonales cuadradas son las m√°s comunes y estudiadas.

#### ¬øC√≥mo representamos una matriz diagonal en Python?

En Python, las matrices diagonales se pueden crear f√°cilmente utilizando librer√≠as como `numpy`. A continuaci√≥n, se muestra c√≥mo crear una matriz diagonal:

```python
import numpy as np

# Definimos un vector con elementos 1, 2, 3, 4 y 5
vector = np.array([1, 2, 3, 4, 5])

# Creaci√≥n de una matriz diagonal a partir del vector
matriz_diagonal = np.diag(vector)

print(matriz_diagonal)
```

La matriz resultante tendr√° los elementos del vector en su diagonal principal y ceros en el resto de las posiciones.

#### ¬øPor qu√© las matrices diagonales facilitan las multiplicaciones con vectores?

Una de las particularidades de las matrices diagonales es que al multiplicarlas por un vector, no se realiza una combinaci√≥n lineal compleja de las distintas coordenadas. En cambio, cada elemento del vector es simplemente multiplicado por el correspondiente elemento diagonal. Este hecho hace que las matrices diagonales resulten √∫tiles y sencillas al realizar c√°lculos.

Por ejemplo:

```python
# Matriz diagonal con elementos en la diagonal 2, 3, 4, 5
matriz = np.diag([2, 3, 4, 5])

# Definimos un vector con todos unos
vector_unos = np.ones(4)

# Producto de la matriz con el vector
resultado = matriz.dot(vector_unos)

print(resultado)
```

El resultado ser√° un vector donde cada elemento es la multiplicaci√≥n directa de los componentes originales del vector por los elementos en la diagonal de la matriz.

#### ¬øC√≥mo se calcula la inversa de una matriz diagonal?

Calcular la inversa de una matriz diagonal es simple. La inversa de una matriz diagonal es otra matriz diagonal donde cada elemento en la diagonal es el inverso multiplicativo (es decir, 1 dividido por el elemento) del elemento en la matriz original.

#### Implementaci√≥n en Python

Para demostrarlo con Python:

```python
# Calculamos la inversa de una matriz diagonal
matriz_inversa = np.diag([1/2, 1/3, 1/4, 1/5])

# Producto interno para verificar que es la inversa
identidad = matriz.dot(matriz_inversa)

print(identidad)
```

El resultado deber√≠a ser una matriz identidad, confirmando as√≠ que se ha calculado correctamente la inversa.

#### ¬øQu√© caracteriza a las matrices sim√©tricas?

Una matriz es sim√©trica si es igual a su transpuesta. Esto implica que los elementos situados en posiciones coincidentes con respecto a su diagonal principal son iguales. Para una matriz general, esto es m√°s complicado que para las matrices diagonales, ya que estas √∫ltimas son siempre sim√©tricas por definici√≥n: tienen ceros tanto abajo como arriba de la diagonal principal.

##### Ejemplo de matriz sim√©trica

```python
# Definimos una matriz sim√©trica
matriz_simetrica = np.array([[1, 2, 3], 
                             [2, -1, 7], 
                             [3, 7, 11]])

# Transpuesta de la matriz
transpuesta = matriz_simetrica.T

# Verificamos si la matriz es sim√©trica
es_simetrica = np.array_equal(matriz_simetrica, transpuesta)

print(es_simetrica)
```

Esta verificaci√≥n nos muestra que efectivamente la matriz definida es sim√©trica ya que es igual a su transpuesta.

Aprender sobre matrices diagonales y sim√©tricas enriquece nuestra comprensi√≥n y capacidad de trabajar m√°s eficientemente con el √°lgebra lineal. ¬°Sigue explorando estas fascinantes herramientas matem√°ticas!

## Vectores ortogonales y ortonormales: conceptos y c√°lculos en Python

¬°Perfecto! Hablemos de **vectores ortogonales** y **ortonormales**, dos conceptos clave en √°lgebra lineal y esenciales en √°reas como machine learning, gr√°ficos 3D y procesamiento de se√±ales.

### üü© 1. Conceptos

### ‚úÖ Vectores Ortogonales

Dos vectores son **ortogonales** si su **producto interno es cero**:

$$
\vec{a} \cdot \vec{b} = 0
$$

Esto significa que forman un √°ngulo de 90¬∞ (perpendiculares).

### ‚úÖ Vectores Ortonormales

Son vectores que son:

* **Ortogonales entre s√≠**, y
* **De norma 1** (es decir, est√°n normalizados).

$$
\|\vec{a}\| = 1 \quad \text{y} \quad \vec{a} \cdot \vec{b} = 0
$$

Un conjunto ortonormal forma una **base ortonormal**.

### üü¶ 2. C√°lculos en Python (usando `NumPy`)

### üîπ Verificar ortogonalidad

```python
import numpy as np

a = np.array([1, 0])
b = np.array([0, 1])

producto = np.dot(a, b)
print("Producto interno:", producto)
print("¬øOrtogonales?", np.isclose(producto, 0))
```

### üîπ Normalizar un vector

```python
def normalizar(v):
    return v / np.linalg.norm(v)

v = np.array([3, 4])
v_normalizado = normalizar(v)
print("Vector normalizado:", v_normalizado)
print("Norma:", np.linalg.norm(v_normalizado))  # Debe ser 1
```

### üîπ Verificar ortonormalidad

```python
a = np.array([1, 0])
b = np.array([0, 1])

norma_a = np.linalg.norm(a)
norma_b = np.linalg.norm(b)
producto = np.dot(a, b)

es_ortonormal = np.isclose(norma_a, 1) and np.isclose(norma_b, 1) and np.isclose(producto, 0)
print("¬øOrtonormales?", es_ortonormal)
```

### üüß 3. Aplicaciones

| Campo               | Aplicaci√≥n de ortogonalidad y ortonormalidad          |
| ------------------- | ----------------------------------------------------- |
| Machine Learning    | PCA (componentes principales), reducci√≥n de dimensi√≥n |
| Computaci√≥n gr√°fica | Sistemas de coordenadas en 3D, rotaciones             |
| Se√±ales y sonido    | Transformadas como FFT y DCT usan bases ortonormales  |
| √Ålgebra lineal      | Descomposici√≥n QR, ortogonalizaci√≥n de Gram-Schmidt   |

### üü® 4. Extra: Ortonormalizaci√≥n con Gram-Schmidt (en Python)

```python
def gram_schmidt(vectores):
    ortonormales = []
    for v in vectores:
        for u in ortonormales:
            v = v - np.dot(v, u) * u
        v = v / np.linalg.norm(v)
        ortonormales.append(v)
    return np.array(ortonormales)

vecs = np.array([[1.0, 1.0], [1.0, -1.0]])
ortonormales = gram_schmidt(vecs)

print("Vectores ortonormales:\n", ortonormales)
```

### Resumen

#### ¬øQu√© son los vectores ortogonales y c√≥mo identificarlos en Python?

Los vectores ortogonales son un concepto fundamental en √°lgebra lineal, esencial para m√∫ltiples aplicaciones en el an√°lisis de datos y la computaci√≥n gr√°fica. Dos vectores son ortogonales si el √°ngulo entre ellos es de 90 grados ‚Äîen otras palabras, son perpendiculares. En este contenido, abordaremos c√≥mo identificar vectores ortogonales mediante c√°lculos en Python, proporcionando tanto los fundamentos te√≥ricos como las implementaciones pr√°cticas.

#### ¬øC√≥mo calcular vectores ortogonales?

Para determinar si dos vectores son ortogonales, el producto interno (o producto punto) entre ellos debe ser igual a cero. Este producto es una medida crucial que no solo nos informa del √°ngulo entre los vectores sino tambi√©n de su relaci√≥n en el espacio multidimensional.

```python
import numpy as np
import matplotlib.pyplot as plt

# Definimos los vectores
vector_x = np.array([2, 2])
vector_y = np.array([2, -2])

# Producto interno
producto_interno = np.dot(vector_x, vector_y)
print("Producto Interno:", producto_interno)

# Resultado: Producto Interno: 0
```

En este caso, dado que el producto interno es cero, podemos confirmar que los vectores `vector_x` y `vector_y` son ortogonales.

#### ¬øQu√© significa ser ortonormal?

El concepto de vectores ortonormales va un paso m√°s all√°. Un conjunto de vectores es ortonormal si son mutuamente ortogonales y, adem√°s, cada vector tiene una norma (o longitud) de uno. La normalizaci√≥n se consigue dividiendo cada vector por su propia norma.

```python
# Calculamos la norma de los vectores
norma_v1 = np.linalg.norm(vector_x)
norma_v2 = np.linalg.norm(vector_y)

# Verificamos si son ortonormales
print("Norma de vector_x:", norma_v1)
print("Norma de vector_y:", norma_v2)

# Normalizaci√≥n
vector_x_normal = vector_x / norma_v1
vector_y_normal = vector_y / norma_v2

# Nuevo Producto Interno (de vectores normalizados)
producto_interno_norm = np.dot(vector_x_normal, vector_y_normal)
print("Producto Interno Normalizado:", producto_interno_norm)

# Resultado: Los vectores normalizados pueden seguir siendo ortogonales si el producto sigue siendo 0
```

Al dividir cada vector por su norma, verificamos que el nuevo producto interno siga siendo cero, lo que conlleva que los vectores son ortonormales.

#### ¬øC√≥mo influye la dimensi√≥n del espacio en la ortogonalidad?

En el espacio de dimensi√≥n `n (R^n)`, el n√∫mero m√°ximo de vectores que pueden ser mutuamente ortogonales es `n`. Por ejemplo, en dos dimensiones (R^2), solo puede haber dos vectores mutuamente ortogonales, ya que cualquier intento de agregar un tercer vector requerir√≠a una dimensi√≥n adicional.

La ortogonalidad y ortonormalidad son pilares en √°reas como el an√°lisis de datos y el aprendizaje autom√°tico, donde te permiten simplificar c√°lculos al trabajar con bases ortogonales. Contin√∫a explorando aspectos avanzados de √°lgebra lineal, ya que cada elemento nuevo que aprendas te abrir√° m√°s posibilidades en el campo de la computaci√≥n y el an√°lisis de datos. ¬°Sigue adelante!

## atrices Ortogonales y Ortogonormalidad en Python

¬°Perfecto! Vamos a explorar **Matrices Ortogonales** y el concepto de **Ortonormalidad** desde lo te√≥rico y lo pr√°ctico en **Python** con ejemplos claros.

### ‚úÖ ¬øQu√© es una **Matriz Ortogonal**?

Una matriz cuadrada $Q \in \mathbb{R}^{n \times n}$ es **ortogonal** si:

$$
Q^T Q = Q Q^T = I
$$

Es decir:

* Su **transpuesta** es igual a su **inversa**:

  $$
  Q^{-1} = Q^T
  $$

* Las **columnas y filas** de $Q$ son **vectores ortonormales**:

  * **Ortogonales** entre s√≠ (producto punto = 0)
  * **Norma** igual a 1

### üéØ Propiedades Clave

| Propiedad                     | Explicaci√≥n                                |
| ----------------------------- | ------------------------------------------ |
| $Q^{-1} = Q^T$                | Inversa f√°cil de calcular                  |
| $\|Qx\| = \|x\|$              | Preserva la norma (rotaciones/reflexiones) |
| $\det(Q) = \pm 1$             | Conserva volumen / orientaci√≥n             |
| Columnas y filas ortonormales | Base ortonormal del espacio                |

### üß™ Ejemplo en Python ‚Äì Verificar Ortogonalidad

```python
import numpy as np

# Matriz de rotaci√≥n 90 grados en 2D
Q = np.array([[0, -1],
              [1,  0]])

# Verificar si Q^T @ Q = Identidad
es_ortogonal = np.allclose(Q.T @ Q, np.eye(2))

print("Q:\n", Q)
print("Q^T * Q:\n", Q.T @ Q)
print("¬øEs ortogonal?", es_ortogonal)
```

üìå **Salida esperada:**

```plaintext
Q^T * Q:
[[1. 0.]
 [0. 1.]]
¬øEs ortogonal? True
```

### üîß C√≥mo Construir una Matriz Ortogonal

La forma m√°s pr√°ctica es usar la **descomposici√≥n QR** de `scipy` o `numpy.linalg`.

```python
from scipy.linalg import qr

# Matriz aleatoria
A = np.random.rand(3, 3)

# Q = matriz ortogonal, R = triangular superior
Q, R = qr(A)

print("Matriz ortogonal Q:\n", Q)
print("¬øQ^T Q = I?", np.allclose(Q.T @ Q, np.eye(3)))
```

### üìè Validar Ortonormalidad Manualmente

```python
# Revisar columnas ortonormales
for i in range(Q.shape[1]):
    print(f"Norma columna {i}:", np.linalg.norm(Q[:, i]))

for i in range(Q.shape[1]):
    for j in range(i + 1, Q.shape[1]):
        print(f"Producto interno entre columna {i} y {j}:", np.dot(Q[:, i], Q[:, j]))
```

### üß† Aplicaciones

* **PCA** (An√°lisis de Componentes Principales)
* **Rotaciones** y **transformaciones geom√©tricas**
* **Descomposici√≥n QR**
* **Procesamiento de se√±ales**
* **Reducci√≥n de dimensionalidad**

### üéì Resumen

| Concepto            | Descripci√≥n                                               |
| ------------------- | --------------------------------------------------------- |
| Matriz ortogonal    | Transpuesta = inversa; columnas y filas ortonormales      |
| Ortonormalidad      | Vectores ortogonales entre s√≠ y de norma 1                |
| Verificaci√≥n Python | `Q.T @ Q == I`, `np.allclose(...)`, `np.linalg.norm(...)` |

### Resumen

#### ¬øQu√© es una matriz ortogonal?

Una matriz es considerada ortogonal cuando todas sus filas y columnas son mutuamente ortonormales. En t√©rminos de √°lgebra lineal, esto significa que, si nuestras filas y columnas son tratadas como vectores, estos deben ser mutuamente ortonormales. Veamos c√≥mo comprobar si una matriz es ortogonal utilizando Python y la biblioteca numpy.

#### ¬øC√≥mo construir una matriz ortogonal en Python?

Para ilustrar el concepto de matrices ortogonales, podemos hacer un ejemplo pr√°ctico usando Python y la biblioteca numpy. Python es ampliamente utilizado en la programaci√≥n matem√°tica debido a sus potentes bibliotecas como numpy para c√°lculos num√©ricos.

```python
import numpy as np

# Definimos una matriz de ejemplo
matrix = np.array([[1, 0, 0],
                   [0, 1, 0],
                   [0, 0, 1]])

# Imprimimos la matriz
print(matrix)
```

La matriz definida es la matriz identidad, que es trivialmente una matriz ortogonal.

#### ¬øC√≥mo comprobar si una matriz es ortogonal?

Para verificar que una matriz es ortogonal, debemos:

1. **Comprobar ortogonalidad de las columnas**: Todas las columnas deben ser ortogonales entre s√≠, lo cual implica que el producto interno de cualquier par de columnas distintas sea cero.
2. **Validar sus normas**: Cada columna debe tener norma uno.

#### Verificaci√≥n de ortogonalidad de las columnas

```python
# Producto interno de columnas
dot_product_12 = np.dot(matrix[:, 0], matrix[:, 1])
dot_product_13 = np.dot(matrix[:, 0], matrix[:, 2])
dot_product_23 = np.dot(matrix[:, 1], matrix[:, 2])

print(dot_product_12, dot_product_13, dot_product_23)  # Deber√≠a ser 0
```

####Validaci√≥n de las normas de las columnas

```python
norm_col1 = np.linalg.norm(matrix[:, 0])
norm_col2 = np.linalg.norm(matrix[:, 1])
norm_col3 = np.linalg.norm(matrix[:, 2])

print(norm_col1, norm_col2, norm_col3)  # Deber√≠a ser 1
```

Los vectores son ortonormales si tienen norma 1, como vemos en el ejemplo anterior.

#### ¬øQu√© es una matriz ortonormal?
Aunque comunmente los t√©rminos "matriz ortogonal" y "ortonormal" se usan indistintamente, t√©cnicamente todas las matrices ortogonales consisten en vectores ortonormales. No hay necesidad de distinguir entre los dos t√©rminos, ya que cualquier matriz ortogonal tiene por definici√≥n vectores ortonormales.

#### ¬øC√≥mo generar matrices ortogonales con Python y trigonometr√≠a?

Podemos usar funciones trigonom√©tricas para generar matrices ortogonales. Veamos un ejemplo usando las funciones seno y coseno:

```python
theta = np.pi / 4  # √Ångulo de 45 grados

# Definici√≥n de la matriz
matrix = np.array([[np.cos(theta), -np.sin(theta)],
                   [np.sin(theta), np.cos(theta)]])

print(matrix)
```

Ahora, para verificar la propiedad ortogonal, podemos comprobar que la multiplicaci√≥n de la matriz por su transpuesta da como resultado la matriz identidad:

```python
# Calcular transpuesta y multiplicar
transpose = matrix.T
identity_check = np.dot(transpose, matrix)

print(identity_check)  # Deber√≠a ser la matriz identidad
```

La pr√°ctica de construir y verificar matrices ortogonales nos ayuda a comprender y aplicar estos conceptos en problemas matem√°ticos reales, a la vez que desarrollamos cuidado al trabajar con c√°lculos num√©ricos en Python, evitando la amplificaci√≥n de errores debido a imprecisiones computacionales. ¬°Sigue explorando la magia de las matem√°ticas y la programaci√≥n!

## Propiedades de la Traza y el Determinante en Matrices

Claro, aqu√≠ tienes una explicaci√≥n completa y clara sobre las **propiedades de la traza** y el **determinante** en matrices, √∫tiles tanto en teor√≠a como en programaci√≥n (por ejemplo, en Python con NumPy).

### üî∑ 1. **Traza de una Matriz** (`trace`)

### üìå Definici√≥n

La **traza** de una matriz cuadrada $A \in \mathbb{R}^{n \times n}$ es la suma de los elementos de su **diagonal principal**:

$$
\text{tr}(A) = \sum_{i=1}^{n} a_{ii}
$$

### üìã Propiedades de la Traza

| Propiedad                    | Explicaci√≥n                                                                             |
| ---------------------------- | --------------------------------------------------------------------------------------- |
| **Linealidad**               | $\text{tr}(A + B) = \text{tr}(A) + \text{tr}(B)$                                        |
|                              | $\text{tr}(cA) = c \cdot \text{tr}(A)$                                                  |
| **C√≠clica para productos**   | $\text{tr}(AB) = \text{tr}(BA)$ (pero **no** $\text{tr}(ABC) = \text{tr}(CAB)$ siempre) |
| **Invariante por semejanza** | $\text{tr}(P^{-1}AP) = \text{tr}(A)$                                                    |
| **Suma de autovalores**      | $\text{tr}(A) = \lambda_1 + \lambda_2 + \dots + \lambda_n$                              |

### üî∂ 2. **Determinante de una Matriz** (`det`)

### üìå Definici√≥n

El **determinante** es un escalar asociado a una matriz cuadrada que representa:

* El **escala** de √°rea o volumen al aplicar la transformaci√≥n lineal.
* Si la matriz es **invertible**:

  * $\det(A) \neq 0$: **invertible**
  * $\det(A) = 0$: **singular** (no invertible)

### üìã Propiedades del Determinante

| Propiedad                                        | Explicaci√≥n                                            |
| ------------------------------------------------ | ------------------------------------------------------ |
| **Multiplicaci√≥n de matrices**                   | $\det(AB) = \det(A)\det(B)$                            |
| **Determinante de transpuesta**                  | $\det(A^T) = \det(A)$                                  |
| **Cambio de filas**                              | Cambiar dos filas invierte el signo del determinante   |
| **Fila multiplicada por escalar**                | Multiplica el determinante por ese escalar             |
| **Determinante de matriz triangular o diagonal** | Producto de elementos diagonales                       |
| **Inversa**                                      | $\det(A^{-1}) = 1 / \det(A)$, si $A$ es invertible     |
| **Producto de autovalores**                      | $\det(A) = \lambda_1 \cdot \lambda_2 \cdots \lambda_n$ |

### üß™ Ejemplo en Python

```python
import numpy as np
from numpy.linalg import det, eig

A = np.array([[4, 2],
              [1, 3]])

# Traza
print("Traza:", np.trace(A))

# Determinante
print("Determinante:", det(A))

# Autovalores
valores, _ = eig(A)
print("Autovalores:", valores)
print("Suma autovalores:", np.sum(valores))
print("Producto autovalores:", np.prod(valores))
```

üìå Resultado esperado:

```
Traza: 7        # 4 + 3
Determinante: 10  # 4*3 - 2*1
Suma autovalores: ‚âà 7
Producto autovalores: ‚âà 10
```

### üß† Resumen

| Concepto         | Relaci√≥n clave                                  |
| ---------------- | ----------------------------------------------- |
| **Traza**        | Suma de la diagonal = Suma de autovalores       |
| **Determinante** | √Årea/volumen escalado = Producto de autovalores |
| **Ambos**        | Invariantes por transformaci√≥n de base          |

### Resumen

#### ¬øQu√© es la traza de una matriz y por qu√© es importante?

La traza de una matriz es una propiedad que siempre devuelve el mismo n√∫mero, sin importar el sistema de referencia utilizado para expresar la matriz. Este valor fijo se obtiene sumando los elementos de la diagonal principal de la matriz. Por ejemplo, si usamos Python y NumPy para definir una matriz de 3x3 y calcular su traza, obtendremos un resultado que es la suma de los elementos de la diagonal. Aunque la matriz tenga una transformaci√≥n en el espacio, la traza permanecer√° inalterada.

#### Ejemplo de c√°lculo de traza con Python y NumPy

```python
import numpy as np

# Definimos una matriz
matriz = np.array([[1, 2, 3], 
                   [4, 5, 6], 
                   [7, 8, 9]])

# Calculamos la traza
traza = np.trace(matriz)

print(traza)  # Salida: 15
```

En este ejemplo, el valor 15 es la suma de los elementos 1, 5 y 9 de la diagonal principal, independientemente de las transformaciones que se realicen.

#### ¬øC√≥mo influye el determinante de una matriz en las transformaciones espaciales?

El determinante de una matriz brinda informaci√≥n sobre la transformaci√≥n que ejerce la matriz en el espacio. Si el determinante es negativo, la matriz ejerce una transformaci√≥n que refleja el espacio, como un espejo. Un determinante positivo generalmente implica una ampliaci√≥n o reducci√≥n homog√©nea, mientras que un determinante cero indica que la matriz comprime el espacio hasta un plano de menor dimensi√≥n.

#### Ejemplo de reflexi√≥n con determinante negativo

Para ilustrar esto, podemos utilizar Python y NumPy para crear una matriz cuya transformaci√≥n refleje el espacio a trav√©s de un determinante negativo.

```python
import numpy as np

# Definimos nuestros vectores base
b1 = np.array([0, 1])
b2 = np.array([1, 0])

# Definimos una matriz que provocar√° un reflejo
A = np.array([[-2, 0], 
              [0, 2]])

# Calculamos el determinante
determinante = np.linalg.det(A)

print(determinante)  # Salida: -4
```

Un determinante de -4 indica una inversi√≥n en una de las coordenadas que resulta en un reflejo espacial.

#### ¬øQu√© efectos tiene una matriz con diferentes determinantes?

Examinemos el impacto de dos matrices‚Äîuna con un determinante positivo y otra con un negativo‚Äîusando Python para comprender c√≥mo modifican el espacio en t√©rminos de rotaci√≥n y escala. Sin embargo, esta exploraci√≥n deja claro que conocer el determinante no es suficiente para obtener un panorama completo de la transformaci√≥n espacial, ya que no revela todas las caracter√≠sticas, como posibles rotaciones de los ejes.

#### Comparaci√≥n de transformaciones espaciales

```python
import numpy as np

# Matriz con determinante positivo
matriz_pos = np.array([[2, 0],
                      [0, 2]])

# Matriz con determinante negativo
matriz_neg = np.array([[-2, 0],
                       [0, 2]])

# Calculamos los determinantes
det_pos = np.linalg.det(matriz_pos)
det_neg = np.linalg.det(matriz_neg)

print(det_pos)  # Salida: 4
print(det_neg)  # Salida: -4
```

Ambas matrices alteran el espacio por un factor de cuatro, pero presentan diferencias importantes en la transformaci√≥n espacial, especialmente en cuanto a orientaci√≥n y reflejo.

Estas propiedades matem√°ticas de la traza y el determinante son fundamentales para las aplicaciones en √°lgebra lineal, ofreciendo conocimientos profundos sobre c√≥mo las matrices afectan el espacio. Si te interesa aprender m√°s sobre el uso de matrices y sus propiedades, te recomendamos seguir explorando estos temas y practicando con diferentes ejemplos pr√°cticos.

## Elementos B√°sicos del √Ålgebra Lineal: Escalares, Vectores y Matrices

### üü° 1. **Escalares**

### ‚úÖ Definici√≥n

Un **escalar** es un n√∫mero real o complejo. Representa una cantidad con magnitud, **pero sin direcci√≥n**.

Ejemplos:

* $a = 3$
* $\pi = 3.1416$
* $\lambda = -7$

Se usan para:

* Escalar vectores/matrices (multiplicarlos)
* Representar magnitudes, pesos, coeficientes, etc.

### üìå En Python:

```python
escalar = 5
```

### üîµ 2. **Vectores**

### ‚úÖ Definici√≥n

Un **vector** es una secuencia ordenada de n√∫meros (componentes) que **tienen direcci√≥n y magnitud**.

Ejemplo en 2D:

$$
\vec{v} = \begin{bmatrix} 3 \\ 4 \end{bmatrix}
$$

### ‚úÖ Tipos:

* **Columnas**: $n \times 1$
* **Filas**: $1 \times n$

### üìå Operaciones b√°sicas:

* **Suma**: componente a componente.
* **Producto por escalar**: multiplica cada componente.
* **Norma** (longitud): $\|\vec{v}\| = \sqrt{v_1^2 + v_2^2 + \dots}$

### üìå En Python:

```python
import numpy as np

v = np.array([3, 4])
print("Norma:", np.linalg.norm(v))  # Resultado: 5.0
```

### üü¢ 3. **Matrices**

### ‚úÖ Definici√≥n

Una **matriz** es una **tabla rectangular** de n√∫meros organizados en **filas** y **columnas**.

Ejemplo:

$$
A = \begin{bmatrix}
1 & 2 \\
3 & 4
\end{bmatrix}
$$

### ‚úÖ Propiedades:

* Tama√±o: $m \times n$ (m filas, n columnas)
* Pueden representar:

  * Sistemas de ecuaciones
  * Transformaciones lineales
  * Relaciones entre datos

### üìå Operaciones b√°sicas:

* **Suma y resta**
* **Multiplicaci√≥n** (entre matrices o con vectores)
* **Transpuesta** $A^T$
* **Determinante** y **inversa** (si es cuadrada)

### üìå En Python:

```python
A = np.array([[1, 2], [3, 4]])
B = np.array([[2, 0], [1, 2]])

# Multiplicaci√≥n de matrices
producto = A @ B
print("Producto:\n", producto)
```

### üß† Resumen Comparativo

| Elemento | Representa           | Ejemplo                  | En Python                 |
| -------- | -------------------- | ------------------------ | ------------------------- |
| Escalar  | Magnitud (n√∫mero)    | $a = 7$                  | `a = 7`                   |
| Vector   | Direcci√≥n + magnitud | $[1, 2, 3]$              | `np.array([1,2,3])`       |
| Matriz   | Transformaci√≥n/datos | $2\times2$ o $m\times n$ | `np.array([[a,b],[c,d]])` |

## Elementos B√°sicos del √Ålgebra Lineal: Escalares, Vectores y Matrices

### üü° 1. **Escalares**

### ‚úÖ Definici√≥n

Un **escalar** es un n√∫mero real o complejo. Representa una cantidad con magnitud, **pero sin direcci√≥n**.

Ejemplos:

* $a = 3$
* $\pi = 3.1416$
* $\lambda = -7$

Se usan para:

* Escalar vectores/matrices (multiplicarlos)
* Representar magnitudes, pesos, coeficientes, etc.

### üìå En Python:

```python
escalar = 5
```

### üîµ 2. **Vectores**

### ‚úÖ Definici√≥n

Un **vector** es una secuencia ordenada de n√∫meros (componentes) que **tienen direcci√≥n y magnitud**.

Ejemplo en 2D:

$$
\vec{v} = \begin{bmatrix} 3 \\ 4 \end{bmatrix}
$$

### ‚úÖ Tipos:

* **Columnas**: $n \times 1$
* **Filas**: $1 \times n$

### üìå Operaciones b√°sicas:

* **Suma**: componente a componente.
* **Producto por escalar**: multiplica cada componente.
* **Norma** (longitud): $\|\vec{v}\| = \sqrt{v_1^2 + v_2^2 + \dots}$

### üìå En Python:

```python
import numpy as np

v = np.array([3, 4])
print("Norma:", np.linalg.norm(v))  # Resultado: 5.0
```

### üü¢ 3. **Matrices**

### ‚úÖ Definici√≥n

Una **matriz** es una **tabla rectangular** de n√∫meros organizados en **filas** y **columnas**.

Ejemplo:

$$
A = \begin{bmatrix}
1 & 2 \\
3 & 4
\end{bmatrix}
$$

### ‚úÖ Propiedades:

* Tama√±o: $m \times n$ (m filas, n columnas)
* Pueden representar:

  * Sistemas de ecuaciones
  * Transformaciones lineales
  * Relaciones entre datos

### üìå Operaciones b√°sicas:

* **Suma y resta**
* **Multiplicaci√≥n** (entre matrices o con vectores)
* **Transpuesta** $A^T$
* **Determinante** y **inversa** (si es cuadrada)

### üìå En Python:

```python
A = np.array([[1, 2], [3, 4]])
B = np.array([[2, 0], [1, 2]])

# Multiplicaci√≥n de matrices
producto = A @ B
print("Producto:\n", producto)
```

### üß† Resumen Comparativo

| Elemento | Representa           | Ejemplo                  | En Python                 |
| -------- | -------------------- | ------------------------ | ------------------------- |
| Escalar  | Magnitud (n√∫mero)    | $a = 7$                  | `a = 7`                   |
| Vector   | Direcci√≥n + magnitud | $[1, 2, 3]$              | `np.array([1,2,3])`       |
| Matriz   | Transformaci√≥n/datos | $2\times2$ o $m\times n$ | `np.array([[a,b],[c,d]])` |
