# Curso para Crear tus Proyectos de Ciencia de Datos

## C칩mo crear tu proyecto de ciencia de datos

En DS existe este marco de trabajo para el desarrollo de proyectos, se llama CRISP-DM

![CRISP-DM Process Diagram ](images/CRISP-DM_Process_Diagram.png)

## Crea proyectos para afianzar tus conocimientos en ciencia de datos

Aqu칤 tienes algunas ideas de proyectos que te ayudar치n a afianzar tus conocimientos en ciencia de datos. Estos proyectos var칤an en complejidad y cubren diferentes aspectos del an치lisis de datos, desde la recopilaci칩n de datos hasta la visualizaci칩n y el modelado. Puedes elegir los que m치s te interesen o incluso combinarlos.

### 1. An치lisis Exploratorio de Datos (EDA)
- **Descripci칩n**: Elige un conjunto de datos de plataformas como Kaggle o UCI Machine Learning Repository y realiza un an치lisis exploratorio de los datos.
- **Objetivos**:
  - Limpiar y preprocesar los datos.
  - Visualizar distribuciones, correlaciones y patrones utilizando bibliotecas como Matplotlib, Seaborn o Plotly.
  - Sacar conclusiones sobre las caracter칤sticas de los datos.

### 2. Predicci칩n de Ventas
- **Descripci칩n**: Utiliza datos de ventas hist칩ricos para construir un modelo que prediga las ventas futuras.
- **Objetivos**:
  - Recopilar datos de ventas (puedes usar datos p칰blicos).
  - Implementar t칠cnicas de regresi칩n lineal o modelos m치s avanzados como ARIMA.
  - Evaluar el modelo y realizar pron칩sticos.

### 3. Clasificaci칩n de Im치genes
- **Descripci칩n**: Construye un modelo de aprendizaje autom치tico para clasificar im치genes.
- **Objetivos**:
  - Usar un conjunto de datos de im치genes (como CIFAR-10 o MNIST).
  - Implementar una red neuronal convolucional (CNN) utilizando TensorFlow o PyTorch.
  - Evaluar la precisi칩n del modelo y optimizarlo.

### 4. An치lisis de Sentimientos
- **Descripci칩n**: Realiza un an치lisis de sentimientos en datos de redes sociales o rese침as de productos.
- **Objetivos**:
  - Recopilar datos de Twitter o rese침as de Amazon.
  - Preprocesar el texto y aplicar t칠cnicas de NLP (Natural Language Processing).
  - Construir un modelo de clasificaci칩n de sentimientos (positivo, negativo, neutral).

### 5. Sistema de Recomendaci칩n
- **Descripci칩n**: Desarrolla un sistema de recomendaci칩n para sugerir productos o contenido a los usuarios.
- **Objetivos**:
  - Utilizar un conjunto de datos de usuarios y elementos (como MovieLens o datos de productos de Amazon).
  - Implementar algoritmos de filtrado colaborativo o basado en contenido.
  - Evaluar la efectividad del sistema.

### 6. Visualizaci칩n de Datos Interactiva
- **Descripci칩n**: Crea un dashboard interactivo para visualizar datos utilizando herramientas como Tableau, Power BI o Dash.
- **Objetivos**:
  - Seleccionar un conjunto de datos interesante (por ejemplo, datos demogr치ficos o de salud).
  - Dise침ar visualizaciones interactivas que permitan a los usuarios explorar los datos.
  - Publicar el dashboard en la web.

### 7. Detecci칩n de Anomal칤as
- **Descripci칩n**: Construye un modelo que detecte anomal칤as en un conjunto de datos (por ejemplo, fraudes en transacciones).
- **Objetivos**:
  - Utilizar un conjunto de datos de transacciones (puedes usar datos simulados).
  - Implementar algoritmos de detecci칩n de anomal칤as como Isolation Forest o Local Outlier Factor.
  - Evaluar el rendimiento del modelo.

### 8. Proyectos de Web Scraping
- **Descripci칩n**: Recopila datos de sitios web utilizando t칠cnicas de web scraping.
- **Objetivos**:
  - Seleccionar un sitio web y definir qu칠 datos deseas extraer.
  - Utilizar bibliotecas como BeautifulSoup o Scrapy para obtener los datos.
  - Analizar y visualizar los datos recopilados.

### 9. Proyecto de Datos en Tiempo Real
- **Descripci칩n**: Crea un pipeline de datos que procese datos en tiempo real (por ejemplo, desde una API).
- **Objetivos**:
  - Recopilar datos en tiempo real utilizando APIs (como Twitter, OpenWeatherMap, etc.).
  - Procesar y almacenar datos en una base de datos.
  - Visualizar datos en tiempo real utilizando herramientas como Grafana o Streamlit.

### 10. Proyecto de Ciencia de Datos para el Bien Social
- **Descripci칩n**: Trabaja en un proyecto que tenga un impacto social, como el an치lisis de datos sobre salud p칰blica, medio ambiente o educaci칩n.
- **Objetivos**:
  - Identificar un problema social y recopilar datos relevantes.
  - Realizar un an치lisis y ofrecer recomendaciones basadas en los resultados.
  - Comunicar los hallazgos a trav칠s de un informe o presentaci칩n.

### Consejos Generales
- **Documentaci칩n**: Aseg칰rate de documentar tu proceso, incluyendo el c칩digo, las decisiones que tomaste y los resultados que obtuviste.
- **Versionamiento**: Utiliza un sistema de control de versiones como Git para gestionar tu c칩digo.
- **Comunicaci칩n**: Prepara una presentaci칩n o un informe para comunicar tus hallazgos de manera efectiva.

Estos proyectos no solo te ayudar치n a consolidar tus conocimientos en ciencia de datos, sino que tambi칠n te proporcionar치n material para tu portafolio, lo cual es valioso al buscar empleo en este campo. 춰Buena suerte con tus proyectos!

Debemos aprender a:

1. Generar preguntas interesantes

2. Obtener la informacion

3. Limpiar los datos

4. Enriquecer los datos que tenemos

5. Comunicar de manera efectiva nuetsro proyecto

## Cada cu치nto hacer un proyecto de datos

쮺ada cuanto debo de hacer un proyecto de ciencia de datos? Tan pronto como sea posible. TIPs: practicar es una buena actividad para continuar

- Es mejor poner las cosas en pr치ctica luego de terminar un curso.
- Practicar movilizado para sacar las dudas del posible 칠xito de ideas propias.
- Retarse a eficientizar tu trabajo cotidiano con la ayuda de lo aprendido en los cursos.
- Explorar una nueva forma de conocimiento que sea interesante.
Utilizar la ciencia de datos para mejorar algo que te gusta hacer (hobby).
- Aplicar lo aprendido ayudando a terceros. (proyectos, organizaciones de la sociedad civil, etc).

La frecuencia con la que deber칤as hacer un proyecto de datos depende de tus objetivos, nivel de experiencia y disponibilidad de tiempo. Aqu칤 algunas recomendaciones:

1. **Principiantes**: Realiza un proyecto peque침o cada 2-3 semanas. Esto te permitir치 aprender nuevos conceptos y reforzar lo aprendido sin saturarte.
   
2. **Intermedios**: Intenta hacer un proyecto m치s complejo cada 1-2 meses. Estos proyectos pueden involucrar t칠cnicas m치s avanzadas o conjuntos de datos m치s grandes.

3. **Avanzados**: Si ya tienes experiencia, puedes trabajar en proyectos m치s extensos a lo largo de varios meses, enfoc치ndote en la optimizaci칩n y en resolver problemas m치s desafiantes o especializados.

4. **Profesionales**: Si ya trabajas en ciencia de datos, hacer proyectos paralelos o de investigaci칩n cada trimestre puede mantener tus habilidades frescas y permitirte explorar nuevas tecnolog칤as o enfoques.

Es importante que estos proyectos sean diversos y que incluyan tareas de limpieza de datos, visualizaci칩n, modelado, y an치lisis de resultados para obtener una visi칩n completa del ciclo de vida de los datos.

## D칩nde sacar ideas para proyectos de ciencia de datos

Aqu칤 tienes algunas fuentes y estrategias para obtener ideas para proyectos de ciencia de datos:

### 1. **Plataformas de Competencias y Retos**
   - **[Kaggle](https://www.kaggle.com/)**: Es una plataforma muy popular que ofrece datasets y competencias en ciencia de datos. Puedes unirte a retos en diferentes 치reas (deportes, salud, finanzas) o simplemente explorar los datasets y resolver problemas propios.
   - **[DrivenData](https://www.drivendata.org/)**: Similar a Kaggle, pero enfocado en proyectos de impacto social, como problemas ambientales, salud p칰blica, etc.
   - **[Zindi](https://zindi.africa/)**: Competencias de ciencia de datos dirigidas a resolver problemas espec칤ficos en 츼frica.
   
### 2. **Datasets P칰blicos**
   - **[UCI Machine Learning Repository](https://archive.ics.uci.edu/ml/index.php)**: Un repositorio con datasets de varias disciplinas.
   - **[Google Dataset Search](https://datasetsearch.research.google.com/)**: Un motor de b칰squeda para encontrar datasets p칰blicos.
   - **[Data.gov](https://www.data.gov/)**: Datasets p칰blicos del gobierno de EE. UU., cubriendo 치reas como educaci칩n, econom칤a y salud.

### 3. **Proyectos de Impacto Social**
   - **Open Data**: Muchas ciudades y pa칤ses tienen portales de datos abiertos. Puedes usarlos para crear proyectos que resuelvan problemas locales, como el an치lisis de tr치nsito, datos de criminalidad o medio ambiente.
   - **[UNICEF Data](https://data.unicef.org/)**: Ofrece datos sobre educaci칩n, salud infantil y otros temas globales que puedes usar para proyectos con un enfoque social.

### 4. **Tu Propio Entorno**
   - **Proyectos Personales**: Puedes identificar problemas en tu entorno laboral o personal que se puedan resolver con ciencia de datos. Por ejemplo:
     - Optimizar el rendimiento de un equipo en una organizaci칩n.
     - An치lisis de tus finanzas personales o de productividad.
     - Monitoreo de tendencias en redes sociales.

### 5. **Investigaci칩n Acad칠mica**
   - **[ArXiv](https://arxiv.org/)**: Puedes leer art칤culos acad칠micos y explorar investigaciones recientes en campos como inteligencia artificial y ciencia de datos. Esto puede inspirarte a desarrollar tus propios enfoques o replicar experimentos.
   
### 6. **Desaf칤os de la Industria**
   - **FinTech**: Modelos de riesgo crediticio, fraude en pagos.
   - **Salud**: Detecci칩n de enfermedades con im치genes m칠dicas, an치lisis de genomas.
   - **Retail**: Recomendadores de productos, an치lisis de comportamiento de clientes.
   - **Medio Ambiente**: Proyectos de predicci칩n clim치tica, an치lisis de consumo energ칠tico.

### 7. **Blogs y Comunidades de Ciencia de Datos**
   - **[Medium](https://medium.com/tag/data-science)**: En Medium hay muchas publicaciones de ciencia de datos donde se comparten proyectos interesantes.
   - **[Towards Data Science](https://towardsdatascience.com/)**: Publicaciones sobre proyectos, nuevas herramientas y t칠cnicas en ciencia de datos.
   - **[Reddit](https://www.reddit.com/r/datascience/)**: En el subreddit de ciencia de datos, muchas personas comparten sus proyectos y experiencias.

### 8. **Proyectos de C칩digo Abierto**
   - **[GitHub](https://github.com/)**: Puedes contribuir a proyectos de c칩digo abierto que impliquen an치lisis de datos o crear el tuyo y compartirlo con la comunidad.

### 9. **Eventos y Hackathons**
   - Participa en hackathons online o presenciales que se enfoquen en resolver problemas usando ciencia de datos.

Estas fuentes pueden ofrecerte un excelente punto de partida para idear y desarrollar proyectos de ciencia de datos relevantes y creativos.

**Lecturas recomendadas**

[dataworldqa.wpengine.com | The Cloud-Native Data Catalog](https://data.world/)

[Datos Abiertos de M칠xico - datos.gob.mx](https://datos.gob.mx/)

[Datos Abiertos Colombia | Datos Abiertos Colombia](https://datos.gov.co/)

[https://datos.gob.ar](https://datos.gob.ar/)

[Dataset Search](https://datasetsearch.research.google.com/)

[UCI Machine Learning Repository: Data Sets](https://archive.ics.uci.edu/ml/datasets.php)

## Generar y comunicar un proyecto de datos

Generar y comunicar un proyecto de datos implica varios pasos que abarcan desde la concepci칩n de la idea hasta la presentaci칩n final de los resultados. Aqu칤 tienes una gu칤a general que puedes seguir:

### 1. **Definici칩n del Problema**
   - **Identifica la Pregunta**: Define claramente la pregunta o el problema que deseas resolver.
   - **Objetivos**: Establece objetivos espec칤ficos que guiar치n tu an치lisis.

### 2. **Recopilaci칩n de Datos**
   - **Fuentes de Datos**: Identifica y accede a las fuentes de datos relevantes (pueden ser bases de datos p칰blicas, APIs, encuestas, etc.).
   - **Almacenamiento**: Organiza los datos en un formato adecuado (CSV, bases de datos, etc.).

### 3. **Exploraci칩n de Datos**
   - **An치lisis Exploratorio**: Usa herramientas como Pandas, Matplotlib o Seaborn para explorar los datos. Busca patrones, tendencias y valores at칤picos.
   - **Visualizaci칩n**: Crea visualizaciones para comprender mejor los datos.

### 4. **Preparaci칩n de Datos**
   - **Limpieza**: Maneja datos faltantes, elimina duplicados y corrige errores en los datos.
   - **Transformaci칩n**: Aplica t칠cnicas de normalizaci칩n, escalado, o creaci칩n de nuevas variables si es necesario.

### 5. **An치lisis y Modelado**
   - **Selecci칩n de M칠todos**: Elige los m칠todos de an치lisis adecuados (estad칤sticos, machine learning, etc.).
   - **Entrenamiento de Modelos**: Si aplicas machine learning, divide los datos en conjuntos de entrenamiento y prueba, y entrena el modelo.

### 6. **Evaluaci칩n del Modelo**
   - **M칠tricas**: Utiliza m칠tricas de evaluaci칩n (precisi칩n, recall, F1 score, etc.) para medir el rendimiento del modelo.
   - **Validaci칩n**: Aseg칰rate de que el modelo generalice bien a datos no vistos.

### 7. **Comunicaci칩n de Resultados**
   - **Documentaci칩n**: Crea documentaci칩n clara sobre el proceso, m칠todos utilizados y resultados obtenidos.
   - **Visualizaciones**: Presenta resultados clave mediante gr치ficos y tablas.
   - **Presentaci칩n**: Prepara una presentaci칩n efectiva que comunique los hallazgos a las partes interesadas.

### 8. **Conclusiones y Recomendaciones**
   - **Insights**: Resume los insights clave y c칩mo responden a la pregunta original.
   - **Recomendaciones**: Si es relevante, proporciona recomendaciones basadas en los resultados.

### 9. **Feedback y Iteraci칩n**
   - **Revisiones**: Solicita feedback sobre el proyecto y haz ajustes si es necesario.
   - **Iterar**: Mejora el proyecto en base a nuevas preguntas o datos adicionales.

### Herramientas Utilizadas
- **Lenguajes de Programaci칩n**: Python, R, SQL.
- **Librer칤as**: Pandas, NumPy, Scikit-learn, Matplotlib, Seaborn.
- **Entornos**: Jupyter Notebook, RStudio.
- **Herramientas de Visualizaci칩n**: Tableau, Power BI, o visualizaciones en Python.

### Ejemplo de Proyecto
**Tema**: An치lisis de ventas de un e-commerce.
- **Pregunta**: 쯈u칠 factores influyen en las ventas mensuales?
- **Datos**: Recopilar datos de ventas, usuarios, productos.
- **An치lisis**: Realizar an치lisis exploratorio, modelar ventas en funci칩n de las caracter칤sticas de los productos y la demograf칤a de los usuarios.
- **Resultados**: Presentar un informe con gr치ficos que muestren las tendencias de ventas y las correlaciones encontradas.

Siguiendo estos pasos, podr치s crear y comunicar un proyecto de datos de manera efectiva.

## Ejecutando: obteniendo los datos

**Lecturas recomendadas**

[Datos Argentina](https://datos.gob.ar/)

[Gobierno Municipal de Monterrey](http://portal.monterrey.gob.mx/transparencia/Oficial/Index_Transparencia.asp)

[dataworldqa.wpengine.com | The Cloud-Native Data Catalog](https://data.world/)

[Datos Abiertos de M칠xico - datos.gob.mx](https://datos.gob.mx/)

[Datos Abiertos Colombia | Datos Abiertos Colombia](https://datos.gov.co/)

[Dataset Search](https://datasetsearch.research.google.com/)

[UCI Machine Learning Repository: Data Sets](https://archive.ics.uci.edu/ml/datasets.php)

## Explora y encuentra patrones en la informaci칩n

El EDA es para conocer los datos que tenemos 游늵
Y es que puede pasar que luego de haber recolectado informaci칩n a칰n nos haga falta para responder nuestra pregunta. El EDA (Exploratory Data Analysis) entonces nos hace ver lo que tenemos y lo que podemos hacer con los datos.

**쯏 c칩mo podemos podemos hacer un EDA?**

Ve de lo m치s peque침o a lo m치s grande. Y de lo m치s general a lo m치s espec칤fico.

Un buen inicio es hacer una breve descripci칩n estad칤stica de nuestro dataframe usando df.info(). Luego pasa al an치lisis univariable, bivariable y multivariable. Adem치s, recuerda que necesitas mucha visualizaci칩n de datos.

**An치lisis univariable**

Aqu칤 buscas entender lo que representa cada variable (columna) por s칤 sola. Puedes usar distribuciones o histogramas.

**An치lisis bivariable**

En este caso, tu objetivo es entender la relaci칩n entre dos variables de inter칠s. Puedes usar distribuciones e histogramas, pero ya a침ades un hue seg칰n necesites. Las correlaciones son muy usadas tambi칠n.

**An치lisis multivariable**

Ahora ya necesitas entender la relaci칩n entre 3 o m치s variables.

## Ejecutando: aplicando un modelo no supervisado de machine learning

Si deseas aplicar un modelo no supervisado de *machine learning*, como por ejemplo el algoritmo de *k-means* para agrupamiento (clustering), aqu칤 tienes un ejemplo paso a paso usando `scikit-learn`:

### Paso 1: Preparar los datos
Aseg칰rate de que tus datos est칠n limpios y listos para el modelo. Si est치s trabajando con variables categ칩ricas, podr칤as necesitar convertirlas en variables num칠ricas (por ejemplo, usando *one-hot encoding*).

```python
from sklearn.preprocessing import StandardScaler
from sklearn.cluster import KMeans

# Ejemplo de c칩mo estandarizar los datos (opcional, pero recomendado para k-means)
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)  # X es tu conjunto de caracter칤sticas
```

### Paso 2: Aplicar el modelo *k-means*

```python
# Definir el modelo k-means con 3 clusters (puedes ajustar el n칰mero de clusters)
kmeans = KMeans(n_clusters=3, random_state=42)

# Ajustar el modelo a los datos
kmeans.fit(X_scaled)

# Obtener las etiquetas de los clusters asignados
clusters = kmeans.labels_

# Ver los centros de los clusters
centroids = kmeans.cluster_centers_
```

### Paso 3: Interpretar los resultados

Despu칠s de aplicar el modelo, puedes asignar los clusters a tu conjunto de datos original o visualizar los resultados:

```python
# Agregar las etiquetas de los clusters al DataFrame original
df['Cluster'] = clusters

# Visualizaci칩n de los clusters (si tienes 2 caracter칤sticas principales)
import matplotlib.pyplot as plt

plt.scatter(X_scaled[:, 0], X_scaled[:, 1], c=clusters, cmap='viridis')
plt.scatter(centroids[:, 0], centroids[:, 1], c='red', marker='x')  # Marcar los centros
plt.show()
```

### Paso 4: Evaluaci칩n

Una forma de evaluar la calidad del agrupamiento es usando el *silhouette score*, que mide cu치n bien separados est치n los clusters.

```python
from sklearn.metrics import silhouette_score

silhouette_avg = silhouette_score(X_scaled, clusters)
print(f"Silhouette Score: {silhouette_avg}")
```

Si est치s usando otro algoritmo no supervisado como PCA o DBSCAN, el proceso ser치 diferente, pero el flujo general sigue siendo:

1. **Preparar los datos**
2. **Aplicar el modelo**
3. **Interpretar y visualizar los resultados**
4. **Evaluar la calidad del modelo (si es aplicable)**

## Ejecutando: aplicando un modelo no supervisado de anomal칤as

Para aplicar un modelo no supervisado de detecci칩n de anomal칤as, puedes utilizar varios enfoques, dependiendo del tipo de datos que tengas y de la naturaleza de las anomal칤as que quieras detectar. Un enfoque com칰n es utilizar el **Isolation Forest**, que es adecuado para detectar anomal칤as en datos de alta dimensi칩n.

Aqu칤 te dejo un ejemplo b치sico usando **Isolation Forest** de la biblioteca `scikit-learn`:

### Pasos para aplicar un modelo de detecci칩n de anomal칤as con Isolation Forest:

1. **Instalar la biblioteca scikit-learn** (si a칰n no lo has hecho):

   ```bash
   pip install scikit-learn
   ```

2. **Cargar los datos y preprocesarlos**. Por ejemplo, si ya tienes un DataFrame `compras_df`, selecciona las columnas que deseas analizar.

3. **Entrenar el modelo Isolation Forest**:

   ```python
   from sklearn.ensemble import IsolationForest
   from sklearn.model_selection import train_test_split
   import numpy as np

   # Suponiendo que tus datos est칠n en compras_df y quieras detectar anomal칤as en una columna espec칤fica:
   X = compras_df[['IMPORTE']]  # Suponiendo que quieres detectar anomal칤as en la columna 'IMPORTE'

   # Dividir en conjuntos de entrenamiento y prueba (opcional)
   X_train, X_test = train_test_split(X, test_size=0.33, random_state=42)

   # Crear el modelo de Isolation Forest
   iso_forest = IsolationForest(n_estimators=100, contamination=0.1, random_state=42)

   # Ajustar el modelo (entrenarlo)
   iso_forest.fit(X_train)

   # Predecir anomal칤as (1 = normal, -1 = an칩malo)
   anomalies = iso_forest.predict(X_test)

   # Agregar una columna para indicar si es an칩malo o no
   X_test['Anomal칤a'] = anomalies
   ```

4. **Interpretar los resultados**:
   - Las predicciones del modelo ser치n `1` si el registro es considerado normal, y `-1` si es considerado una anomal칤a.
   - Puedes explorar los resultados de las anomal칤as:

   ```python
   # Mostrar los registros que fueron detectados como anomal칤as
   anomal칤as_detectadas = X_test[X_test['Anomal칤a'] == -1]
   print(anomal칤as_detectadas)
   ```

### Par치metros importantes:
- **n_estimators**: El n칰mero de 치rboles en el bosque de aislamiento.
- **contamination**: La proporci칩n de anomal칤as que esperas encontrar en tus datos. Si no tienes una idea clara, puedes ajustarlo seg칰n la naturaleza de tus datos.

[GitHub - platzi/proyectos-ciencia-datos: Repositorio del proyecto del Curso para Crear tus Proyectos de Ciencia de Datos](https://github.com/platzi/proyectos-ciencia-datos)