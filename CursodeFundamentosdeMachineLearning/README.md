# Curso de Fundamentos de Machine Learning

## Tipos de modelos de machine learning para analizar equipos deportivos

### üß† 1. **Modelos Supervisados**

Se usan cuando tienes datos **etiquetados** (es decir, con resultados conocidos).

### üìä a) **Clasificaci√≥n**

Predicen categor√≠as discretas (ganar, perder, empatar, etc.)

**Ejemplos:**

* Predecir si un equipo ganar√° el pr√≥ximo partido.
* Clasificar si un jugador est√° en forma o lesionado.

**Modelos comunes:**

* Regresi√≥n log√≠stica
* √Årboles de decisi√≥n
* Random Forest
* SVM (M√°quinas de vectores soporte)
* Redes neuronales

### üìà b) **Regresi√≥n**

Predicen un **valor num√©rico continuo**.

**Ejemplos:**

* Predecir cu√°ntos goles marcar√° un equipo.
* Estimar el rendimiento de un jugador.

**Modelos comunes:**

* Regresi√≥n lineal / ridge / lasso
* XGBoost
* Redes neuronales

### üß† 2. **Modelos No Supervisados**

Se usan cuando **no hay etiquetas** conocidas.

### üîç a) **Clustering (agrupamiento)**

Agrupa datos similares autom√°ticamente.

**Ejemplos:**

* Agrupar jugadores seg√∫n estilo de juego.
* Detectar patrones en los rivales (equipos ofensivos vs. defensivos).

**Modelos comunes:**

* K-means
* DBSCAN
* Modelos de mezcla gaussiana

### üßÆ b) **An√°lisis de Componentes Principales (PCA)**

Reduce dimensiones para visualizar y analizar mejor los datos complejos (como estad√≠sticas por partido).

### üß† 3. **Modelos de Series de Tiempo**

Usados para **analizar datos secuenciales**, como resultados por fecha o evoluci√≥n de un jugador.

**Ejemplos:**

* Predecir la evoluci√≥n de un equipo en la tabla.
* Estimar el rendimiento f√≠sico de un atleta a lo largo del tiempo.

**Modelos comunes:**

* ARIMA
* LSTM (redes neuronales recurrentes)
* Prophet (de Facebook)
* Exponential Smoothing

### üß† 4. **Aprendizaje por Refuerzo (Reinforcement Learning)**

√ötil para **estrategia y toma de decisiones** en tiempo real o simulaciones.

**Ejemplos:**

* Optimizar t√°cticas de equipo (con simuladores).
* Decidir cambios de jugadores en tiempo real.
* Analizar trayectorias √≥ptimas en deportes como f√∫tbol, b√°squet, etc.

### ‚öΩ Aplicaciones Concretas en Deportes

| √Årea                     | Modelo t√≠pico                | Ejemplo pr√°ctico                                |
| ------------------------ | ---------------------------- | ----------------------------------------------- |
| Predicci√≥n de resultados | Clasificaci√≥n / regresi√≥n    | ¬øGanar√° el partido el equipo A?                 |
| Evaluaci√≥n de jugadores  | Clustering / PCA             | ¬øQu√© estilo de juego tiene este jugador?        |
| An√°lisis de desempe√±o    | Series de tiempo / regresi√≥n | ¬øC√≥mo evolucion√≥ el rendimiento este mes?       |
| Scouting / reclutamiento | Clasificaci√≥n                | ¬øEncajar√° un jugador en cierto perfil t√°ctico?  |
| Estrategia t√°ctica       | Aprendizaje por refuerzo     | ¬øCu√°l es la mejor jugada en una situaci√≥n dada? |

### Resumen

¬øSab√≠as que el *machine learning* permite mejorar significativamente el rendimiento deportivo de un equipo? En el caso del equipo Cebollitas, que perdi√≥ cuatro de sus √∫ltimos cinco partidos, la incorporaci√≥n de datos como estad√≠sticas de jugadores, registros de entrenamientos y videos de partidos podr√≠a marcar una diferencia importante. Descubramos juntos c√≥mo los modelos de machine learning pueden ser la clave para optimizar resultados deportivos.

#### ¬øQu√© modelos de machine learning son √∫tiles en el deporte?

El aprendizaje autom√°tico presenta diversas modalidades √∫tiles en contextos deportivos. A continuaci√≥n, repasamos las principales que podr√≠an aplicarse eficientemente al equipo Cebollitas:

#### ¬øQu√© son los modelos supervisados en machine learning?

Estos modelos aprenden mediante ejemplos espec√≠ficos, diferenciando escenarios positivos y negativos. Aplicado al f√∫tbol, podr√≠an analizar:

- Factores determinantes en los resultados de partidos espec√≠ficos.
- Variaciones que inciden en victorias o derrotas.
- Patrones recurrentes asociados con bajos rendimientos.

De esta forma, facilitan predecir resultados futuros basados en condiciones anteriores.

### ¬øC√≥mo funcionan los modelos no supervisados?

Por otra parte, los modelos no supervisados analizan datos sin valoraciones previas. Algunas aplicaciones pr√°cticas son:

- Identificar grupos de jugadores con h√°bitos de entrenamiento similares.
- Reconocer atletas que presentan mayor riesgo de lesiones.
- Descubrir comportamientos y tendencias internas de los jugadores.

Estos hallazgos permiten mejorar decisiones t√©cnicas y estrat√©gicas del equipo.

#### ¬øQu√© ventajas ofrecen los modelos de refuerzo?

Los modelos por refuerzo mejoran mediante prueba y error obteniendo recompensas. Esto es especialmente √∫til en:

- La simulaci√≥n de partidos para dise√±ar t√°cticas efectivas.
- Recomendaci√≥n de jugadas espec√≠ficas adaptadas al rival.
- Optimizaci√≥n de rutinas y entrenamientos para maximizar el rendimiento.

#### ¬øQu√© herramientas se utilizan com√∫nmente para aplicar machine learning en el deporte?

Existen diversas herramientas tecnol√≥gicas que facilitan la aplicaci√≥n del aprendizaje autom√°tico en la actividad f√≠sica y deportes, por ejemplo:

- Scikit learn, √∫til para algoritmos predictivos.
- TensorFlow y PyTorch, que se emplean tanto en an√°lisis predictivo como en aprendizaje por refuerzo.
- Python, lenguaje com√∫nmente empleado debido a su versatilidad e integraci√≥n con estas herramientas.

Estas tecnolog√≠as permiten aplicar directamente modelos al contexto particular del equipo y medir su impacto en rendimiento.

#### ¬øPor qu√© elegir correctamente un modelo de *machine learning* importa?

M√°s que conocer m√∫ltiples algoritmos de manera abstracta, lo realmente importante radica en saber elegir el modelo adecuado seg√∫n las necesidades espec√≠ficas del equipo. Implementando estas estrategias, Cebollitas podr√°:

- Analizar datos reales del equipo.
- Medir mejoras en tiempo real.
- Tomar decisiones basadas en evidencia estad√≠stica.

¬øTe gustar√≠a formar parte de este reto y convertirte en el pr√≥ximo analista de datos o ingeniero de machine learning para Cebollitas? ¬°Comparte tus ideas en comentarios y comencemos el partido!

**Lecturas recomendadas**

[scikit-learn: machine learning in Python ‚Äî scikit-learn 1.7.0 documentation](https://scikit-learn.org/stable/)

## Modelos supervisados de machine learning para an√°lisis deportivo

### üß† ¬øQu√© es un modelo supervisado?

Un modelo supervisado **aprende a partir de datos con etiquetas conocidas**, es decir, ejemplos donde se conoce el resultado (gan√≥/perdi√≥, rendimiento num√©rico, etc.).

üëâ Se divide en dos tipos principales:

* **Clasificaci√≥n** (salida categ√≥rica)
* **Regresi√≥n** (salida num√©rica continua)

### ‚öΩ Aplicaciones deportivas comunes

| Objetivo                                | Tipo de modelo supervisado |
| --------------------------------------- | -------------------------- |
| Predecir si un equipo ganar√°            | Clasificaci√≥n              |
| Clasificar lesiones como leves o graves | Clasificaci√≥n              |
| Estimar goles, puntos o asistencias     | Regresi√≥n                  |
| Predecir tiempo de recuperaci√≥n         | Regresi√≥n                  |
| Clasificar tipo de jugada (pase, tiro)  | Clasificaci√≥n              |

### üîç 1. **Modelos de Clasificaci√≥n**

### üìå ¬øCu√°ndo usar?

Cuando el resultado pertenece a **clases discretas**: ganar/perder, bajo/medio/alto, A/B/C...

### üìä Modelos comunes:

* **Regresi√≥n log√≠stica**: simple y eficaz para 2 clases.
* **K-Nearest Neighbors (KNN)**: asigna la clase m√°s frecuente entre vecinos cercanos.
* **√Årboles de decisi√≥n y Random Forest**: modelos interpretables y robustos.
* **Support Vector Machines (SVM)**: eficaz con datos complejos y pocas dimensiones.
* **Redes neuronales**: √∫tiles si tienes muchos datos y no linealidades complejas.

### üèü Ejemplo:

**¬øGanar√° el equipo A contra el B?**

Datos de entrada:

* posesi√≥n
* tiros a puerta
* faltas
* goles previos

Etiqueta:

* 1 = gan√≥, 0 = no gan√≥

### üìè 2. **Modelos de Regresi√≥n**

### üìå ¬øCu√°ndo usar?

Cuando el resultado es un **n√∫mero real**: goles, puntuaci√≥n, tiempo, distancia, etc.

### üìä Modelos comunes:

* **Regresi√≥n lineal**: para relaciones simples.
* **Ridge y Lasso**: versiones regularizadas.
* **√Årboles de regresi√≥n / Random Forest Regressor**
* **XGBoost**: potente y eficiente para predicci√≥n.
* **Redes neuronales**: si hay muchas variables o relaciones no lineales.

### üèü Ejemplo:

**¬øCu√°ntos goles marcar√° el equipo X en el pr√≥ximo partido?**

Datos de entrada:

* promedio de goles por partido
* defensa del rival
* condici√≥n de local o visitante

Etiqueta:

* N√∫mero de goles (0, 1, 2, ‚Ä¶)

### üß™ Mini ejemplo en Python

```python
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
import pandas as pd

# Datos simulados
data = pd.DataFrame({
    'posesi√≥n': [52, 47, 60, 55],
    'tiros': [8, 5, 11, 7],
    'local': [1, 0, 1, 0],
    'gana': [1, 0, 1, 0]  # etiqueta
})

X = data[['posesi√≥n', 'tiros', 'local']]
y = data['gana']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5)

clf = RandomForestClassifier()
clf.fit(X_train, y_train)

predicciones = clf.predict(X_test)
print("Precisi√≥n:", accuracy_score(y_test, predicciones))
```

### üß† ¬øC√≥mo elegir el mejor modelo?

Depende de:

* Tama√±o y calidad de los datos.
* Tipo de problema (clasificaci√≥n vs regresi√≥n).
* ¬øQuieres explicabilidad o solo precisi√≥n?
* ¬øNecesitas que funcione en tiempo real?

### Resumen

¬øTe imaginas poder anticiparte al resultado de un partido antes siquiera de jugarlo? Esta idea, m√°s cercana de lo que crees, es posible mediante los modelos supervisados de inteligencia artificial. Estos modelos analizan resultados pasados, como los del equipo Cebollitas, que ha perdido m√°s del 60% de sus partidos como visitante, para prever futuros resultados con sorprendente precisi√≥n. Pero, ¬øc√≥mo funcionan realmente estos modelos y cu√°l es su aplicaci√≥n concreta en el an√°lisis deportivo?

#### ¬øQu√© datos usan los modelos supervisados para predecir partidos?

Para realizar una predicci√≥n efectiva, estos modelos necesitan ejemplos claros de datos etiquetados. Espec√≠ficamente, se analizan detalles precisos de partidos disputados anteriormente, como:

- Cantidad de goles anotados.
- Posici√≥n y desempe√±o del equipo.
- N√∫mero de tiros o remates al arco.
- Precisi√≥n en los tiros, como los de Tara √Ålvarez.
- Pases completados, como los que realiza Carol McClain.

Con esta informaci√≥n valiosa, los modelos "aprenden" patrones consistentes que permiten anticipar con mayor exactitud futuros resultados deportivos.

##### ¬øCu√°les son los modelos supervisados m√°s utilizados?
#### ¬øQu√© es y c√≥mo funciona la regresi√≥n lineal?

La regresi√≥n lineal ofrece un c√°lculo simple, pero efectivo, para anticipar valores num√©ricos. Por ejemplo, si se conoce el n√∫mero de remates al arco del equipo, este m√©todo permitir√° estimar cu√°ntos goles marcar√°n con base en dichos datos, proporcionando una relaci√≥n gr√°fica f√°cil de interpretar.

#### ¬øQu√© diferencia hay con la regresi√≥n log√≠stica?

A diferencia de la lineal, la regresi√≥n log√≠stica no predice directamente cifras espec√≠ficas, sino una probabilidad. As√≠, podr√≠as saber que existe un 80% de probabilidad de ganar el pr√≥ximo partido. Aunque se denomina regresi√≥n, su papel real es realizar una clasificaci√≥n clara de posibilidades.

#### ¬øPor qu√© usar √°rboles de decisi√≥n?

¬øQuieres ver c√≥mo tomar decisiones al estilo de un director t√©cnico? El √°rbol de decisi√≥n opera dividiendo criterios claros para saber cu√°l es la siguiente mejor jugada. Por ejemplo, si tienes m√°s del 60% de posesi√≥n y m√°s de 10 disparos al arco, ir√°s directamente al ataque. Aun as√≠, es crucial ser cuidadoso, porque pueden memorizar en vez de generalizar.

#### ¬øQu√© ventajas aporta el random forest?

Para evitar la tendencia del √°rbol de decisi√≥n a memorizar, el random forest emplea m√∫ltiples √°rboles, donde cada uno vota por un resultado probable. Esto da como resultado m√°s robustez, mayor precisi√≥n y menor tasa de errores, haciendo este m√©todo muy confiable.

#### ¬øD√≥nde destacan las m√°quinas de soporte vectorial (SVM)?

Las SVM son herramientas excepcionales para trazar l√≠mites de clasificaci√≥n precisos en un conjunto de datos, diferenciando claramente partidos ganados y perdidos en relaci√≥n a caracter√≠sticas espec√≠ficas como tiros al arco o posesi√≥n del bal√≥n.

#### ¬øCu√°l es el rol de las redes neuronales?

Cuando los datos se vuelven especialmente complejos, entran en juego las redes neuronales. Estas t√©cnicas avanzadas encuentran combinaciones ocultas y patrones no lineales, ideales para detectar jugadas imperceptibles a simple vista, aunque requieren grandes cantidades de informaci√≥n y una alta potencia de computaci√≥n.

#### ¬øQu√© necesitan estos modelos para ofrecer buenos resultados?

La clave de un modelo supervisado exitoso radica en la calidad de sus datos etiquetados. Como analistas deportivos de alto nivel, nuestro trabajo consiste precisamente en proporcionar estos datos cuidadosamente seleccionados, fundamentales para que los modelos aprendan correctamente y puedan anticiparse a resultados precisos.

Ahora que conoces c√≥mo funcionan estos modelos supervisados, cu√©ntanos, ¬øcu√°l elegir√≠as para mejorar el rendimiento del equipo Cebollitas en su pr√≥ximo partido? ¬°Comparte tus comentarios!

**Lecturas recomendadas**

[1. Supervised learning ‚Äî scikit-learn 1.7.0 documentation](https://scikit-learn.org/stable/supervised_learning.html)

[1.1. Linear Models ‚Äî scikit-learn 1.7.0 documentation](https://scikit-learn.org/stable/modules/linear_model.html#ordinary-least-squares%20https://towardsdatascience.com/understanding-linear-regression-output-in-r-7a9cbda948b3/)

## Modelos no supervisados para an√°lisis futbol√≠stico

### üî∑ ¬øQu√© es un modelo no supervisado?

Es un tipo de algoritmo que **aprende de los datos sin conocer las respuestas correctas**. Su objetivo es:

* Agrupar observaciones similares.
* Reducir la complejidad de los datos.
* Encontrar patrones o estructuras internas.

### ‚öΩ Aplicaciones en an√°lisis futbol√≠stico

| Aplicaci√≥n                                    | T√©cnica recomendada                           |
| --------------------------------------------- | --------------------------------------------- |
| Agrupar jugadores por estilo de juego         | **Clustering (K-Means, DBSCAN)**              |
| Detectar formaciones t√°cticas autom√°ticamente | **Clustering o reducci√≥n de dimensi√≥n**       |
| Reducir variables redundantes en estad√≠sticas | **PCA (An√°lisis de Componentes Principales)** |
| An√°lisis de scouting (segmentar talento)      | **Clustering + an√°lisis de distancias**       |
| An√°lisis posicional basado en tracking de GPS | **Modelos de densidad, GMM**                  |
### üîπ 1. Clustering (Agrupamiento)

### ‚úî ¬øQu√© hace?

Agrupa jugadores, partidos o jugadas **similares** entre s√≠, sin que t√∫ definas los grupos previamente.

### üß† Algoritmos populares:

* **K-Means**: divide datos en K grupos definidos por distancia.
* **DBSCAN**: detecta grupos de puntos densos sin definir K.
* **Gaussian Mixture Models (GMM)**: agrupa por distribuciones probabil√≠sticas.

### ‚öΩ Ejemplo en f√∫tbol:

Agrupar jugadores seg√∫n estas estad√≠sticas:

* Pases completados
* Intercepciones
* Disparos al arco
* Minutos jugados

As√≠ puedes descubrir roles reales: creadores, defensores puros, atacantes m√≥viles, etc.

### üîπ 2. PCA (An√°lisis de Componentes Principales)

### ‚úî ¬øQu√© hace?

Reduce **dimensiones** de un conjunto de datos manteniendo la mayor parte de la **variabilidad**.

### ‚öΩ En f√∫tbol:

* Simplificar datos de rendimiento (decenas de m√©tricas por jugador).
* Visualizar en 2D o 3D las "similitudes" entre jugadores.
* Analizar tendencias generales del equipo.

### üîπ 3. Modelos de Detecci√≥n de Anomal√≠as

### ‚úî ¬øQu√© hace?

Detecta **comportamientos fuera de lo com√∫n** (anomal√≠as).

### ‚öΩ En f√∫tbol:

* Detectar partidos at√≠picos (para scouting o apuestas).
* Identificar lesiones o rendimientos inusuales.
* Se√±alar jugadas raras en el tracking del bal√≥n.

### üß† Algoritmos:

* Isolation Forest
* One-Class SVM

### üß™ Ejemplo: Clustering de jugadores con K-Means en Python

```python
import pandas as pd
from sklearn.cluster import KMeans
from sklearn.preprocessing import StandardScaler
import matplotlib.pyplot as plt

# Datos simulados: estad√≠sticas por jugador
data = pd.DataFrame({
    'pases': [55, 70, 65, 20, 30, 25],
    'disparos': [2, 1, 3, 5, 4, 6],
    'intercepciones': [3, 2, 4, 6, 7, 5]
})

# Normalizaci√≥n
scaler = StandardScaler()
data_scaled = scaler.fit_transform(data)

# Agrupar en 2 cl√∫steres
kmeans = KMeans(n_clusters=2, random_state=0)
labels = kmeans.fit_predict(data_scaled)

data['rol_estimado'] = labels
print(data)
```

### üß† Conclusi√≥n

| T√©cnica               | ¬øPara qu√© sirve?                                      |
| --------------------- | ----------------------------------------------------- |
| **K-Means, DBSCAN**   | Agrupar jugadores, jugadas o partidos                 |
| **PCA**               | Reducir dimensi√≥n y encontrar estructura en los datos |
| **Anomaly Detection** | Detectar eventos o desempe√±os fuera de lo com√∫n       |

### Resumen

El f√∫tbol actual va m√°s all√° de goles y asistencias. Cuando las estad√≠sticas b√°sicas no son suficientes para evaluar completamente a un jugador, recurrimos a los **modelos no supervisados**, t√©cnicas que permiten revelar patrones ocultos en el juego sin depender exclusivamente de etiquetas tradicionales.

#### ¬øQu√© es el clustering y c√≥mo ayuda a evaluar jugadores?

El *clustering* es una t√©cnica estad√≠stica que agrupa elementos que comparten caracter√≠sticas similares. En f√∫tbol, esto nos permite identificar jugadores que desempe√±an roles espec√≠ficos o tienen rendimientos parecidos sin necesidad de etiquetas previas como goles marcados o asistencias realizadas.

#### ¬øC√≥mo funciona el algoritmo K-means?

K-means es uno de los algoritmos m√°s populares del clustering. Funciona dividiendo los datos en "k" grupos, asegur√°ndose de que cada jugador est√© lo m√°s cercano posible al centro de su respectivo grupo. As√≠, logramos identificar roles espec√≠ficos como:

- Jugadores carrileros incansables.
- Motores de recuperaci√≥n.
- Delanteros fantasmas.

#### ¬øQu√© hacer cuando los datos no tienen formas claras de agrupaci√≥n?

No siempre los datos se organizan claramente. En estos casos, utilizamos algoritmos m√°s especializados como DBSCAN, que agrupa a los jugadores seg√∫n la densidad de los datos. Este m√©todo detecta grupos aunque no tengan formas geom√©tricas expl√≠citas, examinando c√≥mo est√°n distribuidos los datos en conjunto.

#### ¬øEn qu√© consiste el Clustering jer√°rquico y cu√°ndo usarlo?

El clustering jer√°rquico organiza los datos en una estructura en √°rbol, conocida como dendrograma. Este m√©todo es ideal cuando analizamos jugadas ofensivas o estilos de juego sin etiquetas definidas como goles, permitiendo observar c√≥mo jugadores o jugadas espec√≠ficas se agrupan en estructuras m√°s amplias de caracter√≠sticas similares.

#### ¬øC√≥mo visualizar la informaci√≥n cuando hay muchas variables?

En ocasiones, manejar una gran cantidad de variables es abrumador. Para estos escenarios, la reducci√≥n de dimensionalidad nos brinda herramientas pr√°cticas para resumir informaci√≥n destacada sin perder detalles relevantes.

#### ¬øQu√© es PCA (An√°lisis de Componentes Principales)?

PCA reduce la cantidad de variables creando nuevas dimensiones que capturan la mayor√≠a de la informaci√≥n original. Es similar a observar un partido desde un dron: perdemos algunos detalles espec√≠ficos, pero obtenemos una visi√≥n general del rendimiento y estilo de los jugadores.

#### ¬øHay otras opciones para visualizar datos complejos?

S√≠, t√©cnicas avanzadas como **t-SNE** o **UMAP** permiten representar datos complejos en gr√°ficos bidimensionales o tridimensionales, revelando patrones menos obvios y facilitando la interpretaci√≥n del desempe√±o futbol√≠stico.

#### ¬øC√≥mo evaluar la efectividad del clustering sin etiquetas?

Evaluar resultados sin etiquetas tradicionales como victorias o goles presenta desaf√≠os especiales. Usamos m√©tricas espec√≠ficas para confirmar la validez del agrupamiento:

- **Inercia**: mide qu√© tan compactos son los grupos.
- **Coeficiente de Silhouette**: eval√∫a qu√© tan bien separados est√°n los grupos entre s√≠.

Estas herramientas no ofrecen respuestas definitivas, pero son √∫tiles para verificar que las agrupaciones tengan sentido desde el punto de vista anal√≠tico.
 
**Lecturas recomendadas**

[2. Unsupervised learning ‚Äî scikit-learn 1.7.0 documentation](https://scikit-learn.org/stable/unsupervised_learning.html)

## Configuraci√≥n de Python y Jupyter para an√°lisis deportivo

### ‚öôÔ∏è 1. Instalar Python

### Opci√≥n recomendada: **Anaconda**

Anaconda incluye Python + Jupyter + librer√≠as para ciencia de datos.

üîó Descarga desde: [https://www.anaconda.com/download](https://www.anaconda.com/download)

### Alternativa: **Python + pip**

* Instala Python desde: [https://www.python.org/downloads](https://www.python.org/downloads/)
* Luego instala Jupyter y bibliotecas:

```bash
pip install jupyter numpy pandas matplotlib seaborn scikit-learn
```

### üìì 2. Abrir Jupyter Notebook

Una vez instalado:

```bash
jupyter notebook
```

Esto abrir√° tu navegador con un entorno interactivo donde puedes escribir c√≥digo, visualizar gr√°ficos y explorar datos.

### üì¶ 3. Bibliotecas esenciales para an√°lisis deportivo

| Biblioteca     | Uso principal                                 |
| -------------- | --------------------------------------------- |
| `pandas`       | Manipulaci√≥n de datos (CSV, Excel, JSON...)   |
| `numpy`        | C√°lculo num√©rico y √°lgebra lineal             |
| `matplotlib`   | Gr√°ficos b√°sicos (l√≠neas, barras, dispersi√≥n) |
| `seaborn`      | Gr√°ficos estad√≠sticos m√°s elegantes           |
| `scikit-learn` | Machine learning (modelos supervisados y no)  |
| `statsmodels`  | Modelado estad√≠stico y regresi√≥n              |
| `plotly`       | Gr√°ficos interactivos (opcional)              |
| `xgboost`      | Modelos predictivos potentes (opcional)       |

Instalaci√≥n:

```bash
pip install pandas numpy matplotlib seaborn scikit-learn statsmodels plotly xgboost
```

### üèüÔ∏è 4. Bibliotecas opcionales para deportes

* [`football-data`](https://pypi.org/project/football-data-api/): para acceder a APIs de f√∫tbol.
* [`fifa-api`](https://pypi.org/project/fut/): acceso a estad√≠sticas de FIFA.
* [`mplsoccer`](https://mplsoccer.readthedocs.io/): gr√°ficos avanzados tipo "pizza charts", radar y an√°lisis de f√∫tbol.

```bash
pip install mplsoccer
```

### üß™ 5. Ejemplo b√°sico de an√°lisis deportivo

```python
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# Cargar estad√≠sticas simuladas de jugadores
df = pd.DataFrame({
    'Jugador': ['A', 'B', 'C', 'D'],
    'Goles': [10, 5, 7, 2],
    'Asistencias': [3, 7, 2, 4],
    'Minutos': [900, 850, 1000, 700]
})

# Relaci√≥n goles-minutos
df['Goles por minuto'] = df['Goles'] / df['Minutos']

# Gr√°fico
sns.barplot(x='Jugador', y='Goles por minuto', data=df)
plt.title('Goles por minuto jugado')
plt.show()
```

### üß† Consejos adicionales

‚úÖ Organiza tus notebooks por proyectos: `datos/`, `modelos/`, `gr√°ficas/`

‚úÖ Usa `Google Colab` si no deseas instalar nada localmente.

‚úÖ Guarda tus datasets en CSV y c√°rgalos con `pandas.read_csv("archivo.csv")`.

‚úÖ Si usas datos de p√°ginas como [FBref.com](https://fbref.com/) o [Understat](https://understat.com/), puedes integrarlos f√°cilmente.

### Resumen

La frustraci√≥n en el f√∫tbol es com√∫n cuando los resultados no reflejan claramente el rendimiento del equipo. Esta situaci√≥n ocurre incluso cuando se tienen m√°s posesi√≥n y pases completados. Para solventar este inconveniente, utilizaremos Python y t√©cnicas de machine learning supervisado que nos permitir√°n analizar datos precisos y entender mejor lo que pasa dentro del campo.

#### ¬øPor qu√© usar Python para an√°lisis deportivo?

Python es ideal debido a que es simple, poderoso y cuenta con las herramientas adecuadas para el an√°lisis y procesamiento de datos deportivos. Para facilitar nuestro trabajo, usaremos Jupyter Notebook, que permite escribir c√≥digo, hacer justificaciones y visualizar gr√°ficos c√≥modamente en un mismo entorno.

#### ¬øC√≥mo preparar tu entorno para an√°lisis?

Es importante tener todo listo antes de comenzar a analizar resultados deportivos con datos. Para ello, generaremos un ambiente virtual completo instalando Python, Jupyter Notebook e incluir√° algunas librer√≠as esenciales.

- Instalar Python y Jupyter Notebook.
- Crear un archivo notebook con extensi√≥n punto IPYNB.
- Nombrar tu archivo notebook como ‚Äúcebollitas d√≠a uno‚Äù.

Este ambiente ser√° tu campo digital para entrenar modelos anal√≠ticos, probar nuevas ideas y evaluar resultados.

#### ¬øCu√°l ser√° tu primera l√≠nea de c√≥digo?

Tu introducci√≥n a Python inicia con algo sencillo, pero significativo, como escribir tu primera l√≠nea de c√≥digo. Puedes comenzar con un breve mensaje de bienvenida:

`print("Bienvenidos al Cebollita FC")`

Este sencillo ejercicio representa el pitazo inicial para futuras predicciones estad√≠sticas basadas en datos reales. A partir del pr√≥ximo entrenamiento, se comenzar√° a trabajar con informaci√≥n aut√©ntica del club, comprendiendo estad√≠sticas, desempe√±o y descubriendo patrones √∫tiles para anticipar resultados.

Este nuevo enfoque con *machine learning* y Python permitir√° que analizar el f√∫tbol sea mucho m√°s eficiente, brind√°ndote las herramientas necesarias para comprender mejor cada situaci√≥n del partido.

**Archivos de la clase**

[partidos-cebollitas.csv](https://static.platzi.com/media/public/uploads/partidos_cebollitas_fe82a1a4-e109-41b1-8b78-d9b4341dacaf.csv "partidos-cebollitas.csv")

## Limpieza de datos deportivos con Pandas en Python

### üßº ¬øQu√© es la limpieza de datos?

La limpieza de datos incluye:

1. Cargar datos correctamente.
2. Identificar y tratar **valores nulos**.
3. Corregir **tipos de datos**.
4. Eliminar **duplicados** o errores.
5. Renombrar columnas y estandarizar nombres.
6. Filtrar registros no v√°lidos o inconsistentes.
7. Crear columnas √∫tiles (goles por minuto, etc.).

### üèüÔ∏è Supongamos que tienes este dataset (CSV)

```csv
jugador, goles, minutos_jugados, equipo, fecha
Messi, 3, 90, Inter Miami, 2023-09-12
Mbappe, , 85, PSG, 2023-09-12
Messi, 3, 90, Inter Miami, 2023-09-12
Lewandowski, 1, 78, FC Barcelona, 2023-09-12
Falcao, 0, , Rayo Vallecano, 2023-09-12
```

### üêº Paso a paso con Pandas

```python
import pandas as pd

# Cargar el archivo CSV
df = pd.read_csv('estadisticas.csv')

# Mostrar las primeras filas
print(df.head())
```

### üîç 1. Verificar valores nulos

```python
print(df.isnull().sum())  # ¬øD√≥nde hay valores faltantes?
```

‚û°Ô∏è Soluci√≥n:

```python
df['goles'].fillna(0, inplace=True)  # Rellenar con 0
df['minutos_jugados'].fillna(df['minutos_jugados'].mean(), inplace=True)  # Promedio
```

### üìã 2. Eliminar duplicados

```python
df = df.drop_duplicates()
```

### üî¢ 3. Corregir tipos de datos

```python
df['goles'] = df['goles'].astype(int)
df['minutos_jugados'] = df['minutos_jugados'].astype(int)
df['fecha'] = pd.to_datetime(df['fecha'])
```

### ‚úèÔ∏è 4. Renombrar columnas (opcional)

```python
df.rename(columns={'minutos_jugados': 'min_jugados'}, inplace=True)
```

### ‚ûó 5. Crear columnas nuevas (ej. eficiencia)

```python
df['goles_por_minuto'] = df['goles'] / df['min_jugados']
```

### üßπ 6. Filtrar registros no v√°lidos

```python
df = df[df['min_jugados'] > 0]  # Eliminar jugadores sin minutos jugados
```

### üìä Resultado limpio

```python
print(df)
```

### üß† Consejos extra

| Tarea                        | Funci√≥n √∫til de Pandas                 |
| ---------------------------- | -------------------------------------- |
| Ver resumen general          | `df.info()`                            |
| Estad√≠sticas b√°sicas         | `df.describe()`                        |
| Ver valores √∫nicos por campo | `df['equipo'].unique()`                |
| Filtrar por condici√≥n        | `df[df['equipo'] == 'PSG']`            |
| Exportar CSV limpio          | `df.to_csv('limpio.csv', index=False)` |

### Resumen

Analizar y limpiar los datos es clave antes de utilizar modelos predictivos en deportes. Al usar Python con la librer√≠a pandas, es posible manipular f√°cilmente grandes vol√∫menes de informaci√≥n, pasando de conjuntos de datos confusos y desorganizados a informaci√≥n clara y √∫til que pueda ayudar a prever futuros resultados del club.

#### ¬øQu√© herramientas se necesitan para la limpieza de datos deportivos?

Usamos principalmente Python y la librer√≠a pandas. Dentro del entorno de desarrollo de Visual Studio Code, importamos y utilizamos:

- pandas (`pd`), una herramienta robusta para manipulaci√≥n y an√°lisis de datos.
- Notebooks en Python para facilitar el an√°lisis interactivo de cada etapa del proceso de limpieza.

#### ¬øC√≥mo cargar y visualizar inicialmente los datos deportivos?

Los datos se cargan mediante la funci√≥n `pd.read_csv()`, que permite acceder directamente al archivo CSV. La funci√≥n `head()` muestra las primeras filas de nuestros datos, proporcionando una vista r√°pida y fundamental del estado inicial del dataset. Esta visi√≥n previa es semejante a observar los primeros minutos de juego para seleccionar la estrategia adecuada.

#### ¬øCu√°les son los pasos fundamentales para preparar los datos?

La preparaci√≥n de datos requiere una serie de t√©cnicas espec√≠ficas en Python:

#### ¬øC√≥mo evaluar la calidad general de los datos del equipo?

La funci√≥n info() es clave para obtener una visi√≥n general de los datos:

- Identifica columnas disponibles.
- Detecta valores ausentes o errores.
- Indica tipos de datos presentes (integer, objetos, etc.).
- Presenta consumo de memoria, √∫til para futuras optimizaciones.

#### ¬øC√≥mo lidiar con datos faltantes en los registros deportivos?

Para los valores nulos, particularmente en columnas cr√≠ticas como los goles anotados, se utiliza:

- `isnull().sum()` para identificar faltantes.
- Se rellenan estos valores con el promedio en lugar de eliminarlos, manteniendo la integridad del dataset sin introducir registros falsos.

#### ¬øQu√© es el One-Hot Encoding y c√≥mo se aplica en equipos deportivos?

Se aplica a variables categ√≥ricas como los nombres de equipos usando:

- `pd.get_dummies()` transforma estas categor√≠as en columnas binarias de ceros y unos.
- Facilitando que los algoritmos comprendan y procesen estos datos num√©ricamente.

#### ¬øC√≥mo gestionar duplicados y evitar su impacto en los resultados?

Con la funci√≥n `duplicate()`, eliminamos registros id√©nticos que podr√≠an sesgar el entrenamiento de los modelos predictivos, asegurando aprendizaje claro y √∫nico en cada caso.

#### ¬øPor qu√© y c√≥mo se ajustan los formatos de fecha?

Las fechas inconsistentes o mal formateadas se ajustan usando `pd.to_datetime()`. Esta transformaci√≥n permite realizar an√°lisis temporales √∫tiles para detectar patrones como rachas positivas o negativas en ciertas √©pocas del a√±o.

#### ¬øC√≥mo evaluar finalmente el estado de nuestro dataset limpio?

Luego de completar estas tareas, se recomienda verificar nuevamente con `info()` y `head()` el estado final de los datos. Adem√°s, confirmar con funciones como `shape` el tama√±o y la estructura en filas y columnas.

- Confirmar caracter√≠sticas generales del dataset.
- Asegurar ausencia de nulos o duplicados.
- Validar columnas y registros disponibles.

Este m√©todo provee claridad total antes de avanzar a modelar resultados con t√©cnicas m√°s avanzadas.

¬øQu√© otras t√©cnicas recomiendas para preparar datos antes de predecir resultados en deportes? ¬°Comparte tu opini√≥n en los comentarios!

**Archivos de la clase**

[partidos-cebollitas.csv](https://static.platzi.com/media/public/uploads/partidos_cebollitas_9eada58c-fb57-4224-a3f5-6d9efc881c2e.csv "partidos-cebollitas.csv")

**Lecturas recomendadas**

[pandas - Python Data Analysis Library](https://pandas.pydata.org/ "pandas - Python Data Analysis Library")

[machine-learning/02_preparacion.ipynb at main ¬∑ platzi/machine-learning ¬∑ GitHub](https://github.com/platzi/machine-learning/blob/main/02_preparacion.ipynb "machine-learning/02_preparacion.ipynb at main ¬∑ platzi/machine-learning ¬∑ GitHub")

[machine-learning/02_preparacion.ipynb at main ¬∑ platzi/machine-learning ¬∑ GitHub](https://github.com/platzi/machine-learning/blob/main/02_preparacion.ipynb "machine-learning/02_preparacion.ipynb at main ¬∑ platzi/machine-learning ¬∑ GitHub")

## An√°lisis de rendimiento deportivo con estad√≠stica descriptiva

### ‚öΩ ¬øQu√© es la estad√≠stica descriptiva en deportes?

Es el **an√°lisis num√©rico y gr√°fico** que describe y resume un conjunto de datos deportivos sin hacer inferencias m√°s all√° de la muestra.

### üìä Ejemplos de variables analizadas

| Variable              | Tipo         | Ejemplo                         |
| --------------------- | ------------ | ------------------------------- |
| Goles                 | Cuantitativa | 0, 1, 2, 3‚Ä¶                     |
| Minutos jugados       | Cuantitativa | 90, 85, 75‚Ä¶                     |
| Posici√≥n en el campo  | Cualitativa  | Delantero, Defensa, Mediocampo‚Ä¶ |
| Resultado del partido | Cualitativa  | Victoria, Derrota, Empate       |

### üß™ Medidas comunes

### 1. **Tendencia central**

* **Media (promedio)**: Valor medio de rendimiento.
* **Mediana**: Valor central (√∫til con datos sesgados).
* **Moda**: Valor m√°s frecuente (por ejemplo, goles m√°s comunes).

### 2. **Dispersi√≥n**

* **Rango**: Diferencia entre el valor m√°s alto y el m√°s bajo.
* **Desviaci√≥n est√°ndar**: Qu√© tanto var√≠an los datos respecto a la media.
* **Varianza**: Medida cuadr√°tica de dispersi√≥n.

### 3. **Resumen estad√≠stico r√°pido**

En Python:

```python
df.describe()
```

### üß± Ejemplo pr√°ctico con Pandas (f√∫tbol)

```python
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt

# Dataset simulado
df = pd.DataFrame({
    'Jugador': ['A', 'B', 'C', 'D', 'E'],
    'Goles': [10, 5, 8, 0, 3],
    'Asistencias': [4, 7, 2, 0, 1],
    'Minutos': [900, 800, 950, 400, 600]
})

# Estad√≠sticas descriptivas
print(df.describe())

# Agregar columna de eficiencia
df['Goles por 90 min'] = df['Goles'] / df['Minutos'] * 90

# Gr√°fico: comparaci√≥n de goles
sns.barplot(x='Jugador', y='Goles', data=df)
plt.title('Goles por Jugador')
plt.show()

# Gr√°fico: eficiencia de gol
sns.barplot(x='Jugador', y='Goles por 90 min', data=df)
plt.title('Goles por 90 Minutos')
plt.show()
```

### üìà ¬øQu√© puedes hacer con estos an√°lisis?

| Aplicaci√≥n                        | Ejemplo concreto                           |
| --------------------------------- | ------------------------------------------ |
| Comparar jugadores                | ¬øQui√©n tiene mejor promedio de goles?      |
| Evaluar consistencia              | ¬øQui√©n es m√°s regular en su rendimiento?   |
| Visualizar rendimiento por equipo | Barras, cajas, dispersi√≥n, radar, etc.     |
| Detectar valores at√≠picos         | ¬øHay jugadores con estad√≠sticas inusuales? |

### üß† Conclusi√≥n

La estad√≠stica descriptiva permite:

* Evaluar el **nivel y consistencia de desempe√±o**.
* Facilita la **toma de decisiones deportivas** (alineaciones, fichajes).
* Es base para aplicar modelos predictivos posteriormente.

### Resumen

¬øTe has preguntado por qu√© algunos partidos se ganan con facilidad y otros se complican m√°s de lo normal? La respuesta puede encontrarse en los datos, espec√≠ficamente en c√≥mo se analizan utilizando m√©todos de estad√≠stica descriptiva y visualizaci√≥n gr√°fica. Antes de predecir los resultados futuros, es esencial comprender en detalle los resultados del pasado.

#### ¬øQu√© herramientas necesitamos para analizar los partidos?

Para entender qu√© est√° pasando en el campo, necesitamos algunas herramientas t√©cnicas fundamentales:

- **Pandas**: manipulaci√≥n y preparaci√≥n inicial de nuestros datos.
- **Matplotlib y Seaborn**: para crear visualizaciones intuitivas que faciliten la interpretaci√≥n de informaci√≥n compleja.

Estas herramientas nos permiten extraer informaci√≥n crucial, como promedio de goles, desviaciones est√°ndar, m√°ximo y m√≠nimo de goles marcados.

#### ¬øC√≥mo identificar tendencias y patrones clave?

Las siguientes preguntas nos gu√≠an en el an√°lisis del rendimiento:

#### ¬øEs mejor nuestro desempe√±o como local o como visitante?

Al observar los promedios encontramos algo inesperado: el equipo tiene en promedio **2.2 goles como local** y **2.6 goles como visitante**, indicando un rendimiento s√≥lido incluso fuera de casa. Esto sugiere que nuestro rendimiento no depende √∫nicamente del apoyo local.

#### ¬øQu√© revelan los histogramas sobre nuestros goles?

Los histogramas, realizados con Seaborn, muestran frecuencias reales:

- Localmente, solemos marcar regularmente 2 a 4 goles.
- De visitante, aunque hay partidos con cero goles, sorprendentemente tambi√©n hay varios encuentros en los cuales llegamos a 3 o 5 goles anotados.

Estos gr√°ficos clarifican si nuestro rendimiento es consistente o variable partido a partido.

#### ¬øC√≥mo detectar resultados inusuales con Boxplots?

Los boxplots destacan f√°cilmente valores extremos:

- Se√±alan claramente los partidos excepcionales, tales como goleadas o resultados adversos.
- Revelan que es frecuente hacer entre 1 y 4 goles cuando jugamos en casa, con picos ocasionales de 5 goles.

Aunque la mayor√≠a de resultados est√°n concentrados en un rango limitado, estos valores ayudan a entender nuestras capacidades en escenarios extraordinarios.

#### ¬øTener m√°s posesi√≥n siempre significa m√°s goles?

Probamos esta hip√≥tesis usando un gr√°fico de dispersi√≥n:

- A pesar de una posesi√≥n del 45%, la cantidad de goles anotados var√≠a considerablemente.
- Diversidad en resultados, desde partidos sin goles hasta encuentros con cinco goles, indica que la posesi√≥n sola no determina nuestro rendimiento goleador.

Esto establece una relaci√≥n compleja entre la posesi√≥n del bal√≥n y la efectividad goleadora del equipo.

#### ¬øQu√© revela el mapa de calor sobre correlaciones importantes?

Utilizamos un mapa de calor para detectar conexiones ocultas entre diferentes acciones durante el partido. La correlaci√≥n m√°s alta registrada entre variables, como goles locales y posesi√≥n, es relativamente baja (0.17), indicando que las relaciones entre estas m√©tricas no son extremadamente fuertes.

No obstante, aun siendo significativas, su influencia es moderada, lo cual es √∫til para modelar predicciones futuras.

¬øQu√© correlaciones crees que debemos priorizar al momento de entrenar nuestros futuros modelos predictivos? Danos tu opini√≥n en los comentarios sobre qu√© variables te parecen m√°s determinantes para el rendimiento del equipo.

**Archivos de la clase**

[partidos-cebollitas.csv](https://static.platzi.com/media/public/uploads/partidos_cebollitas_e88b84b1-059b-4559-b1b5-78838f9f7ccc.csv "partidos-cebollitas.csv")

**Lecturas recomendadas**

[Tutorials ‚Äî Matplotlib 3.10.3 documentation](https://matplotlib.org/stable/tutorials/index "Tutorials ‚Äî Matplotlib 3.10.3 documentation")

[User guide and tutorial ‚Äî seaborn 0.13.2 documentation](https://seaborn.pydata.org/tutorial "User guide and tutorial ‚Äî seaborn 0.13.2 documentation")

[machine-learning/03_exploracion_datos_cebollitas.ipynb at main ¬∑ platzi/machine-learning ¬∑ GitHub](https://github.com/platzi/machine-learning/blob/main/03_exploracion_datos_cebollitas.ipynb "machine-learning/03_exploracion_datos_cebollitas.ipynb at main ¬∑ platzi/machine-learning ¬∑ GitHub")

## Normalizaci√≥n y estandarizaci√≥n de datos para modelos predictivos

### üìè ¬øPor qu√© normalizar o estandarizar?

Porque:

* Muchas t√©cnicas de ML **son sensibles a la escala de los datos**.
* Si tus variables tienen **unidades distintas** (por ejemplo, ‚Äúgoles‚Äù y ‚Äúminutos‚Äù), una puede dominar a la otra si no las escalas.
* Mejora la **velocidad de entrenamiento** y la **precisi√≥n del modelo**.

### üîÑ Diferencia entre normalizaci√≥n y estandarizaci√≥n

| T√©cnica                       | Qu√© hace                                                                           | Rango t√≠pico       |
| ----------------------------- | ---------------------------------------------------------------------------------- | ------------------ |
| **Normalizaci√≥n** (Min-Max)   | Escala los datos a un **rango fijo**, normalmente entre **0 y 1**                  | \[0, 1] o \[-1, 1] |
| **Estandarizaci√≥n** (Z-score) | Convierte los datos a una distribuci√≥n con **media = 0 y desviaci√≥n est√°ndar = 1** | Media = 0, Std = 1 |

### ‚öΩ Ejemplo en an√°lisis deportivo

Sup√≥n que tienes:

| Jugador | Goles | Minutos | Pases Completos |
| ------- | ----- | ------- | --------------- |
| A       | 5     | 900     | 300             |
| B       | 2     | 750     | 250             |
| C       | 7     | 1100    | 500             |

üëâ Estos valores est√°n en **escalas diferentes** ‚Üí necesitas escalarlos.

### üß™ En Python con `sklearn`

### üîπ Normalizaci√≥n (Min-Max Scaling)

```python
from sklearn.preprocessing import MinMaxScaler
import pandas as pd

# Datos simulados
df = pd.DataFrame({
    'Goles': [5, 2, 7],
    'Minutos': [900, 750, 1100],
    'Pases': [300, 250, 500]
})

scaler = MinMaxScaler()
df_norm = pd.DataFrame(scaler.fit_transform(df), columns=df.columns)

print("Normalizados:\n", df_norm)
```

### üî∏ Estandarizaci√≥n (Z-score)

```python
from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()
df_std = pd.DataFrame(scaler.fit_transform(df), columns=df.columns)

print("Estandarizados:\n", df_std)
```

### üß† ¬øCu√°ndo usar cada uno?

| Si vas a usar...                   | Recomendaci√≥n                                        |
| ---------------------------------- | ---------------------------------------------------- |
| KNN, SVM, Redes Neuronales, PCA    | ‚úÖ Escala tus datos (normalizaci√≥n o estandarizaci√≥n) |
| √Årboles de decisi√≥n, Random Forest | ‚ùå No es obligatorio escalar                          |
| Visualizaci√≥n (radar, scatter...)  | ‚úÖ Normalizar para comparaci√≥n clara                  |

### üéØ Conclusi√≥n

* **Normalizar o estandarizar** mejora el rendimiento del modelo.
* Elige el m√©todo seg√∫n el algoritmo que uses.
* Usa `sklearn.preprocessing` para escalar f√°cilmente.

### Resumen

Para asegurar predicciones precisas en modelos de aprendizaje autom√°tico, es clave **nivelar la escala de las variables**. Cuando los datos presentan rangos muy diversos, las variables con n√∫meros mayores pueden afectar injustamente los resultados. Aqu√≠ aprenderemos c√≥mo corregir esto con dos t√©cnicas fundamentales: **Min-Max Scaling** para normalizaci√≥n y Standard Scaler para estandarizaci√≥n.

#### ¬øPor qu√© es necesario escalar los datos antes de entrenar modelos?

Los modelos de aprendizaje autom√°tico pueden confundirse cuando las variables manejan escalas muy distintas. Por ejemplo, una variable como tiros al arco (valores entre 0 y 15) podr√≠a parecerle menos relevante al modelo que la posesi√≥n (del 0 al 100), simplemente por tener n√∫meros m√°s peque√±os. Esto no es realista, ya que ambas podr√≠an tener igual importancia.

#### ¬øQu√© ocurre al no escalar correctamente?

Cuando usamos datos sin escalar:

- El modelo asigna incorrectamente mayor importancia a magnitudes mayores.
- Se generan sesgos en las predicciones.
- Puede afectar negativamente la precisi√≥n del modelo.

Al escalar los datos, logramos una medida justa que permite al modelo aprender con mayor precisi√≥n.

#### ¬øQu√© diferencia hay entre Min-Max Scaling y Standard Scaler?

Existen dos m√©todos claves para escalar tus datos, cada uno ideal para ciertas circunstancias:

#### ¬øCu√°ndo usar Min-Max Scaling?

El Min-Max Scaling es ideal cuando tus datos no siguen una distribuci√≥n normal. Este m√©todo transforma cualquier valor num√©rico a un rango cerrado entre 0 y 1. Por ejemplo, si un futbolista tiene 12 tiros al arco y el m√°ximo registrado es 15, al aplicar Min-Max Scaling obtendremos:

- Resultado escalado: 12/15 = 0,8.

Este proceso se realiza usando la herramienta MinMaxScaler de las bibliotecas de procesamiento de datos.

#### ¬øEn qu√© casos se aplica Standard Scaler?

El Standard Scaler, por otro lado, es m√°s apropiado cuando deseas preservar la distribuci√≥n original de los datos. Este m√©todo centra la informaci√≥n alrededor de cero, con desviaci√≥n est√°ndar de uno. Es especialmente √∫til con algoritmos que necesitan datos centrados como regresi√≥n lineal o PCA. Los resultados obtenidos tendr√°n una distribuci√≥n estandarizada, eliminando cualquier sesgo por magnitud original.

#### ¬øC√≥mo aplicar estas t√©cnicas paso a paso?

Veamos brevemente c√≥mo aplicar ambos m√©todos utilizando herramientas comunes en Python como pandas para datos y las clases MinMaxScaler y StandardScaler para escalar.

#### Aplicando Min-Max Scaling a tus datos

- Primero, crea una instancia de MinMaxScaler.
- Utiliza la funci√≥n fit_transform para calcular el m√≠nimo y m√°ximo de cada columna y aplicar la escala a la vez.
- Guarda estos datos normalizados en columnas nuevas:

```python
from sklearn.preprocessing import MinMaxScaler
scaler_norm = MinMaxScaler()
datos_normalizados = scaler_norm.fit_transform(datos[['tiros_al_arco_local', 'tiros_al_arco_visitante']])
datos[['tiros_al_arco_local_norm', 'tiros_al_arco_visitante_norm']] = datos_normalizados
```

#### Aplicando Standard Scaler correctamente

Para estandarizar:

- Genera una instancia de StandardScaler.
- Nuevamente, usa fit_transform para calcular media y desviaci√≥n est√°ndar y aplicar la transformaci√≥n.
- Guarda los resultados en nuevas columnas:

```python
from sklearn.preprocessing import StandardScaler
scaler_std = StandardScaler()
datos_estandarizados = scaler_std.fit_transform(datos[['posesion_local', 'posesion_visitante']])
datos[['posesion_local_std', 'posesion_visitante_std']] = datos_estandarizados
```

#### ¬øC√≥mo saber si el escalado fue exitoso?

Para visualizar si tu escalado fue exitoso y efectivo, usa histogramas, una visualizaci√≥n que revisa c√≥mo se distribuyen tus datos escalados. Para ello, emplea bibliotecas como Matplotlib o Seaborn:

```python
import matplotlib.pyplot as plt 
import seaborn as sns

fig, axes = plt.subplots(1, 2)
sns.histplot(datos['tiros_al_arco_local_norm'], ax=axes[0])
axes[0].set_title('Tiros al Arco Local Normalizados')

sns.histplot(datos['posesion_local_std'], ax=axes[1], color='orange')
axes[1].set_title('Posesi√≥n Local Estandarizada')

plt.show()
```

Dichas gr√°ficas mostrar√°n claramente si los datos tienen una distribuci√≥n adecuada y equilibrada. Cu√©ntanos, ¬øqu√© inferencias puedes sacar de tu visualizaci√≥n?

**Lecturas recomendadas**

[7.3. Preprocessing data ‚Äî scikit-learn 1.7.0 documentation](https://scikit-learn.org/stable/modules/preprocessing "7.3. Preprocessing data ‚Äî scikit-learn 1.7.0 documentation")

[Importance of Feature Scaling ‚Äî scikit-learn 1.7.0 documentation](https://scikit-learn.org/stable/auto_examples/preprocessing/plot_scaling_importance "Importance of Feature Scaling ‚Äî scikit-learn 1.7.0 documentation")

[machine-learning/04_escalado_datos_cebollitas.ipynb at main ¬∑ platzi/machine-learning ¬∑ GitHub](https://github.com/platzi/machine-learning/blob/main/04_escalado_datos_cebollitas.ipynb "machine-learning/04_escalado_datos_cebollitas.ipynb at main ¬∑ platzi/machine-learning ¬∑ GitHub")

## Ingenier√≠a de caracter√≠sticas para mejorar modelos de machine learning

### üß† ¬øQu√© es la ingenier√≠a de caracter√≠sticas?

Es el proceso de:

1. **Crear nuevas variables** a partir de datos existentes.
2. **Seleccionar las m√°s relevantes.**
3. **Transformar o escalar datos** para que los modelos aprendan mejor.
4. **Codificar datos categ√≥ricos.**

### ‚öΩ Ejemplo en datos deportivos

Sup√≥n que tienes este conjunto de datos:

| Jugador     | Goles | Minutos | Pases Completos |
| ----------- | ----- | ------- | --------------- |
| Messi       | 3     | 90      | 70              |
| Lewandowski | 1     | 60      | 35              |

### üîß Podemos crear nuevas caracter√≠sticas como:

| Nueva variable            | F√≥rmula                           | Significado                             |
| ------------------------- | --------------------------------- | --------------------------------------- |
| Goles por minuto          | `Goles / Minutos`                 | Eficiencia goleadora                    |
| Pases por minuto          | `Pases / Minutos`                 | Participaci√≥n en juego                  |
| Participaci√≥n total       | `Goles + Asistencias`             | Impacto ofensivo                        |
| Pases acertados (%)       | `Pases / Pases intentados * 100`  | Precisi√≥n de pase (si se tiene el dato) |
| Diferencia de rendimiento | `Goles por minuto - media global` | Comparaci√≥n con otros                   |

### üß™ Ejemplo en Python

```python
import pandas as pd

# Datos b√°sicos
df = pd.DataFrame({
    'Jugador': ['Messi', 'Lewandowski'],
    'Goles': [3, 1],
    'Minutos': [90, 60],
    'Pases': [70, 35]
})

# Ingenier√≠a de caracter√≠sticas
df['Goles_por_minuto'] = df['Goles'] / df['Minutos']
df['Pases_por_minuto'] = df['Pases'] / df['Minutos']

print(df)
```

### üß† T√©cnicas comunes de ingenier√≠a de caracter√≠sticas

### üìå 1. **Escalado**

* Usar `MinMaxScaler` o `StandardScaler` para igualar escalas.

### üìå 2. **Codificaci√≥n de variables categ√≥ricas**

* `OneHotEncoder`, `LabelEncoder` para posiciones, equipos, etc.

### üìå 3. **Extracci√≥n de tiempo**

* Separar "fecha del partido" en "d√≠a de la semana", "mes", "temporada".

### üìå 4. **Cruces de variables**

* Multiplicar o dividir variables para encontrar relaciones (por ejemplo: **posesi√≥n √ó tiros al arco**).

### üìå 5. **Transformaciones estad√≠sticas**

* Logaritmo, ra√≠z cuadrada, z-score‚Ä¶ para normalizar distribuciones.

### üìà Beneficios

‚úÖ Mejora el rendimiento del modelo.
‚úÖ Permite modelos m√°s simples con mejores resultados.
‚úÖ Reduce la necesidad de redes neuronales profundas en problemas sencillos.
‚úÖ Mejora la **interpretabilidad** de los modelos.

### üß† Consejo clave

> "Un modelo simple con buenas caracter√≠sticas supera a un modelo complejo con malas caracter√≠sticas."

### Resumen

La ingenier√≠a de caracter√≠sticas, tambi√©n conocida como *feature engineering*, es una herramienta fundamental en el √°mbito del *machine learning*. Su objetivo principal consiste en crear nuevas variables a partir de datos ya existentes. Esto permite a los modelos identificar patrones m√°s profundos y √∫tiles, mejorando as√≠ notablemente su desempe√±o predictivo.

#### ¬øPor qu√© es valiosa la ingenier√≠a de caracter√≠sticas?

Esta t√©cnica transforma datos simples en informaci√≥n m√°s relevante para los modelos. Sabemos que los algoritmos no son capaces de detectar relaciones ocultas autom√°ticamente; sin embargo, un analista puede crear variables estrat√©gicas que aporten nuevo contexto al algoritmo:

- **Diferencia de goles**: goles del equipo local menos goles del visitante, √∫til para predecir si un equipo gan√≥, perdi√≥ o empat√≥.
- **Ratio de tiros sobre posesi√≥n**: relaciona los disparos realizados con la posesi√≥n durante el juego, midiendo eficiencia ofensiva.

Ambas variables aportan informaci√≥n valiosa que no est√° expl√≠citamente escrita en los datos originales.

#### ¬øQu√© pasos seguir para crear nuevas variables?

El proceso para implementar estas nuevas variables se desglosa en los siguientes bloques pr√°cticos:

#### Bloque n√∫mero uno: importar datos

Aqu√≠ es clave importar las bibliotecas necesarias, principalmente pandas, para tener acceso organizado y eficiente a los datos completos.

#### Bloque n√∫mero dos: calcular diferencia de goles

Esta nueva columna se crea restando los goles del equipo visitante a los del local, ayud√°ndonos a entender r√°pidamente el desempe√±o de los equipos.

#### Bloque n√∫mero tres: evaluar la eficiencia ofensiva

Se crea un ratio dividiendo los tiros al arco local sobre la posesi√≥n del equipo local. Este √≠ndice mide directamente la capacidad de aprovechar la posesi√≥n del bal√≥n para generar tiros al arco.

#### Bloque n√∫mero cuatro: visualizar con histogramas

Visualizar los datos es crucial. Aqu√≠ se recomienda utilizar hist plot de seaborne para observar la distribuci√≥n de la diferencia de goles:

- Importar bibliotecas (seaborne y matplotlib).
- Usar hist plot evaluando gr√°fica y visualmente la distribuci√≥n.

Esto permite una interpretaci√≥n r√°pida sobre c√≥mo se comporta esta nueva variable: ¬øel equipo tiende m√°s a empatar, perder o ganar?

#### Bloque n√∫mero cinco: establecer correlaciones

Finalmente, se utiliza un mapa de calor (heat map) para evaluar la correlaci√≥n entre variables originales y aquellas recientemente creadas. Esto es determinante para comprobar la utilidad real de estas caracter√≠sticas a√±adidas.

Por ejemplo, una fuerte correlaci√≥n encontrada en el an√°lisis fue entre goles locales y la diferencia de goles, indicando una relaci√≥n s√≥lida que puede mejorar los modelos predictivos.

¬øY t√∫ qu√© opinas de estas nuevas variables? ¬øEn qu√© situaciones crees que podr√≠an aportarte un mayor valor predictivo? Cu√©ntanos tu experiencia en los comentarios.

**Lecturas recomendadas**

[User Guide ‚Äî pandas 2.3.0 documentation](https://pandas.pydata.org/pandas-docs/stable/user_guide/index.html)

[machine-learning/05_ingenieria_caracteristicas_cebollitas.ipynb at main ¬∑ platzi/machine-learning ¬∑ GitHub](https://github.com/platzi/machine-learning/blob/main/05_ingenieria_caracteristicas_cebollitas.ipynb "machine-learning/05_ingenieria_caracteristicas_cebollitas.ipynb at main ¬∑ platzi/machine-learning ¬∑ GitHub")

## Selecci√≥n de variables relevantes para modelos predictivos

La **selecci√≥n de variables relevantes** (tambi√©n llamada **feature selection**) es una etapa crucial en machine learning porque:

* Mejora la **precisi√≥n** del modelo.
* Reduce el **overfitting**.
* Aumenta la **velocidad de entrenamiento**.
* Facilita la **interpretabilidad** del modelo.

### üß† ¬øQu√© es la selecci√≥n de variables?

Es el proceso de **elegir solo las caracter√≠sticas m√°s √∫tiles** para predecir una variable objetivo y **descartar las irrelevantes o redundantes**.

### ‚öΩ Ejemplo en an√°lisis deportivo

Imagina que tienes estas variables para predecir si un equipo ganar√°:

* Posesi√≥n del bal√≥n
* N√∫mero de tiros
* Goles recibidos
* Minutos jugados
* D√≠a de la semana
* Nombre del equipo rival

üëâ Algunas de estas **no ayudan** al modelo o incluso lo **confunden**. El objetivo es quedarte solo con las m√°s relevantes, como posesi√≥n y tiros.


### üîç T√©cnicas para seleccionar variables

### 1. **An√°lisis de correlaci√≥n**

Ideal para variables num√©ricas.

```python
import seaborn as sns
import matplotlib.pyplot as plt

# Matriz de correlaci√≥n
sns.heatmap(df.corr(), annot=True, cmap='coolwarm')
plt.title("Correlaci√≥n entre variables")
plt.show()
```

> Elimina variables muy correlacionadas entre s√≠ (multicolinealidad) o no relacionadas con la variable objetivo.

### 2. **M√©todo de importancia de caracter√≠sticas (feature importance)**

Usado con modelos como Random Forest, XGBoost o √°rboles de decisi√≥n.

```python
from sklearn.ensemble import RandomForestClassifier

model = RandomForestClassifier()
model.fit(X, y)

importancia = pd.Series(model.feature_importances_, index=X.columns)
importancia.sort_values(ascending=False).plot(kind='bar')
```

### 3. **Selecci√≥n autom√°tica (`SelectKBest`)**

```python
from sklearn.feature_selection import SelectKBest, f_classif

selector = SelectKBest(score_func=f_classif, k=5)  # Top 5 variables
X_new = selector.fit_transform(X, y)
```

### 4. **Eliminaci√≥n recursiva (`RFE`)**

```python
from sklearn.feature_selection import RFE
from sklearn.linear_model import LogisticRegression

modelo = LogisticRegression()
rfe = RFE(modelo, n_features_to_select=3)
fit = rfe.fit(X, y)

# Ver qu√© variables fueron seleccionadas
print(X.columns[fit.support_])
```

### ‚úÖ Buenas pr√°cticas

| Pr√°ctica                                  | Descripci√≥n                                                                                                         |
| ----------------------------------------- | ------------------------------------------------------------------------------------------------------------------- |
| Establece una **variable objetivo** clara | Ej: `gan√≥ = 1, no gan√≥ = 0`                                                                                         |
| Escala los datos si es necesario          | Mejora precisi√≥n en modelos sensibles a magnitudes                                                                  |
| Usa t√©cnicas combinadas                   | Correlaci√≥n + RFE, o Feature Importance + PCA                                                                       |
| Evita **leakage**                         | No incluyas variables que solo se conocen despu√©s del evento (ej. goles anotados si est√°s prediciendo el resultado) |

### üß† Conclusi√≥n

La selecci√≥n de variables:

* **Hace tus modelos m√°s precisos y r√°pidos**.
* Evita usar datos que **no aportan valor**.
* Es esencial en datasets deportivos con muchas estad√≠sticas por partido o jugador.

### Resumen

Optimizar modelos predictivos no siempre implica utilizar m√°s variables, sino seleccionar correctamente aquellas que realmente aportan valor a tu an√°lisis. Este m√©todo, conocido como selecci√≥n de caracter√≠sticas, ayuda a reducir ruido, simplificar modelos y prevenir sobreajustes, resultando en predicciones m√°s acertadas.

#### ¬øQu√© es la selecci√≥n de caracter√≠sticas en modelado predictivo?

La selecci√≥n de caracter√≠sticas consiste en identificar y retener √∫nicamente aquellas variables que presenten mayor relevancia estad√≠stica con el objetivo a predecir. Al aplicar esta pr√°ctica:

- Se simplifica el modelo, haciendo su interpretaci√≥n m√°s sencilla.
- Se eliminan variables irrelevantes que act√∫an como ruido.
- Mejora la capacidad de generalizaci√≥n y precisi√≥n del modelo.

#### ¬øC√≥mo realizar una selecci√≥n univariada con SelectKBest?

Utilizando herramientas del paquete *scikit-learn*, puedes aplicar SelectKBest para seleccionar aquellas variables con mejor rendimiento individual:

- Importa `SelectKBest` y `f_regression`.
- Usa `f_regression` para calcular la puntuaci√≥n F, evaluando qu√© tanto influye cada variable en tu objetivo.
- Define tu matriz de caracter√≠sticas X y tu vector objetivo Y.
- Selecciona las variables con mejores puntajes individuales y visualiza en orden decreciente cuales aportan m√°s:

```python
from sklearn.feature_selection import SelectKBest, f_regression
selector = SelectKBest(score_func=f_regression, k=2)
selector.fit(X, y)
```

#### ¬øPor qu√© utilizar √°rboles de decisi√≥n para evaluar importancia de variables?

Los √°rboles de decisi√≥n te permiten evaluar no solo correlaciones lineales, sino tambi√©n posibles interacciones o relaciones no lineales. Siguiendo estos pasos puedes beneficiarte de esta t√©cnica:

- Importa `DecisionTreeRegressor`.
- Instancia el modelo, define una semilla (`random_state`) para resultados reproducibles.
- Ajusta el modelo usando tus datos X e Y.
- Eval√∫a la importancia relativa de cada variable mediante la reducci√≥n total del error:

```python
from sklearn.tree import DecisionTreeRegressor
modelo_arbol = DecisionTreeRegressor(random_state=0)
modelo_arbol.fit(X, y)
```

#### ¬øQu√© aporta la visualizaci√≥n comparativa de t√©cnicas?

Una comparaci√≥n visual, mediante gr√°ficas de barras con seaborn y matplotlib, aclara la diferencia en aportaciones que cada variable tiene seg√∫n distintos m√©todos utilizados. Esto te permite validar conclusiones r√°pidamente y detectar variables consistentemente relevantes:

- Las t√©cnicas utilizadas fueron claramente comparadas:
- SelectKBest analiza correlaciones lineales.
- DecisionTreeRegressor eval√∫a relaciones complejas, incluyendo no lineales.

Aunque ambas t√©cnicas generaron valores espec√≠ficos diferentes, hubo coherencia en variables destacadas como posesi√≥n local y ratio tiros sobre posesi√≥n.

#### ¬øRealmente se necesitan todas las variables?

Este ejercicio pr√°ctico evidenci√≥ que menos variables pueden conseguir resultados equivalentes o superiores cuando est√°n correctamente elegidas:

- **Ratio de tiros sobre posesi√≥n**.
- **Porcentaje de posesi√≥n local**.

Estas variables han demostrado ser cruciales en la predicci√≥n eficaz de partidos.

**Lecturas recomendadas**

[1.13. Feature selection ‚Äî scikit-learn 1.7.0 documentation](https://scikit-learn.org/stable/modules/feature_selection.html "1.13. Feature selection ‚Äî scikit-learn 1.7.0 documentation")

[machine-learning/06_seleccion_caracteristicas_cebollitas.ipynb at main ¬∑ platzi/machine-learning ¬∑ GitHub](https://github.com/platzi/machine-learning/blob/main/06_seleccion_caracteristicas_cebollitas.ipynb "machine-learning/06_seleccion_caracteristicas_cebollitas.ipynb at main ¬∑ platzi/machine-learning ¬∑ GitHub")

[How to Choose a Feature Selection Method For Machine Learning](https://machinelearningmastery.com/feature-selection-with-real-and-categorical-data/ "How to Choose a Feature Selection Method For Machine Learning")

## Divisi√≥n de datos en entrenamiento y prueba con scikit-learn

Dividir tus datos en **entrenamiento y prueba** es una parte fundamental en cualquier proyecto de **machine learning**. Con **scikit-learn**, puedes hacerlo f√°cilmente usando la funci√≥n `train_test_split`.

### üß† ¬øPor qu√© dividir los datos?

* **Entrenamiento (train)**: se usa para ajustar (entrenar) el modelo.
* **Prueba (test)**: se usa para evaluar qu√© tan bien generaliza el modelo a datos nuevos.
* Evita que el modelo aprenda "de memoria" los datos (sobreajuste).

### ‚úÖ Ejemplo en Python con `scikit-learn`

Supongamos que tienes un conjunto de datos con caracter√≠sticas `X` y etiquetas `y`:

```python
from sklearn.model_selection import train_test_split

# Supongamos que X y y ya est√°n definidos
# X = caracter√≠sticas (variables independientes)
# y = etiqueta (variable objetivo)

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
```

### üîç Par√°metros:

* `test_size=0.2`: 20% de los datos se usan para prueba, 80% para entrenamiento.
* `random_state=42`: asegura que la divisi√≥n sea **reproducible** (siempre igual).

### üìä Visualizando tama√±os:

```python
print("Tama√±o entrenamiento:", X_train.shape)
print("Tama√±o prueba:", X_test.shape)
```

### üìå Tip adicional:

Si tu conjunto es muy **desbalanceado**, puedes usar:

```python
train_test_split(X, y, stratify=y, test_size=0.2)
```

Esto mantiene la **proporci√≥n de clases** tanto en entrenamiento como en prueba.

### Resumen

Evaluar correctamente un modelo de machine learning es crucial para asegurar su utilidad con datos que nunca ha visto anteriormente. Una buena manera de lograrlo es mediante la t√©cnica conocida como **train test split**. Esta t√©cnica consiste en dividir el conjunto de datos en dos partes principales: **entrenamiento**, donde el modelo aprende, y **prueba o test**, donde comprobamos su eficacia en escenarios nuevos.

##### ¬øPor qu√© es importante dividir los datos en entrenamiento y prueba?

Para evitar que nuestro modelo simplemente memorice o se adapte en exceso a los datos con los que fue entrenado (problema conocido como overfitting), es esencial verificar c√≥mo se comporta frente a datos nuevos. Esta divisi√≥n nos permite evaluar objetivamente su capacidad de generalizar lo aprendido:

- **Dato de entrenamiento**: Aqu√≠, el modelo aprende patrones y caracter√≠sticas esenciales.
- **Dato de prueba (test)**: Conjunto nuevo utilizado para validar la eficacia real y la generalizaci√≥n del modelo.

#### ¬øC√≥mo implementar la divisi√≥n de datos con scikit-learn?

Para llevar a cabo esta divisi√≥n, usamos la librer√≠a scikit-learn, espec√≠ficamente la funci√≥n train_test_split:

`from sklearn.model_selection import train_test_split`

Se configuran los par√°metros como:

- **test_size** (tama√±o del conjunto de prueba), habitualmente recomendado en 20%.
- **random_state**, para tener resultados consistentes en repeticiones.

`X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)`

#### ¬øC√≥mo puedo experimentar con diferentes tama√±os del conjunto prueba?

Existen herramientas como los widgets interactivos de Jupyter que pueden facilitar la comprensi√≥n del impacto:

```python
import ipywidgets as widgets
widgets.FloatSlider(value=0.2, min=0.1, max=0.4, step=0.05, continuous_update=False)
```

Usando controles din√°micos, experimentamos visualmente diferentes divisiones y examinamos c√≥mo afecta al conjunto:

- M√°s datos en entrenamiento implicar√° potencialmente mejor aprendizaje.
- M√°s datos en prueba permitir√° validar m√°s robustamente su predicci√≥n.

#### ¬øCu√°l es la recomendaci√≥n est√°ndar para dividir los datasets?

Lo habitual es utilizar una proporci√≥n de 80-20, manteniendo el 80% para el entrenamiento y el 20% restante para el test. Esta distribuci√≥n ha demostrado ser efectiva en la mayor√≠a de escenarios, equilibrando aprendizaje y validaci√≥n.

Ahora est√°s preparado para implementar esta pr√°ctica recomendada: dividir eficientemente los datos de tu modelo, garantizando as√≠ resultados confiables en nuevos conjuntos de informaci√≥n. ¬øListo para avanzar y aplicar regresi√≥n lineal en tus predicciones? Cu√©ntanos en comentarios c√≥mo te fue con tu nueva implementaci√≥n.

**Lecturas recomendadas**

[train_test_split ‚Äî scikit-learn 1.7.0 documentation](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html "train_test_split ‚Äî scikit-learn 1.7.0 documentation")

[machine-learning/07_division_datos_interactiva.ipynb at main ¬∑ platzi/machine-learning ¬∑ GitHub](https://github.com/platzi/machine-learning/blob/main/07_division_datos_interactiva.ipynb "machine-learning/07_division_datos_interactiva.ipynb at main ¬∑ platzi/machine-learning ¬∑ GitHub")

## Regresi√≥n lineal para predecir goles en f√∫tbol

Vamos a ver c√≥mo aplicar **regresi√≥n lineal** para predecir goles en f√∫tbol usando **Python y scikit-learn**. Este modelo es ideal si quieres explorar relaciones como:

üìä **¬øCu√°ntos goles marcar√° un equipo seg√∫n sus tiros al arco, posesi√≥n, pases, etc.?**

### ‚öΩ Ejemplo: Regresi√≥n Lineal para predecir goles

### üìÅ 1. Datos de ejemplo (`pandas`)

Supongamos que tienes un DataFrame con estas columnas:

```python
import pandas as pd

# Datos ficticios de partidos
data = {
    'tiros_arco': [5, 3, 8, 6, 7],
    'posesion': [60, 45, 70, 55, 65],
    'pases': [500, 300, 700, 450, 600],
    'goles': [2, 1, 3, 2, 3]
}

df = pd.DataFrame(data)
```

### üß™ 2. Divisi√≥n en entrenamiento y prueba

```python
from sklearn.model_selection import train_test_split

X = df[['tiros_arco', 'posesion', 'pases']]
y = df['goles']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
```

### üß† 3. Entrenar el modelo

```python
from sklearn.linear_model import LinearRegression

modelo = LinearRegression()
modelo.fit(X_train, y_train)
```

### üîç 4. Hacer predicciones

```python
y_pred = modelo.predict(X_test)
print("Predicciones de goles:", y_pred)
```

### üìà 5. Evaluar el modelo

```python
from sklearn.metrics import mean_squared_error, r2_score

print("Error cuadr√°tico medio:", mean_squared_error(y_test, y_pred))
print("R¬≤ score:", r2_score(y_test, y_pred))
```

---

### üßÆ 6. Interpretar los coeficientes

```python
coeficientes = pd.DataFrame({
    'Variable': X.columns,
    'Coeficiente': modelo.coef_
})
print(coeficientes)
```

### ‚úÖ ¬øQu√© te permite hacer esto?

* Ver **qu√© variables influyen m√°s** en los goles.
* Usar el modelo para predecir goles futuros de equipos nuevos.
* Crear visualizaciones con `matplotlib` o `seaborn`.es?

### Resumen

¬øTe imaginas poder predecir los goles de tu equipo favorito con m√©todos precisos? La regresi√≥n lineal, un modelo cl√°sico en *machine learning*, ofrece una herramienta poderosa para asociar variables clave, como posesi√≥n del bal√≥n y tiros al arco, con la diferencia de goles en cada partido.

#### ¬øQu√© significa predecir goles usando regresi√≥n lineal?

La regresi√≥n lineal busca la mejor f√≥rmula matem√°tica para identificar c√≥mo ciertas variables influyen en un resultado espec√≠fico, como la diferencia de goles. Para esto, se usan datos precisos y claros:

- Posici√≥n de bal√≥n.
- N√∫mero de tiros al arco.

Estos datos permiten predecir la diferencia de goles, es decir, cu√°ntos goles m√°s marcar√° uno de los equipos sobre el contrincante.

#### ¬øC√≥mo preparar los datos para entrenar el modelo?

El proceso es sencillo y directo:

- Se importa la biblioteca pandas y la funci√≥n train_test_split.
- Creaci√≥n de variable objetivo "diferencia de goles", definida por goles locales menos visitantes.
- Selecci√≥n de variables predictoras, que incluyen posesi√≥n local y cantidad de tiros al arco.
- Divisi√≥n del conjunto de datos en entrenamiento (80%) y evaluaci√≥n (20%), manteniendo la consistencia en resultados mediante el par√°metro random state.

#### ¬øQu√© resultados ofrece el modelo de regresi√≥n lineal?

Tras entrenar el modelo con la clase Linear Regression de la biblioteca scikit-learn, se obtienen dos elementos clave:

- **Intercepto (beta cero)**: predicci√≥n cuando las variables independientes son cero.
- **Coeficientes (betas)**: muestran c√≥mo cambia la predicci√≥n al incrementar cada variable en una unidad.

Por ejemplo:

- Incrementar 1 unidad la posesi√≥n local cambia en promedio 0.06 la diferencia de goles.
- Incrementar 1 unidad los tiros al arco locales cambia en promedio -0.05 la diferencia de goles.

Esto ayuda a comprender qu√© variables merecen atenci√≥n especial en la estrategia del equipo.

#### ¬øC√≥mo evaluar y visualizar las predicciones?

Luego de hacer las predicciones con modelo_rl.predict, es fundamental visualizar los resultados:

- Uso de gr√°ficos de dispersi√≥n comparando goles reales frente a predichos.
- Identificaci√≥n r√°pida de qu√© predicciones coinciden mejor con la realidad y cu√°les necesitan ajustes.

#### ¬øQu√© herramientas interactivas aportan valor adicional?

Los controles din√°micos, mediante sliders interactivos, permiten explorar c√≥mo diferentes escenarios en posesi√≥n y tiros afectan la predicci√≥n final. Esto resulta especialmente √∫til para demostraciones pr√°cticas y planificaci√≥n estrat√©gica con el entrenador o jugadores clave del equipo.

¬øHas probado previamente una herramienta similar? ¬øCu√°l ha sido tu experiencia utilizando modelos estad√≠sticos en deportes? ¬°Comparte tus opiniones y expectativas sobre estos m√©todos!
 
**Lecturas recomendadas**

[machine-learning/08_regresion_lineal_cebollitas.ipynb at main ¬∑ platzi/machine-learning ¬∑ GitHub](https://github.com/platzi/machine-learning/blob/main/08_regresion_lineal_cebollitas.ipynb "machine-learning/08_regresion_lineal_cebollitas.ipynb at main ¬∑ platzi/machine-learning ¬∑ GitHub")

## M√©tricas de evaluaci√≥n para modelos de machine learning

Las **m√©tricas de evaluaci√≥n** son fundamentales para medir el **rendimiento real de un modelo de machine learning**, tanto en tareas de **regresi√≥n** como de **clasificaci√≥n**. Aqu√≠ te presento las m√°s comunes y √∫tiles seg√∫n el tipo de problema:


### üßÆ Para **Regresi√≥n** (predicci√≥n de valores num√©ricos, como goles)

### 1. **MSE ‚Äì Error Cuadr√°tico Medio**

```python
from sklearn.metrics import mean_squared_error
mse = mean_squared_error(y_true, y_pred)
```

* Penaliza los errores grandes.
* Entre menor, mejor.

### 2. **RMSE ‚Äì Ra√≠z del Error Cuadr√°tico Medio**

```python
import numpy as np
rmse = np.sqrt(mse)
```

* M√°s interpretable, ya que est√° en la misma escala que la variable de salida.

### 3. **MAE ‚Äì Error Absoluto Medio**

```python
from sklearn.metrics import mean_absolute_error
mae = mean_absolute_error(y_true, y_pred)
```

* Promedia las diferencias absolutas.
* M√°s robusto a valores at√≠picos que el MSE.

### 4. **R¬≤ ‚Äì Coeficiente de Determinaci√≥n**

```python
from sklearn.metrics import r2_score
r2 = r2_score(y_true, y_pred)
```

* Cu√°nto del comportamiento de `y` es explicado por el modelo.
* Valores entre 0 y 1 (o negativos si el modelo es malo).
* Idealmente cercano a 1.

### üß™ Para **Clasificaci√≥n** (como predecir si un equipo gana, empata o pierde)

### 1. **Accuracy (Precisi√≥n global)**

```python
from sklearn.metrics import accuracy_score
accuracy = accuracy_score(y_true, y_pred)
```

* Proporci√≥n de predicciones correctas.

### 2. **Precision, Recall, F1-score**

```python
from sklearn.metrics import classification_report
print(classification_report(y_true, y_pred))
```

* **Precisi√≥n (Precision)**: cu√°ntos positivos predichos realmente lo eran.
* **Recall (Sensibilidad)**: cu√°ntos positivos reales fueron detectados.
* **F1-score**: balance entre precision y recall.

### 3. **Matriz de Confusi√≥n**

```python
from sklearn.metrics import confusion_matrix
print(confusion_matrix(y_true, y_pred))
```

* Muestra aciertos y errores por clase.

### 4. **ROC AUC (para clasificaci√≥n binaria)**

```python
from sklearn.metrics import roc_auc_score
roc_auc_score(y_true, y_proba)
```

* Mide la capacidad del modelo para diferenciar clases.

### üìä Visualizaciones √∫tiles

* `sklearn.metrics.plot_confusion_matrix()`
* `seaborn.heatmap()` para la matriz de confusi√≥n
* Gr√°ficas de ROC y Precision-Recall

### Resumen

Evaluar un modelo de *machine learning* es tan importante como entrenarlo. Al utilizar m√©tricas espec√≠ficas, es posible determinar qu√© tan bien est√° desempe√±√°ndose el modelo y si realmente puede usarse para tomar decisiones informadas. En este contexto, consideraremos cuatro m√©tricas fundamentales: **Error Cuadr√°tico Medio (MSE), Ra√≠z del Error Cuadr√°tico Medio (RMSE), Error Absoluto Medio (MAE) y Coeficiente de Determinaci√≥n (R¬≤)**.

#### ¬øQu√© m√©tricas existen para evaluar modelos predictivos?

Cada m√©trica brinda informaci√≥n particular sobre el rendimiento del modelo:

- **MSE** penaliza fuertemente errores significativos al amplificarlos al cuadrado, lo que ayuda a detectar desviaciones considerables aunque la interpretaci√≥n directa en t√©rminos pr√°cticos (por ejemplo, goles) es complicada.
- **RMSE** convierte el MSE nuevamente a la escala original, proporcionando una interpretaci√≥n m√°s intuitiva y f√°cil de comunicar; muy √∫til para presentaciones a personas no especializadas t√©cnicamente.
- **MAE** calcula el promedio directo de los errores absolutos, siendo robusto frente a valores extremos o outliers, con una interpretaci√≥n clara y directa.
- **Coeficiente R¬≤** muestra cu√°nto de la variaci√≥n en los datos logra explicar el modelo, indicando su capacidad general para captar tendencias.

#### ¬øC√≥mo implementar estas m√©tricas en Python?

Con bibliotecas como *pandas*, *NumPy* y funciones espec√≠ficas de evaluaci√≥n, se realiza un c√°lculo riguroso. Previamente, dividimos nuestros datos entre entrenamiento y validaci√≥n con *train test split*, y ajustamos un modelo de regresi√≥n lineal usando

```python
from sklearn.linear_model import LinearRegression
modelo_RL = LinearRegression()
modelo_RL.fit(X_train, y_train)
y_pred = modelo_RL.predict(X_test)
```

Luego, aplicamos las m√©tricas mencionadas:

```python
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
import numpy as np

mse = mean_squared_error(y_test, y_pred)
rmse = np.sqrt(mse)
mae = mean_absolute_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)

print(f"MSE: {mse:.2f}")
print(f"RMSE: {rmse:.2f}")
print(f"MAE: {mae:.2f}")
print(f"R¬≤: {r2:.2f}")
```

Estas medidas aportan claridad al Informe T√©cnico sobre el rendimiento del modelo y facilitan la comunicaci√≥n efectiva con distintos p√∫blicos interesados, como entrenadores o directivos.

#### ¬øPor qu√© usar m√∫ltiples m√©tricas de evaluaci√≥n?

Combinar varias m√©tricas es clave pues as√≠ obtenemos un panorama integral del modelo:

- MSE y RMSE: Detectan desviaciones importantes.
- MAE: Presenta el error t√≠pico claramente.
- R¬≤: Indica la proporci√≥n de la variabilidad explicada por el modelo.

Usadas conjuntamente, estas m√©tricas proveen un diagn√≥stico robusto sobre la utilidad pr√°ctica del modelo y ayudan a decidir pr√≥ximos pasos para ajustes y mejoras.

Te invito a compartir tus experiencias evaluando modelos o cualquier inquietud sobre las m√©tricas mencionadas.

**Lecturas recomendadas**

[Overfitting in Machine Learning: What It Is and How to Prevent It](https://elitedatascience.com/overfitting-in-machine-learning "Overfitting in Machine Learning: What It Is and How to Prevent It")

[machine-learning/09_evaluacion_modelo_cebollitas.ipynb at main ¬∑ platzi/machine-learning ¬∑ GitHub](https://github.com/platzi/machine-learning/blob/main/09_evaluacion_modelo_cebollitas.ipynb "machine-learning/09_evaluacion_modelo_cebollitas.ipynb at main ¬∑ platzi/machine-learning ¬∑ GitHub")

## Evaluaci√≥n de m√©tricas en regresi√≥n lineal para datos deportivos

Evaluar un modelo de **regresi√≥n lineal aplicado a datos deportivos** (como predecir goles, tiros al arco, puntos, etc.) es esencial para entender qu√© tan bien est√° funcionando tu modelo.

### ‚öΩ Escenario t√≠pico

Sup√≥n que tienes datos deportivos y est√°s prediciendo una variable como:

> **`y = goles`**
> A partir de variables como: tiros al arco, posesi√≥n, pases, faltas, etc.

### ‚úÖ M√©tricas clave para evaluaci√≥n de regresi√≥n lineal

### 1. üìâ **MSE ‚Äì Error Cuadr√°tico Medio**

* Penaliza fuertemente los errores grandes.

```python
from sklearn.metrics import mean_squared_error
mse = mean_squared_error(y_true, y_pred)
```

### 2. üìä **MAE ‚Äì Error Absoluto Medio**

* Promedia las diferencias absolutas. M√°s interpretable y robusto.

```python
from sklearn.metrics import mean_absolute_error
mae = mean_absolute_error(y_true, y_pred)
```

### 3. üìà **RMSE ‚Äì Ra√≠z del Error Cuadr√°tico Medio**

* Muestra el error promedio en la **misma escala que la variable objetivo**.

```python
rmse = mean_squared_error(y_true, y_pred, squared=False)
```

### 4. üßÆ **R¬≤ ‚Äì Coeficiente de Determinaci√≥n**

* Indica qu√© proporci√≥n de la varianza es explicada por el modelo.
* Valor entre 0 y 1 (mejor si se acerca a 1).

```python
from sklearn.metrics import r2_score
r2 = r2_score(y_true, y_pred)
```

### üîß Ejemplo en c√≥digo:

```python
from sklearn.linear_model import LinearRegression
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
import numpy as np
import pandas as pd

# Supongamos que tienes datos deportivos
data = {
    'tiros_arco': [5, 3, 8, 6, 7],
    'posesion': [60, 45, 70, 55, 65],
    'pases': [500, 300, 700, 450, 600],
    'goles': [2, 1, 3, 2, 3]
}
df = pd.DataFrame(data)

X = df[['tiros_arco', 'posesion', 'pases']]
y = df['goles']

# Divisi√≥n
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Entrenar modelo
modelo = LinearRegression()
modelo.fit(X_train, y_train)

# Predicci√≥n
y_pred = modelo.predict(X_test)

# M√©tricas
mse = mean_squared_error(y_test, y_pred)
mae = mean_absolute_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)

print(f"MSE: {mse:.2f}")
print(f"MAE: {mae:.2f}")
print(f"R\u00b2: {r2:.2f}")
```

### üìå Interpretaci√≥n de resultados

| M√©trica | ¬øQu√© indica?                                                  |
| ------- | ------------------------------------------------------------- |
| MSE     | Qu√© tan grandes son los errores (penaliza errores grandes).   |
| MAE     | Promedio del error absoluto (m√°s f√°cil de interpretar).       |
| RMSE    | Error t√≠pico (en unidades de goles, por ejemplo).             |
| R¬≤      | Qu√© tan bien el modelo explica la variabilidad del resultado. |

### Resumen

La creaci√≥n de un modelo de regresi√≥n lineal aplicado a datos deportivos, espec√≠ficamente para analizar goles en partidos de f√∫tbol, implica evaluar su efectividad mediante m√©tricas clave como el R cuadrado y el error cuadr√°tico medio (RMC). Al importar nuestros datos y el modelo entrenado, observamos c√≥mo estos indicadores nos informan claramente sobre el desempe√±o del modelo y su utilidad pr√°ctica.

#### ¬øQu√© informaci√≥n obtenemos al evaluar nuestro modelo?

Al aplicar m√©tricas como el R cuadrado (R dos), determinamos r√°pidamente si nuestro modelo de regresi√≥n lineal explica adecuadamente la variabilidad observada en los datos:

- Cuando el valor es negativo, indica que el modelo es incluso menos acertado que simples suposiciones aleatorias.
- Si el valor est√° entre cero y 0.3, el nivel explicativo es insuficiente, se√±alando potencial under fitting.
- Valores superiores a 0.3 sugieren un grado aceptable de explicaci√≥n de los datos.

En este caso, al encontrar un R cuadrado negativo, confirmamos que nuestro modelo actual no capta correctamente los patrones necesarios para explicar las variaciones en diferencia de goles.

#### ¬øSon adecuadas las variables utilizadas?

Es fundamental cuestionarnos sobre la elecci√≥n y relevancia de las variables usadas. ¬øEst√°n capturando realmente los factores decisivos que marcan la diferencia en goles? Algunas variables importantes, como la local√≠a o el desempe√±o rival en tiros al arco, podr√≠an estar ausentes. Considerar estas dimensiones del juego puede aportar mejores insights y elevar significativamente la precisi√≥n del modelo.

#### ¬øExisten limitaciones concretas al usar regresi√≥n lineal en f√∫tbol?

La regresi√≥n lineal presenta ciertas limitaciones importantes al aplicarla a situaciones complejas como partidos de f√∫tbol:

- Supone relaciones lineales entre variables, condici√≥n que no necesariamente refleja la din√°mica real de un partido.
- No captura adecuadamente interacciones o efectos no lineales frecuentes en contextos deportivos.

Estas limitaciones invitan a explorar otros modelos m√°s adecuados.

#### ¬øEs suficiente este modelo para la toma de decisiones deportivas?

Debido al bajo desempe√±o identificado, este modelo en espec√≠fico no podr√≠a considerarse suficiente para fundamentar decisiones deportivas estrat√©gicas. Su reducido poder explicativo limita la fiabilidad de las predicciones realizadas, aconsejando buscar alternativas que aporten una visi√≥n m√°s robusta y confiable.

#### ¬øQu√© alternativas podemos considerar para mejorar el modelo?

Tenemos diversas opciones de mejora y optimizaci√≥n:

- Incorporaci√≥n de nuevas variables relevantes, tales como la local√≠a, caracter√≠sticas del rival o estad√≠sticas adicionales (por ejemplo, tiros al arco).
- Aplicaci√≥n de distintos modelos predictivos m√°s sofisticados y flexibles, como √°rboles de decisi√≥n, random forest o algoritmos como XGBoost.
- Implementaci√≥n de validaci√≥n cruzada para evaluar con mayor precisi√≥n la capacidad predictiva.
- Filtrado y transformaci√≥n de datos para mejorar m√©tricas predictivas.

Mantener una mente abierta hacia estos enfoques diferentes podr√≠a resultar clave en la obtenci√≥n de modelos m√°s efectivos, asegurando decisiones estrat√©gicas enraizadas en an√°lisis s√≥lidos y precisos.

¬øY t√∫ qu√© opinas sobre estos enfoques adicionales? Esta reflexi√≥n es parte clave del aprendizaje continuo.
 
**Lecturas recomendadas**

[Overfitting in Machine Learning: What It Is and How to Prevent It](https://elitedatascience.com/overfitting-in-machine-learning "Overfitting in Machine Learning: What It Is and How to Prevent It")

[machine-learning/10_reflexion_modelo_regresion_cebollitas.ipynb at main ¬∑ platzi/machine-learning ¬∑ GitHub](https://github.com/platzi/machine-learning/blob/main/10_reflexion_modelo_regresion_cebollitas.ipynb "machine-learning/10_reflexion_modelo_regresion_cebollitas.ipynb at main ¬∑ platzi/machine-learning ¬∑ GitHub")

[Bonus: machine-learning/11_Bonus.ipynb at main ¬∑ platzi/machine-learning ¬∑ GitHub](https://github.com/platzi/machine-learning/blob/main/11_Bonus.ipynb "Bonus: machine-learning/11_Bonus.ipynb at main ¬∑ platzi/machine-learning ¬∑ GitHub")

## Reflexi√≥n Cr√≠tica y Conclusi√≥n

La comprensi√≥n de modelos de aprendizaje autom√°tico requiere no solo implementarlos, sino tambi√©n saber evaluar su rendimiento y adaptarse cuando no funcionan como esperamos. En el mundo real, es com√∫n tener que pivotar entre diferentes algoritmos hasta encontrar el que mejor se ajusta a nuestros datos y al problema que intentamos resolver. Aprender a interpretar m√©tricas y tomar decisiones basadas en ellas es una habilidad fundamental para cualquier cient√≠fico de datos.

#### ¬øPor qu√© fall√≥ el modelo de regresi√≥n lineal?

Al analizar el rendimiento de nuestro modelo de regresi√≥n lineal, nos encontramos con resultados poco alentadores. Las m√©tricas revelan un panorama claro:

- El modelo presenta un **R¬≤ negativo**, lo que indica que su desempe√±o es peor que simplemente predecir el valor promedio de los datos.
- Los errores (RMSE y MAE) son **bastante altos**, demostrando una pobre capacidad predictiva.

Estos resultados sugieren fuertemente que la relaci√≥n entre nuestras variables no es lineal. Cuando intentamos forzar una relaci√≥n lineal en datos que siguen patrones no lineales, el modelo no puede captar adecuadamente estos patrones, resultando en predicciones deficientes.

#### ¬øQu√© alternativas tenemos frente a un modelo que no funciona?

Cuando un modelo no cumple con nuestras expectativas, es momento de explorar alternativas. En este caso, el √°rbol de decisi√≥n emerge como una opci√≥n prometedora:

- Los √°rboles de decisi√≥n pueden capturar relaciones no lineales entre variables.
- Son capaces de modelar interacciones complejas sin asumir una forma espec√≠fica en los datos.

Al implementar este nuevo enfoque, observamos mejoras significativas en todas las m√©tricas:

- **Reducci√≥n en RMSE y MAE**: Los errores de predicci√≥n disminuyeron notablemente.
- R¬≤ positivo: A diferencia del modelo lineal, el √°rbol demuestra capacidad para explicar la variabilidad en los datos.

Estas mejoras confirman nuestra hip√≥tesis: estamos tratando con datos que presentan relaciones no lineales.

#### ¬øQu√© hemos aprendido hasta ahora?

Este ejercicio nos ha proporcionado valiosas lecciones:

1. **Preparaci√≥n de datos y construcci√≥n de modelos b√°sicos**: Hemos aprendido a procesar datos y crear modelos iniciales para abordar problemas.
2. **Evaluaci√≥n mediante m√©tricas**: Ahora sabemos interpretar diferentes m√©tricas y utilizarlas para evaluar el rendimiento de nuestros modelos.
3. **No todos los algoritmos sirven para todos los problemas**: Quiz√°s la lecci√≥n m√°s importante es comprender que debemos adaptar nuestro enfoque seg√∫n la naturaleza de los datos.

#### ¬øC√≥mo redise√±ar nuestra estrategia a partir de estos hallazgos?

Con base en los resultados obtenidos, podemos replantear nuestra aproximaci√≥n al problema:

1. **Redefinir un pipeline m√°s adecuado**: Utilizar el √°rbol de decisi√≥n como modelo base e iterar sobre √©l.
2. **Mejorar las visualizaciones**: Crear representaciones visuales que nos ayuden a entender mejor la estructura no lineal de nuestros datos.
3. **Explorar modelos m√°s robustos**: Considerar algoritmos m√°s avanzados que puedan capturar patrones complejos, como:
- Random Forest
- Gradient Boosting
- Redes neuronales

Este nuevo enfoque marca un comienzo m√°s realista y alineado con el comportamiento real de nuestros datos. La capacidad de pivotar y adaptarse cuando los resultados no son los esperados es una habilidad crucial en ciencia de datos.

El camino del aprendizaje autom√°tico est√° lleno de iteraciones y ajustes. Cada "fracaso" nos acerca m√°s a una comprensi√≥n profunda de nuestros datos y a soluciones m√°s efectivas. ¬øQu√© otros modelos crees que podr√≠an funcionar bien con datos no lineales? ¬øHas tenido experiencias similares donde tuviste que cambiar completamente tu enfoque?

**Archivos de la clase**

[jugadores-cebollitas.csv](https://static.platzi.com/media/public/uploads/jugadores_cebollitas_33ecea5c-f6f0-44ca-9ff4-e4135408bc04.csv "jugadores-cebollitas.csv")

**Lecturas recomendadas**

[3.4. Metrics and scoring: quantifying the quality of predictions ‚Äî scikit-learn 1.7.0 documentation](https://scikit-learn.org/stable/modules/model_evaluation.html "3.4. Metrics and scoring: quantifying the quality of predictions ‚Äî scikit-learn 1.7.0 documentation")

[machine-learning/12_Clase_Reflexion_Critica_Conclusion.ipynb at main ¬∑ platzi/machine-learning ¬∑ GitHub](https://github.com/platzi/machine-learning/blob/main/12_Clase_Reflexion_Critica_Conclusion.ipynb "machine-learning/12_Clase_Reflexion_Critica_Conclusion.ipynb at main ¬∑ platzi/machine-learning ¬∑ GitHub")

## Clasificaci√≥n automatizada de jugadores con algoritmo K-means

El algoritmo **K-Means** es una t√©cnica de **machine learning no supervisado** muy √∫til para **agrupar jugadores autom√°ticamente** seg√∫n su rendimiento, estilo o caracter√≠sticas f√≠sicas, sin necesidad de conocer de antemano sus posiciones o roles.

### ‚öΩ Ejemplo pr√°ctico: Clasificaci√≥n de jugadores con K-Means

### üìå Objetivo:

Agrupar jugadores en **clusters** similares con base en estad√≠sticas como:

* Goles
* Asistencias
* Pases completados
* Recuperaciones
* Velocidad, etc.

### üß∞ Paso a paso con Python:

#### 1. üì• Cargar datos de ejemplo

```python
import pandas as pd

# Datos ficticios
data = {
    'nombre': ['Jugador A', 'Jugador B', 'Jugador C', 'Jugador D', 'Jugador E'],
    'goles': [10, 2, 5, 0, 7],
    'asistencias': [5, 1, 2, 0, 3],
    'pases_completos': [300, 100, 200, 150, 250]
}

df = pd.DataFrame(data)
```

#### 2. üéØ Seleccionar variables y escalar

```python
from sklearn.preprocessing import StandardScaler

X = df[['goles', 'asistencias', 'pases_completos']]
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)
```

#### 3. ü§ñ Aplicar K-Means

```python
from sklearn.cluster import KMeans

kmeans = KMeans(n_clusters=2, random_state=42)
df['cluster'] = kmeans.fit_predict(X_scaled)
```

#### 4. üìä Ver los resultados

```python
print(df[['nombre', 'cluster']])
```

### üé® (Opcional) Visualizaci√≥n con `matplotlib`

```python
import matplotlib.pyplot as plt

plt.scatter(X_scaled[:, 0], X_scaled[:, 1], c=df['cluster'], cmap='viridis')
plt.xlabel('Goles (escalado)')
plt.ylabel('Asistencias (escalado)')
plt.title('Clasificaci√≥n de jugadores con K-Means')
plt.grid(True)
plt.show()
```

### üß† ¬øQu√© puedes hacer con esto?

* Identificar **tipos de jugadores** (ofensivos, creativos, defensivos, etc.).
* Sugerir **roles dentro del equipo** autom√°ticamente.
* Analizar c√≥mo se agrupan tus jugadores vs. los de otros equipos.

### üß™ Tip:

Si no sabes cu√°ntos grupos (clusters) elegir, usa el **m√©todo del codo (elbow method)** para determinar el mejor valor de `k`.

### Resumen

¬øSab√≠as que puedes utilizar Machine Learning no solo para predecir resultados, sino tambi√©n para entender mejor a los jugadores de tu equipo? Una herramienta potente es el algoritmo K-means, eficaz para agrupar atletas seg√∫n sus estad√≠sticas individuales. Con K-means, identificamos perfiles estrat√©gicos como delanteros goleadores, volantes creativos o defensas equilibrados sin asignar etiquetas previas.

#### ¬øQu√© es el aprendizaje no supervisado y c√≥mo se utiliza con jugadores de f√∫tbol?

El aprendizaje no supervisado implica ense√±ar al modelo sin ejemplos espec√≠ficos, permitiendo que encuentren patrones por su cuenta. A diferencia del aprendizaje supervisado, aqu√≠ no decimos qu√© es correcto o incorrecto desde el inicio. Con algoritmos como K-means, los jugadores se agrupan autom√°ticamente en base a caracter√≠sticas compartidas como:

- Goles realizados.
- Asistencias otorgadas.
- Pases completados.
- Tiros al arco.

Esto ayuda a revelar semejanzas que quiz√°s hasta el momento hab√≠an pasado desapercibidas.

#### ¬øC√≥mo funciona el algoritmo K-means para clasificar jugadores?

K-means agrupa jugadores seg√∫n caracter√≠sticas num√©ricas espec√≠ficas. Sigue estos pasos clave:

1. Selecciona un n√∫mero predefinido de clusters o grupos.
2. Asigna inicialmente los jugadores a un grupo bas√°ndose en cercan√≠a matem√°tica.
3. Ajusta iterativamente hasta lograr grupos estables.

De esta forma, jugadores con perfiles similares se agrupan entre s√≠, facilitando la interpretaci√≥n de sus desempe√±os.

#### ¬øQu√© ofrece explorar estos clusters en un entorno interactivo como Jupyter Notebook?

Cuando usamos K-means dentro de un notebook, podemos realizar procesos como:

#### Importar datos

Usando `pandas`, cargamos m√©tricas individuales desde un archivo:

```python
import pandas as pd
df = pd.read_csv('jugadores.csv')
df.head()
```

#### Visualizar relaciones estad√≠sticas

Con librer√≠as como `seaborn` y `matplotlib`, visualizamos patrones y correlaciones f√°cilmente:

```python
import seaborn as sns
import matplotlib.pyplot as plt
sns.pairplot(df)
plt.show()
```

#### Aplicar el clustering con K-means

Implementamos el algoritmo indicando el n√∫mero de grupos deseado:

```python
from sklearn.cluster import KMeans
modelo = KMeans(n_clusters=3, random_state=0)
df['cluster'] = modelo.fit_predict(df[['goles', 'asistencias', 'pases', 'tiros_al_arco']])
df.head()
```

#### ¬øC√≥mo interpretar los grupos generados por K-means?

Con gr√°ficos y estad√≠sticas podemos definir perfiles claros. Por ejemplo, un grupo con alta cifra de goles y tiros, pero pocas asistencias, sugiere delanteros ofensivos. As√≠ mismo, un grupo predominante en asistencias y pases podr√≠a indicar volantes creativos.

#### Visualizaci√≥n gr√°fica de clusters

Un gr√°fico de dispersi√≥n o scatter plot permite visualizar r√°pidamente estos perfiles:

```python
plt.figure(figsize=(10,6))
sns.scatterplot(data=df, x='goles', y='asistencias', hue='cluster', palette='Set1')
plt.title('Grupos de Jugadores seg√∫n Goles y Asistencias')
plt.xlabel('Goles')
plt.ylabel('Asistencias')
plt.show()
```

#### Exploraci√≥n interactiva

La interactividad permite ajustar din√°micamente el n√∫mero de grupos para identificar la cantidad ideal de perfiles √∫tiles:

```python
import ipywidgets as widgets
from ipywidgets import interact

def cluster_interactivo(num_clusters):
    modelo = KMeans(n_clusters=num_clusters, random_state=0)
    df['cluster'] = modelo.fit_predict(df[['goles', 'asistencias', 'pases', 'tiros_al_arco']])
    sns.scatterplot(data=df, x='goles', y='asistencias', hue='cluster', palette='Set1')
    plt.show()

interact(cluster_interactivo, num_clusters=(2,6,1))
```

#### ¬øQu√© beneficios aporta clasificar jugadores mediante K-means?

El an√°lisis automatizado permite: - Entrenar a jugadores seg√∫n su perfil espec√≠fico. - Tomar decisiones t√°cticas fundamentadas en estad√≠sticas reales. - Identificar necesidades claras para futuros fichajes.

Ahora cuentas con una herramienta fiable para conocer en profundidad a tus jugadores, optimizar entrenamientos e implementar t√°cticas efectivas. ¬øTe animas a probarla en tu equipo y contarnos qu√© patrones o grupos nuevos encontraste?
 
**Lecturas recomendadas**

[2.3. Clustering ‚Äî scikit-learn 1.7.0 documentation](https://scikit-learn.org/stable/modules/clustering.html#k-means "2.3. Clustering ‚Äî scikit-learn 1.7.0 documentation")

[machine-learning/16_clustering_kmeans_jugadores.ipynb at main ¬∑ platzi/machine-learning ¬∑ GitHub](https://github.com/platzi/machine-learning/blob/main/16_clustering_kmeans_jugadores.ipynb "machine-learning/16_clustering_kmeans_jugadores.ipynb at main ¬∑ platzi/machine-learning ¬∑ GitHub")

## Interpretaci√≥n de clusters K-Means para perfiles de jugadores

Una vez que aplicaste **K-Means** y tienes los jugadores agrupados en **clusters**, el siguiente paso es interpretar esos grupos. Es decir: **¬øqu√© significa cada cluster?** ¬øQu√© perfil de jugador representa?

### üéØ ¬øQu√© es interpretar los clusters?

Interpretar un **cluster** es descubrir **qu√© tienen en com√∫n los jugadores dentro de ese grupo**. Esto se hace observando las **caracter√≠sticas promedio** de cada grupo.

### üß† Pasos para interpretar clusters de jugadores

### 1. ‚úÖ **Agregar el n√∫mero de cluster a tu DataFrame**

Si no lo has hecho:

```python
df['cluster'] = kmeans.labels_
```

### 2. üìä **Agrupar por cluster y obtener estad√≠sticas**

```python
perfil_cluster = df.groupby('cluster').mean(numeric_only=True)
print(perfil_cluster)
```

Esto te dir√°, por ejemplo:

| cluster | goles | asistencias | pases\_completos |
| ------- | ----- | ----------- | ---------------- |
| 0       | 7.5   | 3.2         | 280              |
| 1       | 1.0   | 0.3         | 120              |

üëâ Aqu√≠ puedes decir:

* Cluster 0 = **jugadores ofensivos** (marcan m√°s, asisten m√°s).
* Cluster 1 = **jugadores defensivos o con menor participaci√≥n ofensiva**.

### 3. üß© **Etiquetar clusters con perfiles intuitivos**

Puedes usar la media de los datos o visualizaciones para decidir etiquetas como:

| Cluster | Perfil sugerido           |
| ------- | ------------------------- |
| 0       | "Atacantes creativos"     |
| 1       | "Defensores o suplentes"  |
| 2       | "Mediocampistas de apoyo" |

### 4. üìà (Opcional) **Visualiza los clusters**

```python
import matplotlib.pyplot as plt

plt.scatter(X_scaled[:, 0], X_scaled[:, 1], c=df['cluster'], cmap='viridis')
plt.xlabel("Goles (escalado)")
plt.ylabel("Asistencias (escalado)")
plt.title("Clusters de jugadores - KMeans")
plt.show()
```

Si tienes m√°s de 2 dimensiones, puedes usar PCA para reducir a 2D:

```python
from sklearn.decomposition import PCA

pca = PCA(n_components=2)
X_pca = pca.fit_transform(X_scaled)

plt.scatter(X_pca[:, 0], X_pca[:, 1], c=df['cluster'], cmap='tab10')
plt.title("Clusters de jugadores (PCA)")
plt.xlabel("PC1")
plt.ylabel("PC2")
plt.show()
```

### üß™ Consejo profesional

* A√±ade variables **contextuales**: minutos jugados, posici√≥n, equipo, etc.
* Compara tu interpretaci√≥n con la realidad (¬øel modelo detecta bien a los delanteros, volantes, etc.?).

### Resumen

El an√°lisis del rendimiento deportivo mediante t√©cnicas avanzadas como el clustering K-Means permite identificar r√°pidamente perfiles claros dentro de un equipo de f√∫tbol. Aprender√°s c√≥mo interpretar clusters generados a partir de estad√≠sticas clave, como goles, asistencias, pases completados y tiros al arco, identificando qui√©nes destacan en ataque, defensa o juego colectivo. Esta habilidad constituye una valiosa herramienta estrat√©gica y t√°ctica para cualquier cuerpo t√©cnico.

#### ¬øQu√© es el an√°lisis por clustering usando K-Means?

El algoritmo K-Means es una t√©cnica del aprendizaje no supervisado usada para agrupar individuos, como jugadores de f√∫tbol, seg√∫n ciertas caracter√≠sticas estad√≠sticas. Su objetivo es identificar perfiles o grupos homog√©neos para facilitar la toma de decisiones t√°cticas y estrat√©gicas.

#### ¬øC√≥mo preparar los datos para K-Means?

En primer lugar, se importan y visualizan los datos mediante la librer√≠a pandas en Python, asegurando observar bien las columnas disponibles. Los datos seleccionados t√≠picamente para este an√°lisis incluyen:

- Goles.
- Asistencias.
- Pases completados.
- Tiros al arco.

La ejecuci√≥n del algoritmo K-Means requiere √∫nicamente estas variables espec√≠ficas para crear grupos √∫tiles basados en estad√≠sticas reales de juego.

```python
import pandas as pd
jugadores = pd.read_csv('jugadores.csv')
print(jugadores.columns)
```

#### ¬øC√≥mo interpretar los resultados del an√°lisis?

Una vez creados los clusters por K-Means, utilizamos el m√©todo `.groupby()` junto a `.mean()` para calcular promedios de cada m√©trica dentro de cada cluster. Este proceso revela perfiles promedio muy claros de cada grupo. Observando as√≠:

- Qu√© jugadores anotan m√°s.
- Qui√©nes asisten m√°s frecuentemente.
- Cu√°les completan m√°s pases o rematan m√°s al arco.

#### ¬øC√≥mo se visualizan y comparan los clusters?

La visualizaci√≥n mediante Boxplots permite examinar con claridad y rapidez la distribuci√≥n interna y los valores at√≠picos (outliers) por cada grupo. Las gr√°ficas obtenidas destacan de inmediato las diferencias estad√≠sticamente significativas entre clusters.

Mediante estas visualizaciones podemos confirmar hip√≥tesis, por ejemplo:

- El cluster 0 presenta m√°s goles.
- El cluster 1 destaca en asistencias.
- El cluster con m√°s tiros al arco posiblemente representa delanteros.

Esto ayuda mucho al cuerpo t√©cnico a entender claramente d√≥nde sobresale cada jugador.

#### ¬øC√≥mo utilizar widgets para una exploraci√≥n din√°mica?

La utilizaci√≥n de widgets de selecci√≥n r√°pido permite filtrar datos visualmente, lo cual es extremadamente √∫til en reuniones t√©cnicas. Mediante Python, se pueden ver jugadores espec√≠ficos por cluster junto a sus m√©tricas destacadas. Esto permite una interacci√≥n en tiempo real, mejorando la comprensi√≥n y facilitando la planificaci√≥n t√©cnica.

```python
import ipywidgets as widgets
from IPython.display import display

cluster_selector = widgets.Dropdown(options=[0,1,2])

def mostrar_jugadores(cluster):
    display(jugadores[jugadores['cluster'] == cluster])

widgets.interact(mostrar_jugadores, cluster=cluster_selector)
```

#### ¬øC√≥mo aplicar estos resultados en decisiones reales?

El an√°lisis avanzado mediante clustering es directamente aplicable en decisiones t√°cticas, ayudando a los entrenadores a definir roles espec√≠ficos dentro del campo de juego:

- Organizar alineaciones √≥ptimas seg√∫n las fortalezas estad√≠sticas.
- Dise√±ar entrenamientos personalizados, enfocados en el perfil real.
- Evaluar el potencial fichaje basados en necesidades concretas del equipo.

Este enfoque claro y objetivo basado en datos puede ser crucial para implementar una gesti√≥n t√°ctica moderna que conduzca a mejores resultados deportivos.

Finalmente, la pr√≥xima t√©cnica a revisar ser√° PCA (Principal Component Analysis), utilizada para simplificar visualizaciones complejas sin perder informaci√≥n relevante.
 
**Lecturas recomendadas**

[Las 12 mejores herramientas y software UX para perfeccionar la experiencia de usuario](https://www.hotjar.com/es/diseno-ux/herramientas/ "Las 12 mejores herramientas y software UX para perfeccionar la experiencia de usuario")

[Plotting Time Series Boxplots](https://towardsdatascience.com/plotting-time-series-boxplots-5a21f2b76cfe/ "Plotting Time Series Boxplots")

[machine-learning/17_interpretacion_clusters_jugadores.ipynb at main ¬∑ platzi/machine-learning ¬∑ GitHub](https://github.com/platzi/machine-learning/blob/main/17_interpretacion_clusters_jugadores.ipynb "machine-learning/17_interpretacion_clusters_jugadores.ipynb at main ¬∑ platzi/machine-learning ¬∑ GitHub")

## An√°lisis PCA para agrupar jugadores seg√∫n rendimiento

El **An√°lisis de Componentes Principales (PCA)** es una t√©cnica muy √∫til para:

üîπ **Reducir la dimensionalidad** de tus datos
üîπ **Visualizar grupos (clusters) de jugadores** en 2D o 3D
üîπ **Mantener la mayor varianza posible** de los datos originales

### ‚öΩ Escenario: Agrupar jugadores seg√∫n rendimiento

Sup√≥n que tienes un DataFrame `df_jugadores` con estad√≠sticas como:

* Goles
* Asistencias
* Tiros al arco
* Pases completados
* Recuperaciones
* ... y una columna `cluster` asignada por `KMeans`.

### üß∞ Paso a paso: An√°lisis PCA en Python

### 1. üì¶ Importar librer√≠as necesarias

```python
from sklearn.decomposition import PCA
from sklearn.preprocessing import StandardScaler
import matplotlib.pyplot as plt
import seaborn as sns
```

### 2. ‚öôÔ∏è Preparar los datos

```python
# Selecciona solo las columnas num√©ricas de rendimiento
features = ['goles', 'asistencias', 'pases_completados (%)', 'tiros_al_arco']

# Estandarizar para que todas las variables tengan media 0 y varianza 1
X = StandardScaler().fit_transform(df_jugadores[features])
```

### 3. üß† Aplicar PCA

```python
pca = PCA(n_components=2)  # Para visualizaci√≥n en 2D
X_pca = pca.fit_transform(X)

# Agregar los componentes al DataFrame
df_jugadores['PC1'] = X_pca[:, 0]
df_jugadores['PC2'] = X_pca[:, 1]
```

### 4. üìä Visualizar los clusters en el espacio PCA

```python
plt.figure(figsize=(8, 6))
sns.scatterplot(
    x='PC1',
    y='PC2',
    hue='cluster',
    palette='Set2',
    data=df_jugadores,
    s=100,
    edgecolor='k'
)
plt.title('Clusters de jugadores en espacio PCA')
plt.xlabel(f'PC1 ({pca.explained_variance_ratio_[0]*100:.1f}% varianza)')
plt.ylabel(f'PC2 ({pca.explained_variance_ratio_[1]*100:.1f}% varianza)')
plt.grid(True)
plt.show()
```

### ‚úÖ ¬øQu√© interpretas de este gr√°fico?

* Los **puntos cercanos** representan jugadores similares en sus estad√≠sticas.
* Cada **color** representa un **cluster de K-Means**.
* Si los clusters est√°n **bien separados**, significa que tu segmentaci√≥n tiene **sentido y valor anal√≠tico**.
* Puedes analizar qu√© **variables contribuyen m√°s a cada componente** usando:

```python
pd.DataFrame(pca.components_, columns=features, index=['PC1', 'PC2'])
```

### Resumen

El an√°lisis de datos en f√∫tbol puede complicarse cuando manejamos m√∫ltiples variables por jugador, como goles, asistencias o precisi√≥n. La t√©cnica PCA, o An√°lisis de Componentes Principales, simplifica este proceso reduciendo m√∫ltiples variables a solo dos o tres componentes principales, ofreciendo una visualizaci√≥n gr√°fica clara e intuitiva del rendimiento y agrupaci√≥n natural de jugadores.

#### ¬øQu√© es PCA y c√≥mo simplifica el an√°lisis futbol√≠stico?

El PCA es una t√©cnica matem√°tica que transforma variables complejas en unas pocas nuevas llamadas componentes principales. Estas nuevas variables son combinaciones de las originales y retienen la mayor parte de la informaci√≥n inicial. Esto permite:

- Visualizar datos complejos en gr√°ficos 2D o 3D.
- Crear res√∫menes efectivos del rendimiento individual y grupal.
- Identificar grupos naturales de jugadores seg√∫n estad√≠sticas espec√≠ficas.

#### ¬øC√≥mo beneficia el PCA al scouting y decisiones t√°cticas?

Realizar un an√°lisis mediante PCA tiene m√∫ltiples ventajas:

- Facilita la identificaci√≥n visual r√°pida de grupos de jugadores (delanteros, volantes, defensivos).
- Permite detectar jugadores at√≠picos o outliers, con habilidades √∫nicas en comparaci√≥n con el equipo.
- Simplifica la comparaci√≥n directa entre jugadores.
- Apoya la toma de decisiones t√°cticas efectivas y selecci√≥n de refuerzos ideales.

#### Visualizaci√≥n pr√°ctica del rendimiento con PCA

En el ejemplo pr√°ctico, tomando en cuenta variables como goles, asistencias o tiros, el PCA revela diferentes grupos claros en un solo gr√°fico:

- Los delanteros destacan en una esquina por su alta cantidad de goles y tiros.
- Mediocampistas aparecen centralizados, combinando diversas capacidades.
- Volantes resaltan por asistencias y pases, ubicados generalmente en otra √°rea del gr√°fico.

#### Integraci√≥n con clustering (K-means)

Se complementa PCA con K-means clustering para asignar etiquetas visuales claras a cada jugador seg√∫n su estilo de juego:

- Cada color identifica un perfil futbol√≠stico particular.
- Sirve para planificaci√≥n, entrenamientos espec√≠ficos, fichajes y scouting.
- Facilita la exposici√≥n visual sencilla y r√°pida de perfiles t√©cnicos al cuerpo encargado.

#### Visualizaci√≥n interactiva del PCA

Con herramientas interactivas, como widgets dropdown, se puede:

- Explorar interactivamente combinaciones de componentes principales.
- Presentar al cuerpo t√©cnico visualizaciones din√°micas y personalizadas.
- Facilitar el an√°lisis detallado del rendimiento en tiempo real.

#### ¬øQu√© se logra al implementar PCA en el an√°lisis futbol√≠stico?

Implementar PCA implica obtener:

- Reducci√≥n efectiva de la complejidad de los datos.
- Visualizaci√≥n r√°pida y clara de agrupamientos naturales y perfiles espec√≠ficos de jugadores.
- Una herramienta √°gil que respalde decisiones t√©cnicas inteligentes en tiempo real.

Te invito a comentar qu√© otros usos pr√°cticos considerar√≠as para PCA dentro de tu equipo.
 
**Lecturas recomendadas**

[2.5. Decomposing signals in components (matrix factorization problems) ‚Äî scikit-learn 1.7.0 documentation](https://scikit-learn.org/stable/modules/decomposition.html#pca "2.5. Decomposing signals in components (matrix factorization problems) ‚Äî scikit-learn 1.7.0 documentation")

[machine-learning/18_pca_visualizacion_jugadores.ipynb at main ¬∑ platzi/machine-learning ¬∑ GitHub](https://github.com/platzi/machine-learning/blob/main/18_pca_visualizacion_jugadores.ipynb "machine-learning/18_pca_visualizacion_jugadores.ipynb at main ¬∑ platzi/machine-learning ¬∑ GitHub")

## Pipeline integrado de Machine Learning para an√°lisis deportivo

Un **pipeline de Machine Learning** bien dise√±ado para **an√°lisis deportivo** te permite automatizar y optimizar todo el flujo de trabajo, desde los datos hasta las predicciones.

### ‚öΩ ¬øQu√© es un pipeline de ML en an√°lisis deportivo?

Es un **flujo estructurado** que:

1. Recibe y limpia datos de rendimiento deportivo.
2. Extrae o transforma variables (features).
3. Aplica escalamiento o normalizaci√≥n.
4. Entrena un modelo (regresi√≥n, clasificaci√≥n, clustering...).
5. Eval√∫a el desempe√±o del modelo.
6. Aplica el modelo a nuevos datos.

### üîÑ Ejemplo de pipeline con `scikit-learn`

### üéØ Caso pr√°ctico:

Predecir la cantidad de goles de un jugador a partir de sus estad√≠sticas (tiros, asistencias, pases, etc.).

### ‚úÖ 1. Importar librer√≠as

```python
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LinearRegression
from sklearn.pipeline import Pipeline
from sklearn.metrics import mean_squared_error, r2_score
```

### ‚úÖ 2. Datos de ejemplo

```python
df = pd.DataFrame({
    'tiros_al_arco': [30, 12, 45, 10, 33],
    'asistencias': [5, 2, 7, 1, 3],
    'pases_completados': [300, 150, 400, 120, 280],
    'goles': [12, 3, 15, 2, 10]  # variable objetivo
})

X = df.drop('goles', axis=1)
y = df['goles']
```

### ‚úÖ 3. Dividir en entrenamiento y prueba

```python
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
```

### ‚úÖ 4. Crear el pipeline

```python
pipeline = Pipeline([
    ('scaler', StandardScaler()),              # Escalamiento de datos
    ('regresor', LinearRegression())           # Modelo de regresi√≥n
])
```

### ‚úÖ 5. Entrenar el modelo

```python
pipeline.fit(X_train, y_train)
```

### ‚úÖ 6. Evaluar el modelo

```python
y_pred = pipeline.predict(X_test)

print("RMSE:", mean_squared_error(y_test, y_pred, squared=False))
print("R¬≤:", r2_score(y_test, y_pred))
```

### üöÄ ¬øQu√© m√°s se puede integrar al pipeline?

* **Selecci√≥n de variables** (`SelectKBest`, `RFE`)
* **Reducci√≥n de dimensionalidad** (`PCA`)
* **Modelos avanzados** (Random Forest, XGBoost)
* **Cross-validation**
* **Exportaci√≥n autom√°tica con `joblib`**

### üß† ¬øPor qu√© usar pipelines?

* üí° Reproducibilidad
* üîÅ Reutilizaci√≥n del flujo
* ‚úÖ Evitas errores entre etapas
* üì¶ Es f√°cil de integrar con **GridSearchCV** y producci√≥n

### Resumen

La inteligencia deportiva a trav√©s de modelos de *machine learning* est√° transformando la forma en que equipos y entrenadores ejecutan sus estrategias. Al combinar eficazmente modelos supervisados y no supervisados en un pipeline integrado, logramos predicciones precisas sobre resultados de partidos y an√°lisis autom√°tico de perfiles de jugadores.

#### ¬øQu√© es un pipeline integrado avanzado?

Un pipeline integrado avanzado en el √°mbito deportivo permite automatizar todo un flujo de trabajo, desde la preparaci√≥n de datos hasta la generaci√≥n autom√°tica de predicciones. Esta herramienta re√∫ne modelos supervisados y no supervisados para ofrecer resultados coherentes, claros y escalables en tiempo real.

Este pipeline presenta dos funciones centrales:

- **Modelo supervisado (Regresi√≥n Ridge)**: predice diferencias esperadas de goles teniendo en cuenta estad√≠sticas clave como posesi√≥n de bal√≥n y cantidad de tiros.
- **Modelo no supervisado (Cl√∫ster K-Means)**: clasifica autom√°ticamente a los jugadores en grupos claramente definidos seg√∫n estad√≠sticas individuales tales como goles, asistencias y pases concretados.

La combinaci√≥n de ambos modelos constituye un poderoso motor anal√≠tico:

- Escala autom√°ticamente datos en ambos modelos.
- Genera predicciones claras y f√°ciles de interpretar.
- Facilita decisiones r√°pidas y efectivas sobre estrategias a seguir durante los partidos.

#### ¬øC√≥mo funciona la integraci√≥n entre modelos supervisados y no supervisados?

La aplicaci√≥n funciona en varios pasos bien definidos:

1. Carga y preparaci√≥n de datasets sobre partidos y jugadores.
2. Implementaci√≥n del pipeline supervisado con regresi√≥n Ridge para predecir resultados.
3. Uso de K-Means en un pipeline no supervisado para clasificar a los jugadores en perfiles de acuerdo a su desempe√±o.
4. An√°lisis integrado para visualizar resultados esperados y perfiles de jugadores disponibles, proporcionando una base s√≥lida para decisiones t√°cticas en tiempo real.

#### ¬øC√≥mo esta herramienta beneficia al cuerpo t√©cnico?

Contar con esta herramienta predictiva es como tener un asistente inteligente 24/7. Permite:

- Visualizar r√°pidamente c√≥mo puede desarrollarse un partido, prediciendo diferencias de goles basadas en escenarios ajustables de posesi√≥n y tiros al arco.
- Identificar claramente tipos espec√≠ficos de jugadores seg√∫n perfiles individuales clasificados previamente.
- Ajustar en tiempo real las t√°cticas seg√∫n las predicciones generadas.
- Crear an√°lisis personalizados para recomendaciones t√°cticas, fichajes o entrenamientos espec√≠ficos.

Este sistema tambi√©n incluye widgets interactivos que permiten una interacci√≥n din√°mica con los modelos predictivos, ofreciendo al equipo t√©cnico una plataforma intuitiva y accesible para evaluar escenarios cambiantes.

¬øQu√© ajustes t√°cticos sugerir√≠as para optimizar resultados en el pr√≥ximo partido? Te invito a comentar tus ideas basadas en estas herramientas predictivas.

**Lecturas recomendadas**

[Pipeline ‚Äî scikit-learn 1.7.0 documentation](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html "Pipeline ‚Äî scikit-learn 1.7.0 documentation")

[machine-learning/19_pipeline_avanzado_presentacion.ipynb at main ¬∑ platzi/machine-learning ¬∑ GitHub](https://github.com/platzi/machine-learning/blob/main/19_pipeline_avanzado_presentacion.ipynb "machine-learning/19_pipeline_avanzado_presentacion.ipynb at main ¬∑ platzi/machine-learning ¬∑ GitHub")

## Redes neuronales artificiales con PyTorch para clasificaci√≥n binaria

Las **redes neuronales artificiales (ANN)** con **PyTorch** son una herramienta poderosa para tareas como **clasificaci√≥n binaria**, por ejemplo:

> ¬øUn equipo gana (1) o no gana (0) un partido?

### ‚öôÔ∏è ¬øQu√© cubriremos?

* Estructura de una red neuronal para clasificaci√≥n binaria
* C√≥digo en PyTorch paso a paso
* Entrenamiento, evaluaci√≥n y predicci√≥n

### ‚úÖ Paso 1: Librer√≠as necesarias

```python
import torch
import torch.nn as nn
import torch.optim as optim
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import accuracy_score
import numpy as np
```

### ‚úÖ Paso 2: Datos de ejemplo

Supongamos que tienes estad√≠sticas de partidos:

```python
# X = tiros al arco, posesi√≥n, pases, etc.
X = np.array([
    [5, 60, 300],
    [2, 45, 150],
    [8, 70, 400],
    [3, 40, 100],
    [6, 65, 280]
])

# y = 1 si gan√≥ el equipo, 0 si no
y = np.array([1, 0, 1, 0, 1])
```

### ‚úÖ Paso 3: Preprocesamiento

```python
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

X_train, X_test, y_train, y_test = train_test_split(
    X_scaled, y, test_size=0.2, random_state=42)

X_train = torch.tensor(X_train, dtype=torch.float32)
X_test  = torch.tensor(X_test, dtype=torch.float32)
y_train = torch.tensor(y_train, dtype=torch.float32).view(-1, 1)
y_test  = torch.tensor(y_test, dtype=torch.float32).view(-1, 1)
```

### ‚úÖ Paso 4: Red neuronal

```python
class RedBinaria(nn.Module):
    def __init__(self):
        super(RedBinaria, self).__init__()
        self.net = nn.Sequential(
            nn.Linear(3, 8),    # 3 features de entrada
            nn.ReLU(),
            nn.Linear(8, 4),
            nn.ReLU(),
            nn.Linear(4, 1),
            nn.Sigmoid()        # Activaci√≥n para clasificaci√≥n binaria
        )

    def forward(self, x):
        return self.net(x)
```

### ‚úÖ Paso 5: Entrenamiento

```python
modelo = RedBinaria()
criterio = nn.BCELoss()  # Binary Cross Entropy
optimizador = optim.Adam(modelo.parameters(), lr=0.01)

# Entrenar
for epoch in range(200):
    modelo.train()
    salida = modelo(X_train)
    loss = criterio(salida, y_train)
    
    optimizador.zero_grad()
    loss.backward()
    optimizador.step()

    if epoch % 20 == 0:
        print(f"Epoch {epoch}, Loss: {loss.item():.4f}")
```

### ‚úÖ Paso 6: Evaluaci√≥n

```python
modelo.eval()
with torch.no_grad():
    pred = modelo(X_test)
    pred_labels = (pred >= 0.5).float()

accuracy = accuracy_score(y_test, pred_labels)
print(f"Accuracy: {accuracy:.2f}")
```

### ‚úÖ ¬øQu√© puedes ajustar?

* Cantidad de capas o neuronas
* Activaciones (ReLU, Tanh)
* M√©tricas (F1, precisi√≥n, recall)
* Funci√≥n de p√©rdida (por ejemplo `BCEWithLogitsLoss` sin `Sigmoid`)

### Resumen

Comprender el funcionamiento de las **redes neuronales artificiales (RNA)** es fundamental para avanzar en el √°rea del aprendizaje profundo o *deep learning*. Estas redes, capaces de aprender patrones de forma autom√°tica, constituyen la base de muchos sistemas de inteligencia artificial, especialmente en aplicaciones deportivas como el f√∫tbol. Usando PyTorch, una herramienta de programaci√≥n y an√°lisis, podemos definir, entrenar y evaluar nuestras propias redes neuronales con facilidad y precisi√≥n.

#### ¬øQu√© herramientas necesitamos para crear una red neuronal?

Para comenzar el trabajo con RNA en PyTorch, es fundamental contar con las bibliotecas adecuadas:

- **Torch**: proporciona soporte b√°sico para tensores y autograd.
- **Torch NN**: incluye elementos esenciales para crear las diferentes capas de una red.
- **Torch Optim**: usado para actualizar los par√°metros y pesos.
- **NumPy**: facilita la manipulaci√≥n de matrices en Python.

Estas herramientas nos permiten definir redes, manejar datos y realizar entrenamiento supervisado de manera efectiva.

#### ¬øC√≥mo crear y entrenar una red neuronal sencilla para clasificaci√≥n binaria?

El proceso inicia con un dataset sint√©tico sencillo:

- Creamos datos con 100 muestras y 4 caracter√≠sticas cada una.
- Convertimos estos datos y sus etiquetas en tensores, utilizando `Torch.from_numpy`.

Luego definimos una red neuronal compuesta por:

- Una capa oculta de 8 neuronas con activaci√≥n ReLU.
- Una capa de salida con activaci√≥n sigmoide, √∫til para problemas de clasificaci√≥n binaria.

La p√©rdida en clasificaci√≥n se mide mediante la funci√≥n BCLoss, adecuada para este tipo de activaci√≥n. Para actualizar los pesos y optimizar la red se utiliza Adam Optimizer, lo cual facilita la convergencia y mejora el rendimiento.

El entrenamiento implica calcular predicciones, evaluar errores, obtener gradientes y ajustar pesos autom√°ticamente. Cada √©poca del entrenamiento verifica la p√©rdida para determinar c√≥mo progresa el aprendizaje.

#### ¬øC√≥mo evaluar y ajustar la estructura de la red neuronal?

Para medir resultados, se transforma la salida de la red en predicciones binarias usando un umbral de 0.5 y se eval√∫a la precisi√≥n mediante el porcentaje de aciertos:

- Se desactivan los c√°lculos de gradientes para rapidez.
- Se obtiene la precisi√≥n final del modelo, observando cu√°ntas predicciones acierta frente al total del dataset.

Adem√°s, se incluye una herramienta interactiva para modificar la arquitectura de red de manera din√°mica:

- Podemos ajustar f√°cilmente el n√∫mero de capas ocultas entre 1 y 5.
- Cada capa modifica c√≥mo aprende y generaliza el modelo.
- Este ejercicio ilustra la importancia del balance entre la capacidad del modelo para aprender y evitar sobreajustes.

Experimentar con diferentes configuraciones te permitir√° comprender claramente c√≥mo se correlacionan la arquitectura de la red y su eficacia en los resultados pr√°cticos del f√∫tbol, al mejorar desde soluciones de detecci√≥n de jugadas hasta el an√°lisis detallado de im√°genes y videos.
 
**Lecturas recomendadas**

[Tutorials  |  TensorFlow Core](https://www.tensorflow.org/tutorials "Tutorials  |  TensorFlow Core")

[PyTorch](https://pytorch.org/ "PyTorch")

[machine-learning/20_intro_redes_neuronales.ipynb at main ¬∑ platzi/machine-learning ¬∑ GitHub](https://github.com/platzi/machine-learning/blob/main/20_intro_redes_neuronales.ipynb "machine-learning/20_intro_redes_neuronales.ipynb at main ¬∑ platzi/machine-learning ¬∑ GitHub")

## An√°lisis de sentimientos en comentarios deportivos con NLP

El **an√°lisis de sentimientos** con **NLP (Procesamiento de Lenguaje Natural)** es ideal para interpretar comentarios de fans, periodistas o redes sociales sobre eventos deportivos, jugadores o equipos.

### üéØ ¬øQu√© es el an√°lisis de sentimientos?

Es una t√©cnica de NLP que **detecta la opini√≥n emocional** detr√°s de un texto:

* **Positivo** ‚Üí elogios, entusiasmo, apoyo
* **Negativo** ‚Üí cr√≠ticas, decepci√≥n
* **Neutral** ‚Üí informaci√≥n objetiva o sin carga emocional

### üõ†Ô∏è Herramientas comunes para hacerlo en Python

* **NLTK / TextBlob** ‚Üí f√°cil para empezar
* **Hugging Face Transformers** (modelos preentrenados como BERT)
* **scikit-learn** con TF-IDF y regresores
* **spaCy** para tareas de NLP general + extensiones

### ‚úÖ Pipeline t√≠pico de an√°lisis de sentimientos deportivo

### 1. üßæ Recolectar comentarios

Ejemplo:

```python
comentarios = [
    "¬°Qu√© gran partido jug√≥ Messi!",
    "Fue una verg√ºenza el arbitraje.",
    "El equipo no mostr√≥ nada hoy.",
    "Incre√≠ble atajada del arquero.",
    "Un empate justo, buen nivel de ambos."
]
```

### 2. üßΩ Preprocesamiento (con `nltk` o `re`)

```python
import re

def limpiar(texto):
    texto = texto.lower()
    texto = re.sub(r'[^\w\s]', '', texto)  # Eliminar signos
    return texto

comentarios_limpios = [limpiar(c) for c in comentarios]
```

### 3. üì¶ An√°lisis r√°pido con `TextBlob`

```python
from textblob import TextBlob

for c in comentarios_limpios:
    blob = TextBlob(c)
    print(f"Comentario: {c}")
    print(f"Polaridad: {blob.sentiment.polarity:.2f} ‚Üí {'Positivo' if blob.sentiment.polarity > 0 else 'Negativo' if blob.sentiment.polarity < 0 else 'Neutral'}")
    print()
```

### üß† ¬øQu√© hace TextBlob?

* `polarity`: valor entre -1 (negativo) y 1 (positivo)
* `subjectivity`: qu√© tan subjetivo u objetivo es el texto (opcional para otras tareas)

### üìà ¬øY si quiero usar un modelo m√°s potente como BERT?

```python
from transformers import pipeline

clasificador = pipeline("sentiment-analysis", model="nlptown/bert-base-multilingual-uncased-sentiment")

resultados = clasificador(comentarios)
for comentario, res in zip(comentarios, resultados):
    print(f"{comentario} ‚Üí {res['label']}, score: {res['score']:.2f}")
```

Este modelo entrega predicciones del 1 al 5 üåü.

#3# üîç Aplicaciones en deportes

* üèüÔ∏è **Monitorear reacciones** en tiempo real durante partidos
* üë• **Evaluar percepci√≥n** de fans sobre jugadores o decisiones t√°cticas
* üìä **Visualizar tendencias** emocionales en redes o foros
* üì¢ **Segmentar audiencia** por tono de opini√≥n

### Resumen

¬øTe imaginas qu√© decisiones podr√≠as tomar si supieras exactamente lo que sienten los fan√°ticos de tu equipo? Eso es lo que propone el procesamiento de lenguaje natural (NLP), una poderosa rama de la inteligencia artificial (IA) que permite a las m√°quinas entender, interpretar y analizar textos humanos, desde comentarios en redes hasta reportes de prensa.

#### ¬øQu√© es NLP y c√≥mo puede aplicarse en an√°lisis deportivos?

El NLP (*Natural Language Processing*) es una tecnolog√≠a clave en sistemas conocidos como Siri, Google o ChatGPT. Gracias a esta tecnolog√≠a, puedes extraer informaci√≥n clave de opiniones escritas por seguidores y medios, transform√°ndolas en decisiones basadas en datos emocionales concretos.

En el contexto deportivo, esto significa:

- Medir la moral de la hinchada luego de partidos clave.
- Identificar cr√≠ticas y alabanzas hacia distintas √°reas del equipo, como la defensa o el ataque.
- Tomar decisiones estrat√©gicas que est√©n conectadas con la realidad emocional del club.

#### ¬øC√≥mo preparar los datos textuales para analizarlos con NLP?

La efectividad del an√°lisis NPL depende fundamentalmente de c√≥mo prepares tus datos. El proceso inicial es sencillo y directo:

1. **Carga de datos**: Importar tus comentarios deportivos desde archivos CSV utilizando pandas y asegurarte que cada comentario sea tratado como texto.
2. **Limpieza de texto**: Crear una funci√≥n sencilla en Python que utilice expresiones regulares para:
3. Convertir todas las letras a min√∫sculas.
4. Eliminar espacios excesivos, signos de puntuaci√≥n y caracteres especiales.
5. **Inspecci√≥n inicial**: Visualizar los primeros resultados limpios para confirmar que el proceso fue exitoso.

Aqu√≠ un breve ejemplo en Python:

```python
import re

def limpiar_texto(texto):
    texto = texto.lower()
    texto = re.sub(r'[^a-zA-Z√±√°√©√≠√≥√∫√º0-9\s]', '', texto)
    texto = re.sub(r'\s+', ' ', texto).strip()
    return texto
```

Esta funci√≥n simplifica considerablemente los comentarios, volvi√©ndolos m√°s f√°ciles de analizar y comprender.

#### ¬øC√≥mo visualizar f√°cilmente los resultados del an√°lisis emocional?

Las representaciones visuales son herramientas potentes para entender r√°pidamente grandes vol√∫menes de informaci√≥n cualitativa:

- **Nube de palabras**: Generar gr√°ficos visuales del vocabulario m√°s repetido en los comentarios, permitiendo identificar f√°cilmente preocupaciones recurrentes o temas valiosos para el equipo t√©cnico.
- **Distribuci√≥n de sentimientos**: Representar gr√°ficamente cu√°ntos comentarios son positivos, negativos o neutros ayuda a detectar tendencias generales entre los seguidores.

Ejemplo para generar una nube de palabras:

```python
from wordcloud import WordCloud
import matplotlib.pyplot as plt

wordcloud = WordCloud(width=800, height=400, colormap='viridis').generate(texto_total)
plt.figure(figsize=(10,5))
plt.imshow(wordcloud, interpolation='bilinear')
plt.axis('off')
plt.show()
```

Utilizando Seaborn se genera una distribuci√≥n visual de sentimientos:

```python
import seaborn as sns
sns.countplot(data=df_comentarios, x='sentimiento')
plt.title('Distribuci√≥n de Sentimientos')
plt.xlabel('Sentimiento')
plt.ylabel('Frecuencia')
plt.show()
```

#### ¬øC√≥mo explorar comentarios espec√≠ficos mediante interactividad?

Integrar funciones interactivas permite examinar comentarios puntuales basados en su categor√≠a emocional. Esto puede lograrse mediante widgets en Jupyter Notebook, facilitando la exploraci√≥n cualitativa del contenido.

Un sencillo ejemplo de implementaci√≥n interactiva:

```python
import ipywidgets as widgets
from IPython.display import display

seleccion = widgets.Dropdown(options=df_comentarios['sentimiento'].unique())

def mostrar_comentarios(categoria):
    display(df_comentarios[df_comentarios['sentimiento'] == categoria].sample(5))

widgets.interactive(mostrar_comentarios, categoria=seleccion)
```

Este enfoque mejora enormemente la interacci√≥n con los datos y aporta claridad en la toma de decisiones deportivas guiadas por las emociones reales de seguidores y prensa.
 
**Archivos de la clase**

[comentarios-deportivos.csv](https://static.platzi.com/media/public/uploads/comentarios_deportivos_a58295c0-8866-44e6-b80e-1ca5f7c2342b.csv "comentarios-deportivos.csv")

**Lecturas recomendadas**

[spaCy 101: Everything you need to know ¬∑ spaCy Usage Documentation](https://spacy.io/usage/spacy-101 "spaCy 101: Everything you need to know ¬∑ spaCy Usage Documentation")

[NLTK Book](https://www.nltk.org/book/ "NLTK Book")

[Rate limit ¬∑ GitHub](https://github.com/platzi/machine-learning/blob/main/22_intro_nlp_deportivo.ipynb "Rate limit ¬∑ GitHub")