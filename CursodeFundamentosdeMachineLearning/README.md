# Curso de Fundamentos de Machine Learning

## Tipos de modelos de machine learning para analizar equipos deportivos

### üß† 1. **Modelos Supervisados**

Se usan cuando tienes datos **etiquetados** (es decir, con resultados conocidos).

### üìä a) **Clasificaci√≥n**

Predicen categor√≠as discretas (ganar, perder, empatar, etc.)

**Ejemplos:**

* Predecir si un equipo ganar√° el pr√≥ximo partido.
* Clasificar si un jugador est√° en forma o lesionado.

**Modelos comunes:**

* Regresi√≥n log√≠stica
* √Årboles de decisi√≥n
* Random Forest
* SVM (M√°quinas de vectores soporte)
* Redes neuronales

### üìà b) **Regresi√≥n**

Predicen un **valor num√©rico continuo**.

**Ejemplos:**

* Predecir cu√°ntos goles marcar√° un equipo.
* Estimar el rendimiento de un jugador.

**Modelos comunes:**

* Regresi√≥n lineal / ridge / lasso
* XGBoost
* Redes neuronales

### üß† 2. **Modelos No Supervisados**

Se usan cuando **no hay etiquetas** conocidas.

### üîç a) **Clustering (agrupamiento)**

Agrupa datos similares autom√°ticamente.

**Ejemplos:**

* Agrupar jugadores seg√∫n estilo de juego.
* Detectar patrones en los rivales (equipos ofensivos vs. defensivos).

**Modelos comunes:**

* K-means
* DBSCAN
* Modelos de mezcla gaussiana

### üßÆ b) **An√°lisis de Componentes Principales (PCA)**

Reduce dimensiones para visualizar y analizar mejor los datos complejos (como estad√≠sticas por partido).

### üß† 3. **Modelos de Series de Tiempo**

Usados para **analizar datos secuenciales**, como resultados por fecha o evoluci√≥n de un jugador.

**Ejemplos:**

* Predecir la evoluci√≥n de un equipo en la tabla.
* Estimar el rendimiento f√≠sico de un atleta a lo largo del tiempo.

**Modelos comunes:**

* ARIMA
* LSTM (redes neuronales recurrentes)
* Prophet (de Facebook)
* Exponential Smoothing

### üß† 4. **Aprendizaje por Refuerzo (Reinforcement Learning)**

√ötil para **estrategia y toma de decisiones** en tiempo real o simulaciones.

**Ejemplos:**

* Optimizar t√°cticas de equipo (con simuladores).
* Decidir cambios de jugadores en tiempo real.
* Analizar trayectorias √≥ptimas en deportes como f√∫tbol, b√°squet, etc.

### ‚öΩ Aplicaciones Concretas en Deportes

| √Årea                     | Modelo t√≠pico                | Ejemplo pr√°ctico                                |
| ------------------------ | ---------------------------- | ----------------------------------------------- |
| Predicci√≥n de resultados | Clasificaci√≥n / regresi√≥n    | ¬øGanar√° el partido el equipo A?                 |
| Evaluaci√≥n de jugadores  | Clustering / PCA             | ¬øQu√© estilo de juego tiene este jugador?        |
| An√°lisis de desempe√±o    | Series de tiempo / regresi√≥n | ¬øC√≥mo evolucion√≥ el rendimiento este mes?       |
| Scouting / reclutamiento | Clasificaci√≥n                | ¬øEncajar√° un jugador en cierto perfil t√°ctico?  |
| Estrategia t√°ctica       | Aprendizaje por refuerzo     | ¬øCu√°l es la mejor jugada en una situaci√≥n dada? |

### Resumen

¬øSab√≠as que el *machine learning* permite mejorar significativamente el rendimiento deportivo de un equipo? En el caso del equipo Cebollitas, que perdi√≥ cuatro de sus √∫ltimos cinco partidos, la incorporaci√≥n de datos como estad√≠sticas de jugadores, registros de entrenamientos y videos de partidos podr√≠a marcar una diferencia importante. Descubramos juntos c√≥mo los modelos de machine learning pueden ser la clave para optimizar resultados deportivos.

#### ¬øQu√© modelos de machine learning son √∫tiles en el deporte?

El aprendizaje autom√°tico presenta diversas modalidades √∫tiles en contextos deportivos. A continuaci√≥n, repasamos las principales que podr√≠an aplicarse eficientemente al equipo Cebollitas:

#### ¬øQu√© son los modelos supervisados en machine learning?

Estos modelos aprenden mediante ejemplos espec√≠ficos, diferenciando escenarios positivos y negativos. Aplicado al f√∫tbol, podr√≠an analizar:

- Factores determinantes en los resultados de partidos espec√≠ficos.
- Variaciones que inciden en victorias o derrotas.
- Patrones recurrentes asociados con bajos rendimientos.

De esta forma, facilitan predecir resultados futuros basados en condiciones anteriores.

### ¬øC√≥mo funcionan los modelos no supervisados?

Por otra parte, los modelos no supervisados analizan datos sin valoraciones previas. Algunas aplicaciones pr√°cticas son:

- Identificar grupos de jugadores con h√°bitos de entrenamiento similares.
- Reconocer atletas que presentan mayor riesgo de lesiones.
- Descubrir comportamientos y tendencias internas de los jugadores.

Estos hallazgos permiten mejorar decisiones t√©cnicas y estrat√©gicas del equipo.

#### ¬øQu√© ventajas ofrecen los modelos de refuerzo?

Los modelos por refuerzo mejoran mediante prueba y error obteniendo recompensas. Esto es especialmente √∫til en:

- La simulaci√≥n de partidos para dise√±ar t√°cticas efectivas.
- Recomendaci√≥n de jugadas espec√≠ficas adaptadas al rival.
- Optimizaci√≥n de rutinas y entrenamientos para maximizar el rendimiento.

#### ¬øQu√© herramientas se utilizan com√∫nmente para aplicar machine learning en el deporte?

Existen diversas herramientas tecnol√≥gicas que facilitan la aplicaci√≥n del aprendizaje autom√°tico en la actividad f√≠sica y deportes, por ejemplo:

- Scikit learn, √∫til para algoritmos predictivos.
- TensorFlow y PyTorch, que se emplean tanto en an√°lisis predictivo como en aprendizaje por refuerzo.
- Python, lenguaje com√∫nmente empleado debido a su versatilidad e integraci√≥n con estas herramientas.

Estas tecnolog√≠as permiten aplicar directamente modelos al contexto particular del equipo y medir su impacto en rendimiento.

#### ¬øPor qu√© elegir correctamente un modelo de *machine learning* importa?

M√°s que conocer m√∫ltiples algoritmos de manera abstracta, lo realmente importante radica en saber elegir el modelo adecuado seg√∫n las necesidades espec√≠ficas del equipo. Implementando estas estrategias, Cebollitas podr√°:

- Analizar datos reales del equipo.
- Medir mejoras en tiempo real.
- Tomar decisiones basadas en evidencia estad√≠stica.

¬øTe gustar√≠a formar parte de este reto y convertirte en el pr√≥ximo analista de datos o ingeniero de machine learning para Cebollitas? ¬°Comparte tus ideas en comentarios y comencemos el partido!

**Lecturas recomendadas**

[scikit-learn: machine learning in Python ‚Äî scikit-learn 1.7.0 documentation](https://scikit-learn.org/stable/)

## Modelos supervisados de machine learning para an√°lisis deportivo

### üß† ¬øQu√© es un modelo supervisado?

Un modelo supervisado **aprende a partir de datos con etiquetas conocidas**, es decir, ejemplos donde se conoce el resultado (gan√≥/perdi√≥, rendimiento num√©rico, etc.).

üëâ Se divide en dos tipos principales:

* **Clasificaci√≥n** (salida categ√≥rica)
* **Regresi√≥n** (salida num√©rica continua)

### ‚öΩ Aplicaciones deportivas comunes

| Objetivo                                | Tipo de modelo supervisado |
| --------------------------------------- | -------------------------- |
| Predecir si un equipo ganar√°            | Clasificaci√≥n              |
| Clasificar lesiones como leves o graves | Clasificaci√≥n              |
| Estimar goles, puntos o asistencias     | Regresi√≥n                  |
| Predecir tiempo de recuperaci√≥n         | Regresi√≥n                  |
| Clasificar tipo de jugada (pase, tiro)  | Clasificaci√≥n              |

### üîç 1. **Modelos de Clasificaci√≥n**

### üìå ¬øCu√°ndo usar?

Cuando el resultado pertenece a **clases discretas**: ganar/perder, bajo/medio/alto, A/B/C...

### üìä Modelos comunes:

* **Regresi√≥n log√≠stica**: simple y eficaz para 2 clases.
* **K-Nearest Neighbors (KNN)**: asigna la clase m√°s frecuente entre vecinos cercanos.
* **√Årboles de decisi√≥n y Random Forest**: modelos interpretables y robustos.
* **Support Vector Machines (SVM)**: eficaz con datos complejos y pocas dimensiones.
* **Redes neuronales**: √∫tiles si tienes muchos datos y no linealidades complejas.

### üèü Ejemplo:

**¬øGanar√° el equipo A contra el B?**

Datos de entrada:

* posesi√≥n
* tiros a puerta
* faltas
* goles previos

Etiqueta:

* 1 = gan√≥, 0 = no gan√≥

### üìè 2. **Modelos de Regresi√≥n**

### üìå ¬øCu√°ndo usar?

Cuando el resultado es un **n√∫mero real**: goles, puntuaci√≥n, tiempo, distancia, etc.

### üìä Modelos comunes:

* **Regresi√≥n lineal**: para relaciones simples.
* **Ridge y Lasso**: versiones regularizadas.
* **√Årboles de regresi√≥n / Random Forest Regressor**
* **XGBoost**: potente y eficiente para predicci√≥n.
* **Redes neuronales**: si hay muchas variables o relaciones no lineales.

### üèü Ejemplo:

**¬øCu√°ntos goles marcar√° el equipo X en el pr√≥ximo partido?**

Datos de entrada:

* promedio de goles por partido
* defensa del rival
* condici√≥n de local o visitante

Etiqueta:

* N√∫mero de goles (0, 1, 2, ‚Ä¶)

### üß™ Mini ejemplo en Python

```python
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
import pandas as pd

# Datos simulados
data = pd.DataFrame({
    'posesi√≥n': [52, 47, 60, 55],
    'tiros': [8, 5, 11, 7],
    'local': [1, 0, 1, 0],
    'gana': [1, 0, 1, 0]  # etiqueta
})

X = data[['posesi√≥n', 'tiros', 'local']]
y = data['gana']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5)

clf = RandomForestClassifier()
clf.fit(X_train, y_train)

predicciones = clf.predict(X_test)
print("Precisi√≥n:", accuracy_score(y_test, predicciones))
```

### üß† ¬øC√≥mo elegir el mejor modelo?

Depende de:

* Tama√±o y calidad de los datos.
* Tipo de problema (clasificaci√≥n vs regresi√≥n).
* ¬øQuieres explicabilidad o solo precisi√≥n?
* ¬øNecesitas que funcione en tiempo real?

### Resumen

¬øTe imaginas poder anticiparte al resultado de un partido antes siquiera de jugarlo? Esta idea, m√°s cercana de lo que crees, es posible mediante los modelos supervisados de inteligencia artificial. Estos modelos analizan resultados pasados, como los del equipo Cebollitas, que ha perdido m√°s del 60% de sus partidos como visitante, para prever futuros resultados con sorprendente precisi√≥n. Pero, ¬øc√≥mo funcionan realmente estos modelos y cu√°l es su aplicaci√≥n concreta en el an√°lisis deportivo?

#### ¬øQu√© datos usan los modelos supervisados para predecir partidos?

Para realizar una predicci√≥n efectiva, estos modelos necesitan ejemplos claros de datos etiquetados. Espec√≠ficamente, se analizan detalles precisos de partidos disputados anteriormente, como:

- Cantidad de goles anotados.
- Posici√≥n y desempe√±o del equipo.
- N√∫mero de tiros o remates al arco.
- Precisi√≥n en los tiros, como los de Tara √Ålvarez.
- Pases completados, como los que realiza Carol McClain.

Con esta informaci√≥n valiosa, los modelos "aprenden" patrones consistentes que permiten anticipar con mayor exactitud futuros resultados deportivos.

##### ¬øCu√°les son los modelos supervisados m√°s utilizados?
#### ¬øQu√© es y c√≥mo funciona la regresi√≥n lineal?

La regresi√≥n lineal ofrece un c√°lculo simple, pero efectivo, para anticipar valores num√©ricos. Por ejemplo, si se conoce el n√∫mero de remates al arco del equipo, este m√©todo permitir√° estimar cu√°ntos goles marcar√°n con base en dichos datos, proporcionando una relaci√≥n gr√°fica f√°cil de interpretar.

#### ¬øQu√© diferencia hay con la regresi√≥n log√≠stica?

A diferencia de la lineal, la regresi√≥n log√≠stica no predice directamente cifras espec√≠ficas, sino una probabilidad. As√≠, podr√≠as saber que existe un 80% de probabilidad de ganar el pr√≥ximo partido. Aunque se denomina regresi√≥n, su papel real es realizar una clasificaci√≥n clara de posibilidades.

#### ¬øPor qu√© usar √°rboles de decisi√≥n?

¬øQuieres ver c√≥mo tomar decisiones al estilo de un director t√©cnico? El √°rbol de decisi√≥n opera dividiendo criterios claros para saber cu√°l es la siguiente mejor jugada. Por ejemplo, si tienes m√°s del 60% de posesi√≥n y m√°s de 10 disparos al arco, ir√°s directamente al ataque. Aun as√≠, es crucial ser cuidadoso, porque pueden memorizar en vez de generalizar.

#### ¬øQu√© ventajas aporta el random forest?

Para evitar la tendencia del √°rbol de decisi√≥n a memorizar, el random forest emplea m√∫ltiples √°rboles, donde cada uno vota por un resultado probable. Esto da como resultado m√°s robustez, mayor precisi√≥n y menor tasa de errores, haciendo este m√©todo muy confiable.

#### ¬øD√≥nde destacan las m√°quinas de soporte vectorial (SVM)?

Las SVM son herramientas excepcionales para trazar l√≠mites de clasificaci√≥n precisos en un conjunto de datos, diferenciando claramente partidos ganados y perdidos en relaci√≥n a caracter√≠sticas espec√≠ficas como tiros al arco o posesi√≥n del bal√≥n.

#### ¬øCu√°l es el rol de las redes neuronales?

Cuando los datos se vuelven especialmente complejos, entran en juego las redes neuronales. Estas t√©cnicas avanzadas encuentran combinaciones ocultas y patrones no lineales, ideales para detectar jugadas imperceptibles a simple vista, aunque requieren grandes cantidades de informaci√≥n y una alta potencia de computaci√≥n.

#### ¬øQu√© necesitan estos modelos para ofrecer buenos resultados?

La clave de un modelo supervisado exitoso radica en la calidad de sus datos etiquetados. Como analistas deportivos de alto nivel, nuestro trabajo consiste precisamente en proporcionar estos datos cuidadosamente seleccionados, fundamentales para que los modelos aprendan correctamente y puedan anticiparse a resultados precisos.

Ahora que conoces c√≥mo funcionan estos modelos supervisados, cu√©ntanos, ¬øcu√°l elegir√≠as para mejorar el rendimiento del equipo Cebollitas en su pr√≥ximo partido? ¬°Comparte tus comentarios!

**Lecturas recomendadas**

[1. Supervised learning ‚Äî scikit-learn 1.7.0 documentation](https://scikit-learn.org/stable/supervised_learning.html)

[1.1. Linear Models ‚Äî scikit-learn 1.7.0 documentation](https://scikit-learn.org/stable/modules/linear_model.html#ordinary-least-squares%20https://towardsdatascience.com/understanding-linear-regression-output-in-r-7a9cbda948b3/)

## Modelos no supervisados para an√°lisis futbol√≠stico

### üî∑ ¬øQu√© es un modelo no supervisado?

Es un tipo de algoritmo que **aprende de los datos sin conocer las respuestas correctas**. Su objetivo es:

* Agrupar observaciones similares.
* Reducir la complejidad de los datos.
* Encontrar patrones o estructuras internas.

### ‚öΩ Aplicaciones en an√°lisis futbol√≠stico

| Aplicaci√≥n                                    | T√©cnica recomendada                           |
| --------------------------------------------- | --------------------------------------------- |
| Agrupar jugadores por estilo de juego         | **Clustering (K-Means, DBSCAN)**              |
| Detectar formaciones t√°cticas autom√°ticamente | **Clustering o reducci√≥n de dimensi√≥n**       |
| Reducir variables redundantes en estad√≠sticas | **PCA (An√°lisis de Componentes Principales)** |
| An√°lisis de scouting (segmentar talento)      | **Clustering + an√°lisis de distancias**       |
| An√°lisis posicional basado en tracking de GPS | **Modelos de densidad, GMM**                  |
### üîπ 1. Clustering (Agrupamiento)

### ‚úî ¬øQu√© hace?

Agrupa jugadores, partidos o jugadas **similares** entre s√≠, sin que t√∫ definas los grupos previamente.

### üß† Algoritmos populares:

* **K-Means**: divide datos en K grupos definidos por distancia.
* **DBSCAN**: detecta grupos de puntos densos sin definir K.
* **Gaussian Mixture Models (GMM)**: agrupa por distribuciones probabil√≠sticas.

### ‚öΩ Ejemplo en f√∫tbol:

Agrupar jugadores seg√∫n estas estad√≠sticas:

* Pases completados
* Intercepciones
* Disparos al arco
* Minutos jugados

As√≠ puedes descubrir roles reales: creadores, defensores puros, atacantes m√≥viles, etc.

### üîπ 2. PCA (An√°lisis de Componentes Principales)

### ‚úî ¬øQu√© hace?

Reduce **dimensiones** de un conjunto de datos manteniendo la mayor parte de la **variabilidad**.

### ‚öΩ En f√∫tbol:

* Simplificar datos de rendimiento (decenas de m√©tricas por jugador).
* Visualizar en 2D o 3D las "similitudes" entre jugadores.
* Analizar tendencias generales del equipo.

### üîπ 3. Modelos de Detecci√≥n de Anomal√≠as

### ‚úî ¬øQu√© hace?

Detecta **comportamientos fuera de lo com√∫n** (anomal√≠as).

### ‚öΩ En f√∫tbol:

* Detectar partidos at√≠picos (para scouting o apuestas).
* Identificar lesiones o rendimientos inusuales.
* Se√±alar jugadas raras en el tracking del bal√≥n.

### üß† Algoritmos:

* Isolation Forest
* One-Class SVM

### üß™ Ejemplo: Clustering de jugadores con K-Means en Python

```python
import pandas as pd
from sklearn.cluster import KMeans
from sklearn.preprocessing import StandardScaler
import matplotlib.pyplot as plt

# Datos simulados: estad√≠sticas por jugador
data = pd.DataFrame({
    'pases': [55, 70, 65, 20, 30, 25],
    'disparos': [2, 1, 3, 5, 4, 6],
    'intercepciones': [3, 2, 4, 6, 7, 5]
})

# Normalizaci√≥n
scaler = StandardScaler()
data_scaled = scaler.fit_transform(data)

# Agrupar en 2 cl√∫steres
kmeans = KMeans(n_clusters=2, random_state=0)
labels = kmeans.fit_predict(data_scaled)

data['rol_estimado'] = labels
print(data)
```

### üß† Conclusi√≥n

| T√©cnica               | ¬øPara qu√© sirve?                                      |
| --------------------- | ----------------------------------------------------- |
| **K-Means, DBSCAN**   | Agrupar jugadores, jugadas o partidos                 |
| **PCA**               | Reducir dimensi√≥n y encontrar estructura en los datos |
| **Anomaly Detection** | Detectar eventos o desempe√±os fuera de lo com√∫n       |

### Resumen

El f√∫tbol actual va m√°s all√° de goles y asistencias. Cuando las estad√≠sticas b√°sicas no son suficientes para evaluar completamente a un jugador, recurrimos a los **modelos no supervisados**, t√©cnicas que permiten revelar patrones ocultos en el juego sin depender exclusivamente de etiquetas tradicionales.

#### ¬øQu√© es el clustering y c√≥mo ayuda a evaluar jugadores?

El *clustering* es una t√©cnica estad√≠stica que agrupa elementos que comparten caracter√≠sticas similares. En f√∫tbol, esto nos permite identificar jugadores que desempe√±an roles espec√≠ficos o tienen rendimientos parecidos sin necesidad de etiquetas previas como goles marcados o asistencias realizadas.

#### ¬øC√≥mo funciona el algoritmo K-means?

K-means es uno de los algoritmos m√°s populares del clustering. Funciona dividiendo los datos en "k" grupos, asegur√°ndose de que cada jugador est√© lo m√°s cercano posible al centro de su respectivo grupo. As√≠, logramos identificar roles espec√≠ficos como:

- Jugadores carrileros incansables.
- Motores de recuperaci√≥n.
- Delanteros fantasmas.

#### ¬øQu√© hacer cuando los datos no tienen formas claras de agrupaci√≥n?

No siempre los datos se organizan claramente. En estos casos, utilizamos algoritmos m√°s especializados como DBSCAN, que agrupa a los jugadores seg√∫n la densidad de los datos. Este m√©todo detecta grupos aunque no tengan formas geom√©tricas expl√≠citas, examinando c√≥mo est√°n distribuidos los datos en conjunto.

#### ¬øEn qu√© consiste el Clustering jer√°rquico y cu√°ndo usarlo?

El clustering jer√°rquico organiza los datos en una estructura en √°rbol, conocida como dendrograma. Este m√©todo es ideal cuando analizamos jugadas ofensivas o estilos de juego sin etiquetas definidas como goles, permitiendo observar c√≥mo jugadores o jugadas espec√≠ficas se agrupan en estructuras m√°s amplias de caracter√≠sticas similares.

#### ¬øC√≥mo visualizar la informaci√≥n cuando hay muchas variables?

En ocasiones, manejar una gran cantidad de variables es abrumador. Para estos escenarios, la reducci√≥n de dimensionalidad nos brinda herramientas pr√°cticas para resumir informaci√≥n destacada sin perder detalles relevantes.

#### ¬øQu√© es PCA (An√°lisis de Componentes Principales)?

PCA reduce la cantidad de variables creando nuevas dimensiones que capturan la mayor√≠a de la informaci√≥n original. Es similar a observar un partido desde un dron: perdemos algunos detalles espec√≠ficos, pero obtenemos una visi√≥n general del rendimiento y estilo de los jugadores.

#### ¬øHay otras opciones para visualizar datos complejos?

S√≠, t√©cnicas avanzadas como **t-SNE** o **UMAP** permiten representar datos complejos en gr√°ficos bidimensionales o tridimensionales, revelando patrones menos obvios y facilitando la interpretaci√≥n del desempe√±o futbol√≠stico.

#### ¬øC√≥mo evaluar la efectividad del clustering sin etiquetas?

Evaluar resultados sin etiquetas tradicionales como victorias o goles presenta desaf√≠os especiales. Usamos m√©tricas espec√≠ficas para confirmar la validez del agrupamiento:

- **Inercia**: mide qu√© tan compactos son los grupos.
- **Coeficiente de Silhouette**: eval√∫a qu√© tan bien separados est√°n los grupos entre s√≠.

Estas herramientas no ofrecen respuestas definitivas, pero son √∫tiles para verificar que las agrupaciones tengan sentido desde el punto de vista anal√≠tico.
 
**Lecturas recomendadas**

[2. Unsupervised learning ‚Äî scikit-learn 1.7.0 documentation](https://scikit-learn.org/stable/unsupervised_learning.html)

## Configuraci√≥n de Python y Jupyter para an√°lisis deportivo

### ‚öôÔ∏è 1. Instalar Python

### Opci√≥n recomendada: **Anaconda**

Anaconda incluye Python + Jupyter + librer√≠as para ciencia de datos.

üîó Descarga desde: [https://www.anaconda.com/download](https://www.anaconda.com/download)

### Alternativa: **Python + pip**

* Instala Python desde: [https://www.python.org/downloads](https://www.python.org/downloads/)
* Luego instala Jupyter y bibliotecas:

```bash
pip install jupyter numpy pandas matplotlib seaborn scikit-learn
```

### üìì 2. Abrir Jupyter Notebook

Una vez instalado:

```bash
jupyter notebook
```

Esto abrir√° tu navegador con un entorno interactivo donde puedes escribir c√≥digo, visualizar gr√°ficos y explorar datos.

### üì¶ 3. Bibliotecas esenciales para an√°lisis deportivo

| Biblioteca     | Uso principal                                 |
| -------------- | --------------------------------------------- |
| `pandas`       | Manipulaci√≥n de datos (CSV, Excel, JSON...)   |
| `numpy`        | C√°lculo num√©rico y √°lgebra lineal             |
| `matplotlib`   | Gr√°ficos b√°sicos (l√≠neas, barras, dispersi√≥n) |
| `seaborn`      | Gr√°ficos estad√≠sticos m√°s elegantes           |
| `scikit-learn` | Machine learning (modelos supervisados y no)  |
| `statsmodels`  | Modelado estad√≠stico y regresi√≥n              |
| `plotly`       | Gr√°ficos interactivos (opcional)              |
| `xgboost`      | Modelos predictivos potentes (opcional)       |

Instalaci√≥n:

```bash
pip install pandas numpy matplotlib seaborn scikit-learn statsmodels plotly xgboost
```

### üèüÔ∏è 4. Bibliotecas opcionales para deportes

* [`football-data`](https://pypi.org/project/football-data-api/): para acceder a APIs de f√∫tbol.
* [`fifa-api`](https://pypi.org/project/fut/): acceso a estad√≠sticas de FIFA.
* [`mplsoccer`](https://mplsoccer.readthedocs.io/): gr√°ficos avanzados tipo "pizza charts", radar y an√°lisis de f√∫tbol.

```bash
pip install mplsoccer
```

### üß™ 5. Ejemplo b√°sico de an√°lisis deportivo

```python
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# Cargar estad√≠sticas simuladas de jugadores
df = pd.DataFrame({
    'Jugador': ['A', 'B', 'C', 'D'],
    'Goles': [10, 5, 7, 2],
    'Asistencias': [3, 7, 2, 4],
    'Minutos': [900, 850, 1000, 700]
})

# Relaci√≥n goles-minutos
df['Goles por minuto'] = df['Goles'] / df['Minutos']

# Gr√°fico
sns.barplot(x='Jugador', y='Goles por minuto', data=df)
plt.title('Goles por minuto jugado')
plt.show()
```

### üß† Consejos adicionales

‚úÖ Organiza tus notebooks por proyectos: `datos/`, `modelos/`, `gr√°ficas/`

‚úÖ Usa `Google Colab` si no deseas instalar nada localmente.

‚úÖ Guarda tus datasets en CSV y c√°rgalos con `pandas.read_csv("archivo.csv")`.

‚úÖ Si usas datos de p√°ginas como [FBref.com](https://fbref.com/) o [Understat](https://understat.com/), puedes integrarlos f√°cilmente.

### Resumen

La frustraci√≥n en el f√∫tbol es com√∫n cuando los resultados no reflejan claramente el rendimiento del equipo. Esta situaci√≥n ocurre incluso cuando se tienen m√°s posesi√≥n y pases completados. Para solventar este inconveniente, utilizaremos Python y t√©cnicas de machine learning supervisado que nos permitir√°n analizar datos precisos y entender mejor lo que pasa dentro del campo.

#### ¬øPor qu√© usar Python para an√°lisis deportivo?

Python es ideal debido a que es simple, poderoso y cuenta con las herramientas adecuadas para el an√°lisis y procesamiento de datos deportivos. Para facilitar nuestro trabajo, usaremos Jupyter Notebook, que permite escribir c√≥digo, hacer justificaciones y visualizar gr√°ficos c√≥modamente en un mismo entorno.

#### ¬øC√≥mo preparar tu entorno para an√°lisis?

Es importante tener todo listo antes de comenzar a analizar resultados deportivos con datos. Para ello, generaremos un ambiente virtual completo instalando Python, Jupyter Notebook e incluir√° algunas librer√≠as esenciales.

- Instalar Python y Jupyter Notebook.
- Crear un archivo notebook con extensi√≥n punto IPYNB.
- Nombrar tu archivo notebook como ‚Äúcebollitas d√≠a uno‚Äù.

Este ambiente ser√° tu campo digital para entrenar modelos anal√≠ticos, probar nuevas ideas y evaluar resultados.

#### ¬øCu√°l ser√° tu primera l√≠nea de c√≥digo?

Tu introducci√≥n a Python inicia con algo sencillo, pero significativo, como escribir tu primera l√≠nea de c√≥digo. Puedes comenzar con un breve mensaje de bienvenida:

`print("Bienvenidos al Cebollita FC")`

Este sencillo ejercicio representa el pitazo inicial para futuras predicciones estad√≠sticas basadas en datos reales. A partir del pr√≥ximo entrenamiento, se comenzar√° a trabajar con informaci√≥n aut√©ntica del club, comprendiendo estad√≠sticas, desempe√±o y descubriendo patrones √∫tiles para anticipar resultados.

Este nuevo enfoque con *machine learning* y Python permitir√° que analizar el f√∫tbol sea mucho m√°s eficiente, brind√°ndote las herramientas necesarias para comprender mejor cada situaci√≥n del partido.

**Archivos de la clase**

[partidos-cebollitas.csv](https://static.platzi.com/media/public/uploads/partidos_cebollitas_fe82a1a4-e109-41b1-8b78-d9b4341dacaf.csv "partidos-cebollitas.csv")

## Limpieza de datos deportivos con Pandas en Python

### üßº ¬øQu√© es la limpieza de datos?

La limpieza de datos incluye:

1. Cargar datos correctamente.
2. Identificar y tratar **valores nulos**.
3. Corregir **tipos de datos**.
4. Eliminar **duplicados** o errores.
5. Renombrar columnas y estandarizar nombres.
6. Filtrar registros no v√°lidos o inconsistentes.
7. Crear columnas √∫tiles (goles por minuto, etc.).

### üèüÔ∏è Supongamos que tienes este dataset (CSV)

```csv
jugador, goles, minutos_jugados, equipo, fecha
Messi, 3, 90, Inter Miami, 2023-09-12
Mbappe, , 85, PSG, 2023-09-12
Messi, 3, 90, Inter Miami, 2023-09-12
Lewandowski, 1, 78, FC Barcelona, 2023-09-12
Falcao, 0, , Rayo Vallecano, 2023-09-12
```

### üêº Paso a paso con Pandas

```python
import pandas as pd

# Cargar el archivo CSV
df = pd.read_csv('estadisticas.csv')

# Mostrar las primeras filas
print(df.head())
```

### üîç 1. Verificar valores nulos

```python
print(df.isnull().sum())  # ¬øD√≥nde hay valores faltantes?
```

‚û°Ô∏è Soluci√≥n:

```python
df['goles'].fillna(0, inplace=True)  # Rellenar con 0
df['minutos_jugados'].fillna(df['minutos_jugados'].mean(), inplace=True)  # Promedio
```

### üìã 2. Eliminar duplicados

```python
df = df.drop_duplicates()
```

### üî¢ 3. Corregir tipos de datos

```python
df['goles'] = df['goles'].astype(int)
df['minutos_jugados'] = df['minutos_jugados'].astype(int)
df['fecha'] = pd.to_datetime(df['fecha'])
```

### ‚úèÔ∏è 4. Renombrar columnas (opcional)

```python
df.rename(columns={'minutos_jugados': 'min_jugados'}, inplace=True)
```

### ‚ûó 5. Crear columnas nuevas (ej. eficiencia)

```python
df['goles_por_minuto'] = df['goles'] / df['min_jugados']
```

### üßπ 6. Filtrar registros no v√°lidos

```python
df = df[df['min_jugados'] > 0]  # Eliminar jugadores sin minutos jugados
```

### üìä Resultado limpio

```python
print(df)
```

### üß† Consejos extra

| Tarea                        | Funci√≥n √∫til de Pandas                 |
| ---------------------------- | -------------------------------------- |
| Ver resumen general          | `df.info()`                            |
| Estad√≠sticas b√°sicas         | `df.describe()`                        |
| Ver valores √∫nicos por campo | `df['equipo'].unique()`                |
| Filtrar por condici√≥n        | `df[df['equipo'] == 'PSG']`            |
| Exportar CSV limpio          | `df.to_csv('limpio.csv', index=False)` |

### Resumen

Analizar y limpiar los datos es clave antes de utilizar modelos predictivos en deportes. Al usar Python con la librer√≠a pandas, es posible manipular f√°cilmente grandes vol√∫menes de informaci√≥n, pasando de conjuntos de datos confusos y desorganizados a informaci√≥n clara y √∫til que pueda ayudar a prever futuros resultados del club.

#### ¬øQu√© herramientas se necesitan para la limpieza de datos deportivos?

Usamos principalmente Python y la librer√≠a pandas. Dentro del entorno de desarrollo de Visual Studio Code, importamos y utilizamos:

- pandas (`pd`), una herramienta robusta para manipulaci√≥n y an√°lisis de datos.
- Notebooks en Python para facilitar el an√°lisis interactivo de cada etapa del proceso de limpieza.

#### ¬øC√≥mo cargar y visualizar inicialmente los datos deportivos?

Los datos se cargan mediante la funci√≥n `pd.read_csv()`, que permite acceder directamente al archivo CSV. La funci√≥n `head()` muestra las primeras filas de nuestros datos, proporcionando una vista r√°pida y fundamental del estado inicial del dataset. Esta visi√≥n previa es semejante a observar los primeros minutos de juego para seleccionar la estrategia adecuada.

#### ¬øCu√°les son los pasos fundamentales para preparar los datos?

La preparaci√≥n de datos requiere una serie de t√©cnicas espec√≠ficas en Python:

#### ¬øC√≥mo evaluar la calidad general de los datos del equipo?

La funci√≥n info() es clave para obtener una visi√≥n general de los datos:

- Identifica columnas disponibles.
- Detecta valores ausentes o errores.
- Indica tipos de datos presentes (integer, objetos, etc.).
- Presenta consumo de memoria, √∫til para futuras optimizaciones.

#### ¬øC√≥mo lidiar con datos faltantes en los registros deportivos?

Para los valores nulos, particularmente en columnas cr√≠ticas como los goles anotados, se utiliza:

- `isnull().sum()` para identificar faltantes.
- Se rellenan estos valores con el promedio en lugar de eliminarlos, manteniendo la integridad del dataset sin introducir registros falsos.

#### ¬øQu√© es el One-Hot Encoding y c√≥mo se aplica en equipos deportivos?

Se aplica a variables categ√≥ricas como los nombres de equipos usando:

- `pd.get_dummies()` transforma estas categor√≠as en columnas binarias de ceros y unos.
- Facilitando que los algoritmos comprendan y procesen estos datos num√©ricamente.

#### ¬øC√≥mo gestionar duplicados y evitar su impacto en los resultados?

Con la funci√≥n `duplicate()`, eliminamos registros id√©nticos que podr√≠an sesgar el entrenamiento de los modelos predictivos, asegurando aprendizaje claro y √∫nico en cada caso.

#### ¬øPor qu√© y c√≥mo se ajustan los formatos de fecha?

Las fechas inconsistentes o mal formateadas se ajustan usando `pd.to_datetime()`. Esta transformaci√≥n permite realizar an√°lisis temporales √∫tiles para detectar patrones como rachas positivas o negativas en ciertas √©pocas del a√±o.

#### ¬øC√≥mo evaluar finalmente el estado de nuestro dataset limpio?

Luego de completar estas tareas, se recomienda verificar nuevamente con `info()` y `head()` el estado final de los datos. Adem√°s, confirmar con funciones como `shape` el tama√±o y la estructura en filas y columnas.

- Confirmar caracter√≠sticas generales del dataset.
- Asegurar ausencia de nulos o duplicados.
- Validar columnas y registros disponibles.

Este m√©todo provee claridad total antes de avanzar a modelar resultados con t√©cnicas m√°s avanzadas.

¬øQu√© otras t√©cnicas recomiendas para preparar datos antes de predecir resultados en deportes? ¬°Comparte tu opini√≥n en los comentarios!

**Archivos de la clase**

[partidos-cebollitas.csv](https://static.platzi.com/media/public/uploads/partidos_cebollitas_9eada58c-fb57-4224-a3f5-6d9efc881c2e.csv "partidos-cebollitas.csv")

**Lecturas recomendadas**

[pandas - Python Data Analysis Library](https://pandas.pydata.org/ "pandas - Python Data Analysis Library")

[machine-learning/02_preparacion.ipynb at main ¬∑ platzi/machine-learning ¬∑ GitHub](https://github.com/platzi/machine-learning/blob/main/02_preparacion.ipynb "machine-learning/02_preparacion.ipynb at main ¬∑ platzi/machine-learning ¬∑ GitHub")

[machine-learning/02_preparacion.ipynb at main ¬∑ platzi/machine-learning ¬∑ GitHub](https://github.com/platzi/machine-learning/blob/main/02_preparacion.ipynb "machine-learning/02_preparacion.ipynb at main ¬∑ platzi/machine-learning ¬∑ GitHub")

## An√°lisis de rendimiento deportivo con estad√≠stica descriptiva

### ‚öΩ ¬øQu√© es la estad√≠stica descriptiva en deportes?

Es el **an√°lisis num√©rico y gr√°fico** que describe y resume un conjunto de datos deportivos sin hacer inferencias m√°s all√° de la muestra.

### üìä Ejemplos de variables analizadas

| Variable              | Tipo         | Ejemplo                         |
| --------------------- | ------------ | ------------------------------- |
| Goles                 | Cuantitativa | 0, 1, 2, 3‚Ä¶                     |
| Minutos jugados       | Cuantitativa | 90, 85, 75‚Ä¶                     |
| Posici√≥n en el campo  | Cualitativa  | Delantero, Defensa, Mediocampo‚Ä¶ |
| Resultado del partido | Cualitativa  | Victoria, Derrota, Empate       |

### üß™ Medidas comunes

### 1. **Tendencia central**

* **Media (promedio)**: Valor medio de rendimiento.
* **Mediana**: Valor central (√∫til con datos sesgados).
* **Moda**: Valor m√°s frecuente (por ejemplo, goles m√°s comunes).

### 2. **Dispersi√≥n**

* **Rango**: Diferencia entre el valor m√°s alto y el m√°s bajo.
* **Desviaci√≥n est√°ndar**: Qu√© tanto var√≠an los datos respecto a la media.
* **Varianza**: Medida cuadr√°tica de dispersi√≥n.

### 3. **Resumen estad√≠stico r√°pido**

En Python:

```python
df.describe()
```

### üß± Ejemplo pr√°ctico con Pandas (f√∫tbol)

```python
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt

# Dataset simulado
df = pd.DataFrame({
    'Jugador': ['A', 'B', 'C', 'D', 'E'],
    'Goles': [10, 5, 8, 0, 3],
    'Asistencias': [4, 7, 2, 0, 1],
    'Minutos': [900, 800, 950, 400, 600]
})

# Estad√≠sticas descriptivas
print(df.describe())

# Agregar columna de eficiencia
df['Goles por 90 min'] = df['Goles'] / df['Minutos'] * 90

# Gr√°fico: comparaci√≥n de goles
sns.barplot(x='Jugador', y='Goles', data=df)
plt.title('Goles por Jugador')
plt.show()

# Gr√°fico: eficiencia de gol
sns.barplot(x='Jugador', y='Goles por 90 min', data=df)
plt.title('Goles por 90 Minutos')
plt.show()
```

### üìà ¬øQu√© puedes hacer con estos an√°lisis?

| Aplicaci√≥n                        | Ejemplo concreto                           |
| --------------------------------- | ------------------------------------------ |
| Comparar jugadores                | ¬øQui√©n tiene mejor promedio de goles?      |
| Evaluar consistencia              | ¬øQui√©n es m√°s regular en su rendimiento?   |
| Visualizar rendimiento por equipo | Barras, cajas, dispersi√≥n, radar, etc.     |
| Detectar valores at√≠picos         | ¬øHay jugadores con estad√≠sticas inusuales? |

### üß† Conclusi√≥n

La estad√≠stica descriptiva permite:

* Evaluar el **nivel y consistencia de desempe√±o**.
* Facilita la **toma de decisiones deportivas** (alineaciones, fichajes).
* Es base para aplicar modelos predictivos posteriormente.

### Resumen

¬øTe has preguntado por qu√© algunos partidos se ganan con facilidad y otros se complican m√°s de lo normal? La respuesta puede encontrarse en los datos, espec√≠ficamente en c√≥mo se analizan utilizando m√©todos de estad√≠stica descriptiva y visualizaci√≥n gr√°fica. Antes de predecir los resultados futuros, es esencial comprender en detalle los resultados del pasado.

#### ¬øQu√© herramientas necesitamos para analizar los partidos?

Para entender qu√© est√° pasando en el campo, necesitamos algunas herramientas t√©cnicas fundamentales:

- **Pandas**: manipulaci√≥n y preparaci√≥n inicial de nuestros datos.
- **Matplotlib y Seaborn**: para crear visualizaciones intuitivas que faciliten la interpretaci√≥n de informaci√≥n compleja.

Estas herramientas nos permiten extraer informaci√≥n crucial, como promedio de goles, desviaciones est√°ndar, m√°ximo y m√≠nimo de goles marcados.

#### ¬øC√≥mo identificar tendencias y patrones clave?

Las siguientes preguntas nos gu√≠an en el an√°lisis del rendimiento:

#### ¬øEs mejor nuestro desempe√±o como local o como visitante?

Al observar los promedios encontramos algo inesperado: el equipo tiene en promedio **2.2 goles como local** y **2.6 goles como visitante**, indicando un rendimiento s√≥lido incluso fuera de casa. Esto sugiere que nuestro rendimiento no depende √∫nicamente del apoyo local.

#### ¬øQu√© revelan los histogramas sobre nuestros goles?

Los histogramas, realizados con Seaborn, muestran frecuencias reales:

- Localmente, solemos marcar regularmente 2 a 4 goles.
- De visitante, aunque hay partidos con cero goles, sorprendentemente tambi√©n hay varios encuentros en los cuales llegamos a 3 o 5 goles anotados.

Estos gr√°ficos clarifican si nuestro rendimiento es consistente o variable partido a partido.

#### ¬øC√≥mo detectar resultados inusuales con Boxplots?

Los boxplots destacan f√°cilmente valores extremos:

- Se√±alan claramente los partidos excepcionales, tales como goleadas o resultados adversos.
- Revelan que es frecuente hacer entre 1 y 4 goles cuando jugamos en casa, con picos ocasionales de 5 goles.

Aunque la mayor√≠a de resultados est√°n concentrados en un rango limitado, estos valores ayudan a entender nuestras capacidades en escenarios extraordinarios.

#### ¬øTener m√°s posesi√≥n siempre significa m√°s goles?

Probamos esta hip√≥tesis usando un gr√°fico de dispersi√≥n:

- A pesar de una posesi√≥n del 45%, la cantidad de goles anotados var√≠a considerablemente.
- Diversidad en resultados, desde partidos sin goles hasta encuentros con cinco goles, indica que la posesi√≥n sola no determina nuestro rendimiento goleador.

Esto establece una relaci√≥n compleja entre la posesi√≥n del bal√≥n y la efectividad goleadora del equipo.

#### ¬øQu√© revela el mapa de calor sobre correlaciones importantes?

Utilizamos un mapa de calor para detectar conexiones ocultas entre diferentes acciones durante el partido. La correlaci√≥n m√°s alta registrada entre variables, como goles locales y posesi√≥n, es relativamente baja (0.17), indicando que las relaciones entre estas m√©tricas no son extremadamente fuertes.

No obstante, aun siendo significativas, su influencia es moderada, lo cual es √∫til para modelar predicciones futuras.

¬øQu√© correlaciones crees que debemos priorizar al momento de entrenar nuestros futuros modelos predictivos? Danos tu opini√≥n en los comentarios sobre qu√© variables te parecen m√°s determinantes para el rendimiento del equipo.

**Archivos de la clase**

[partidos-cebollitas.csv](https://static.platzi.com/media/public/uploads/partidos_cebollitas_e88b84b1-059b-4559-b1b5-78838f9f7ccc.csv "partidos-cebollitas.csv")

**Lecturas recomendadas**

[Tutorials ‚Äî Matplotlib 3.10.3 documentation](https://matplotlib.org/stable/tutorials/index "Tutorials ‚Äî Matplotlib 3.10.3 documentation")

[User guide and tutorial ‚Äî seaborn 0.13.2 documentation](https://seaborn.pydata.org/tutorial "User guide and tutorial ‚Äî seaborn 0.13.2 documentation")

[machine-learning/03_exploracion_datos_cebollitas.ipynb at main ¬∑ platzi/machine-learning ¬∑ GitHub](https://github.com/platzi/machine-learning/blob/main/03_exploracion_datos_cebollitas.ipynb "machine-learning/03_exploracion_datos_cebollitas.ipynb at main ¬∑ platzi/machine-learning ¬∑ GitHub")

## Normalizaci√≥n y estandarizaci√≥n de datos para modelos predictivos

### üìè ¬øPor qu√© normalizar o estandarizar?

Porque:

* Muchas t√©cnicas de ML **son sensibles a la escala de los datos**.
* Si tus variables tienen **unidades distintas** (por ejemplo, ‚Äúgoles‚Äù y ‚Äúminutos‚Äù), una puede dominar a la otra si no las escalas.
* Mejora la **velocidad de entrenamiento** y la **precisi√≥n del modelo**.

### üîÑ Diferencia entre normalizaci√≥n y estandarizaci√≥n

| T√©cnica                       | Qu√© hace                                                                           | Rango t√≠pico       |
| ----------------------------- | ---------------------------------------------------------------------------------- | ------------------ |
| **Normalizaci√≥n** (Min-Max)   | Escala los datos a un **rango fijo**, normalmente entre **0 y 1**                  | \[0, 1] o \[-1, 1] |
| **Estandarizaci√≥n** (Z-score) | Convierte los datos a una distribuci√≥n con **media = 0 y desviaci√≥n est√°ndar = 1** | Media = 0, Std = 1 |

### ‚öΩ Ejemplo en an√°lisis deportivo

Sup√≥n que tienes:

| Jugador | Goles | Minutos | Pases Completos |
| ------- | ----- | ------- | --------------- |
| A       | 5     | 900     | 300             |
| B       | 2     | 750     | 250             |
| C       | 7     | 1100    | 500             |

üëâ Estos valores est√°n en **escalas diferentes** ‚Üí necesitas escalarlos.

### üß™ En Python con `sklearn`

### üîπ Normalizaci√≥n (Min-Max Scaling)

```python
from sklearn.preprocessing import MinMaxScaler
import pandas as pd

# Datos simulados
df = pd.DataFrame({
    'Goles': [5, 2, 7],
    'Minutos': [900, 750, 1100],
    'Pases': [300, 250, 500]
})

scaler = MinMaxScaler()
df_norm = pd.DataFrame(scaler.fit_transform(df), columns=df.columns)

print("Normalizados:\n", df_norm)
```

### üî∏ Estandarizaci√≥n (Z-score)

```python
from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()
df_std = pd.DataFrame(scaler.fit_transform(df), columns=df.columns)

print("Estandarizados:\n", df_std)
```

### üß† ¬øCu√°ndo usar cada uno?

| Si vas a usar...                   | Recomendaci√≥n                                        |
| ---------------------------------- | ---------------------------------------------------- |
| KNN, SVM, Redes Neuronales, PCA    | ‚úÖ Escala tus datos (normalizaci√≥n o estandarizaci√≥n) |
| √Årboles de decisi√≥n, Random Forest | ‚ùå No es obligatorio escalar                          |
| Visualizaci√≥n (radar, scatter...)  | ‚úÖ Normalizar para comparaci√≥n clara                  |

### üéØ Conclusi√≥n

* **Normalizar o estandarizar** mejora el rendimiento del modelo.
* Elige el m√©todo seg√∫n el algoritmo que uses.
* Usa `sklearn.preprocessing` para escalar f√°cilmente.

### Resumen

Para asegurar predicciones precisas en modelos de aprendizaje autom√°tico, es clave **nivelar la escala de las variables**. Cuando los datos presentan rangos muy diversos, las variables con n√∫meros mayores pueden afectar injustamente los resultados. Aqu√≠ aprenderemos c√≥mo corregir esto con dos t√©cnicas fundamentales: **Min-Max Scaling** para normalizaci√≥n y Standard Scaler para estandarizaci√≥n.

#### ¬øPor qu√© es necesario escalar los datos antes de entrenar modelos?

Los modelos de aprendizaje autom√°tico pueden confundirse cuando las variables manejan escalas muy distintas. Por ejemplo, una variable como tiros al arco (valores entre 0 y 15) podr√≠a parecerle menos relevante al modelo que la posesi√≥n (del 0 al 100), simplemente por tener n√∫meros m√°s peque√±os. Esto no es realista, ya que ambas podr√≠an tener igual importancia.

#### ¬øQu√© ocurre al no escalar correctamente?

Cuando usamos datos sin escalar:

- El modelo asigna incorrectamente mayor importancia a magnitudes mayores.
- Se generan sesgos en las predicciones.
- Puede afectar negativamente la precisi√≥n del modelo.

Al escalar los datos, logramos una medida justa que permite al modelo aprender con mayor precisi√≥n.

#### ¬øQu√© diferencia hay entre Min-Max Scaling y Standard Scaler?

Existen dos m√©todos claves para escalar tus datos, cada uno ideal para ciertas circunstancias:

#### ¬øCu√°ndo usar Min-Max Scaling?

El Min-Max Scaling es ideal cuando tus datos no siguen una distribuci√≥n normal. Este m√©todo transforma cualquier valor num√©rico a un rango cerrado entre 0 y 1. Por ejemplo, si un futbolista tiene 12 tiros al arco y el m√°ximo registrado es 15, al aplicar Min-Max Scaling obtendremos:

- Resultado escalado: 12/15 = 0,8.

Este proceso se realiza usando la herramienta MinMaxScaler de las bibliotecas de procesamiento de datos.

#### ¬øEn qu√© casos se aplica Standard Scaler?

El Standard Scaler, por otro lado, es m√°s apropiado cuando deseas preservar la distribuci√≥n original de los datos. Este m√©todo centra la informaci√≥n alrededor de cero, con desviaci√≥n est√°ndar de uno. Es especialmente √∫til con algoritmos que necesitan datos centrados como regresi√≥n lineal o PCA. Los resultados obtenidos tendr√°n una distribuci√≥n estandarizada, eliminando cualquier sesgo por magnitud original.

#### ¬øC√≥mo aplicar estas t√©cnicas paso a paso?

Veamos brevemente c√≥mo aplicar ambos m√©todos utilizando herramientas comunes en Python como pandas para datos y las clases MinMaxScaler y StandardScaler para escalar.

#### Aplicando Min-Max Scaling a tus datos

- Primero, crea una instancia de MinMaxScaler.
- Utiliza la funci√≥n fit_transform para calcular el m√≠nimo y m√°ximo de cada columna y aplicar la escala a la vez.
- Guarda estos datos normalizados en columnas nuevas:

```python
from sklearn.preprocessing import MinMaxScaler
scaler_norm = MinMaxScaler()
datos_normalizados = scaler_norm.fit_transform(datos[['tiros_al_arco_local', 'tiros_al_arco_visitante']])
datos[['tiros_al_arco_local_norm', 'tiros_al_arco_visitante_norm']] = datos_normalizados
```

#### Aplicando Standard Scaler correctamente

Para estandarizar:

- Genera una instancia de StandardScaler.
- Nuevamente, usa fit_transform para calcular media y desviaci√≥n est√°ndar y aplicar la transformaci√≥n.
- Guarda los resultados en nuevas columnas:

```python
from sklearn.preprocessing import StandardScaler
scaler_std = StandardScaler()
datos_estandarizados = scaler_std.fit_transform(datos[['posesion_local', 'posesion_visitante']])
datos[['posesion_local_std', 'posesion_visitante_std']] = datos_estandarizados
```

#### ¬øC√≥mo saber si el escalado fue exitoso?

Para visualizar si tu escalado fue exitoso y efectivo, usa histogramas, una visualizaci√≥n que revisa c√≥mo se distribuyen tus datos escalados. Para ello, emplea bibliotecas como Matplotlib o Seaborn:

```python
import matplotlib.pyplot as plt 
import seaborn as sns

fig, axes = plt.subplots(1, 2)
sns.histplot(datos['tiros_al_arco_local_norm'], ax=axes[0])
axes[0].set_title('Tiros al Arco Local Normalizados')

sns.histplot(datos['posesion_local_std'], ax=axes[1], color='orange')
axes[1].set_title('Posesi√≥n Local Estandarizada')

plt.show()
```

Dichas gr√°ficas mostrar√°n claramente si los datos tienen una distribuci√≥n adecuada y equilibrada. Cu√©ntanos, ¬øqu√© inferencias puedes sacar de tu visualizaci√≥n?

**Lecturas recomendadas**

[7.3. Preprocessing data ‚Äî scikit-learn 1.7.0 documentation](https://scikit-learn.org/stable/modules/preprocessing "7.3. Preprocessing data ‚Äî scikit-learn 1.7.0 documentation")

[Importance of Feature Scaling ‚Äî scikit-learn 1.7.0 documentation](https://scikit-learn.org/stable/auto_examples/preprocessing/plot_scaling_importance "Importance of Feature Scaling ‚Äî scikit-learn 1.7.0 documentation")

[machine-learning/04_escalado_datos_cebollitas.ipynb at main ¬∑ platzi/machine-learning ¬∑ GitHub](https://github.com/platzi/machine-learning/blob/main/04_escalado_datos_cebollitas.ipynb "machine-learning/04_escalado_datos_cebollitas.ipynb at main ¬∑ platzi/machine-learning ¬∑ GitHub")

## Ingenier√≠a de caracter√≠sticas para mejorar modelos de machine learning

### üß† ¬øQu√© es la ingenier√≠a de caracter√≠sticas?

Es el proceso de:

1. **Crear nuevas variables** a partir de datos existentes.
2. **Seleccionar las m√°s relevantes.**
3. **Transformar o escalar datos** para que los modelos aprendan mejor.
4. **Codificar datos categ√≥ricos.**

### ‚öΩ Ejemplo en datos deportivos

Sup√≥n que tienes este conjunto de datos:

| Jugador     | Goles | Minutos | Pases Completos |
| ----------- | ----- | ------- | --------------- |
| Messi       | 3     | 90      | 70              |
| Lewandowski | 1     | 60      | 35              |

### üîß Podemos crear nuevas caracter√≠sticas como:

| Nueva variable            | F√≥rmula                           | Significado                             |
| ------------------------- | --------------------------------- | --------------------------------------- |
| Goles por minuto          | `Goles / Minutos`                 | Eficiencia goleadora                    |
| Pases por minuto          | `Pases / Minutos`                 | Participaci√≥n en juego                  |
| Participaci√≥n total       | `Goles + Asistencias`             | Impacto ofensivo                        |
| Pases acertados (%)       | `Pases / Pases intentados * 100`  | Precisi√≥n de pase (si se tiene el dato) |
| Diferencia de rendimiento | `Goles por minuto - media global` | Comparaci√≥n con otros                   |

### üß™ Ejemplo en Python

```python
import pandas as pd

# Datos b√°sicos
df = pd.DataFrame({
    'Jugador': ['Messi', 'Lewandowski'],
    'Goles': [3, 1],
    'Minutos': [90, 60],
    'Pases': [70, 35]
})

# Ingenier√≠a de caracter√≠sticas
df['Goles_por_minuto'] = df['Goles'] / df['Minutos']
df['Pases_por_minuto'] = df['Pases'] / df['Minutos']

print(df)
```

### üß† T√©cnicas comunes de ingenier√≠a de caracter√≠sticas

### üìå 1. **Escalado**

* Usar `MinMaxScaler` o `StandardScaler` para igualar escalas.

### üìå 2. **Codificaci√≥n de variables categ√≥ricas**

* `OneHotEncoder`, `LabelEncoder` para posiciones, equipos, etc.

### üìå 3. **Extracci√≥n de tiempo**

* Separar "fecha del partido" en "d√≠a de la semana", "mes", "temporada".

### üìå 4. **Cruces de variables**

* Multiplicar o dividir variables para encontrar relaciones (por ejemplo: **posesi√≥n √ó tiros al arco**).

### üìå 5. **Transformaciones estad√≠sticas**

* Logaritmo, ra√≠z cuadrada, z-score‚Ä¶ para normalizar distribuciones.

### üìà Beneficios

‚úÖ Mejora el rendimiento del modelo.
‚úÖ Permite modelos m√°s simples con mejores resultados.
‚úÖ Reduce la necesidad de redes neuronales profundas en problemas sencillos.
‚úÖ Mejora la **interpretabilidad** de los modelos.

### üß† Consejo clave

> "Un modelo simple con buenas caracter√≠sticas supera a un modelo complejo con malas caracter√≠sticas."

### Resumen

La ingenier√≠a de caracter√≠sticas, tambi√©n conocida como *feature engineering*, es una herramienta fundamental en el √°mbito del *machine learning*. Su objetivo principal consiste en crear nuevas variables a partir de datos ya existentes. Esto permite a los modelos identificar patrones m√°s profundos y √∫tiles, mejorando as√≠ notablemente su desempe√±o predictivo.

#### ¬øPor qu√© es valiosa la ingenier√≠a de caracter√≠sticas?

Esta t√©cnica transforma datos simples en informaci√≥n m√°s relevante para los modelos. Sabemos que los algoritmos no son capaces de detectar relaciones ocultas autom√°ticamente; sin embargo, un analista puede crear variables estrat√©gicas que aporten nuevo contexto al algoritmo:

- **Diferencia de goles**: goles del equipo local menos goles del visitante, √∫til para predecir si un equipo gan√≥, perdi√≥ o empat√≥.
- **Ratio de tiros sobre posesi√≥n**: relaciona los disparos realizados con la posesi√≥n durante el juego, midiendo eficiencia ofensiva.

Ambas variables aportan informaci√≥n valiosa que no est√° expl√≠citamente escrita en los datos originales.

#### ¬øQu√© pasos seguir para crear nuevas variables?

El proceso para implementar estas nuevas variables se desglosa en los siguientes bloques pr√°cticos:

#### Bloque n√∫mero uno: importar datos

Aqu√≠ es clave importar las bibliotecas necesarias, principalmente pandas, para tener acceso organizado y eficiente a los datos completos.

#### Bloque n√∫mero dos: calcular diferencia de goles

Esta nueva columna se crea restando los goles del equipo visitante a los del local, ayud√°ndonos a entender r√°pidamente el desempe√±o de los equipos.

#### Bloque n√∫mero tres: evaluar la eficiencia ofensiva

Se crea un ratio dividiendo los tiros al arco local sobre la posesi√≥n del equipo local. Este √≠ndice mide directamente la capacidad de aprovechar la posesi√≥n del bal√≥n para generar tiros al arco.

#### Bloque n√∫mero cuatro: visualizar con histogramas

Visualizar los datos es crucial. Aqu√≠ se recomienda utilizar hist plot de seaborne para observar la distribuci√≥n de la diferencia de goles:

- Importar bibliotecas (seaborne y matplotlib).
- Usar hist plot evaluando gr√°fica y visualmente la distribuci√≥n.

Esto permite una interpretaci√≥n r√°pida sobre c√≥mo se comporta esta nueva variable: ¬øel equipo tiende m√°s a empatar, perder o ganar?

#### Bloque n√∫mero cinco: establecer correlaciones

Finalmente, se utiliza un mapa de calor (heat map) para evaluar la correlaci√≥n entre variables originales y aquellas recientemente creadas. Esto es determinante para comprobar la utilidad real de estas caracter√≠sticas a√±adidas.

Por ejemplo, una fuerte correlaci√≥n encontrada en el an√°lisis fue entre goles locales y la diferencia de goles, indicando una relaci√≥n s√≥lida que puede mejorar los modelos predictivos.

¬øY t√∫ qu√© opinas de estas nuevas variables? ¬øEn qu√© situaciones crees que podr√≠an aportarte un mayor valor predictivo? Cu√©ntanos tu experiencia en los comentarios.

**Lecturas recomendadas**

[User Guide ‚Äî pandas 2.3.0 documentation](https://pandas.pydata.org/pandas-docs/stable/user_guide/index.html)

[machine-learning/05_ingenieria_caracteristicas_cebollitas.ipynb at main ¬∑ platzi/machine-learning ¬∑ GitHub](https://github.com/platzi/machine-learning/blob/main/05_ingenieria_caracteristicas_cebollitas.ipynb "machine-learning/05_ingenieria_caracteristicas_cebollitas.ipynb at main ¬∑ platzi/machine-learning ¬∑ GitHub")

## Selecci√≥n de variables relevantes para modelos predictivos

La **selecci√≥n de variables relevantes** (tambi√©n llamada **feature selection**) es una etapa crucial en machine learning porque:

* Mejora la **precisi√≥n** del modelo.
* Reduce el **overfitting**.
* Aumenta la **velocidad de entrenamiento**.
* Facilita la **interpretabilidad** del modelo.

### üß† ¬øQu√© es la selecci√≥n de variables?

Es el proceso de **elegir solo las caracter√≠sticas m√°s √∫tiles** para predecir una variable objetivo y **descartar las irrelevantes o redundantes**.

### ‚öΩ Ejemplo en an√°lisis deportivo

Imagina que tienes estas variables para predecir si un equipo ganar√°:

* Posesi√≥n del bal√≥n
* N√∫mero de tiros
* Goles recibidos
* Minutos jugados
* D√≠a de la semana
* Nombre del equipo rival

üëâ Algunas de estas **no ayudan** al modelo o incluso lo **confunden**. El objetivo es quedarte solo con las m√°s relevantes, como posesi√≥n y tiros.


### üîç T√©cnicas para seleccionar variables

### 1. **An√°lisis de correlaci√≥n**

Ideal para variables num√©ricas.

```python
import seaborn as sns
import matplotlib.pyplot as plt

# Matriz de correlaci√≥n
sns.heatmap(df.corr(), annot=True, cmap='coolwarm')
plt.title("Correlaci√≥n entre variables")
plt.show()
```

> Elimina variables muy correlacionadas entre s√≠ (multicolinealidad) o no relacionadas con la variable objetivo.

### 2. **M√©todo de importancia de caracter√≠sticas (feature importance)**

Usado con modelos como Random Forest, XGBoost o √°rboles de decisi√≥n.

```python
from sklearn.ensemble import RandomForestClassifier

model = RandomForestClassifier()
model.fit(X, y)

importancia = pd.Series(model.feature_importances_, index=X.columns)
importancia.sort_values(ascending=False).plot(kind='bar')
```

### 3. **Selecci√≥n autom√°tica (`SelectKBest`)**

```python
from sklearn.feature_selection import SelectKBest, f_classif

selector = SelectKBest(score_func=f_classif, k=5)  # Top 5 variables
X_new = selector.fit_transform(X, y)
```

### 4. **Eliminaci√≥n recursiva (`RFE`)**

```python
from sklearn.feature_selection import RFE
from sklearn.linear_model import LogisticRegression

modelo = LogisticRegression()
rfe = RFE(modelo, n_features_to_select=3)
fit = rfe.fit(X, y)

# Ver qu√© variables fueron seleccionadas
print(X.columns[fit.support_])
```

### ‚úÖ Buenas pr√°cticas

| Pr√°ctica                                  | Descripci√≥n                                                                                                         |
| ----------------------------------------- | ------------------------------------------------------------------------------------------------------------------- |
| Establece una **variable objetivo** clara | Ej: `gan√≥ = 1, no gan√≥ = 0`                                                                                         |
| Escala los datos si es necesario          | Mejora precisi√≥n en modelos sensibles a magnitudes                                                                  |
| Usa t√©cnicas combinadas                   | Correlaci√≥n + RFE, o Feature Importance + PCA                                                                       |
| Evita **leakage**                         | No incluyas variables que solo se conocen despu√©s del evento (ej. goles anotados si est√°s prediciendo el resultado) |

### üß† Conclusi√≥n

La selecci√≥n de variables:

* **Hace tus modelos m√°s precisos y r√°pidos**.
* Evita usar datos que **no aportan valor**.
* Es esencial en datasets deportivos con muchas estad√≠sticas por partido o jugador.

### Resumen

Optimizar modelos predictivos no siempre implica utilizar m√°s variables, sino seleccionar correctamente aquellas que realmente aportan valor a tu an√°lisis. Este m√©todo, conocido como selecci√≥n de caracter√≠sticas, ayuda a reducir ruido, simplificar modelos y prevenir sobreajustes, resultando en predicciones m√°s acertadas.

#### ¬øQu√© es la selecci√≥n de caracter√≠sticas en modelado predictivo?

La selecci√≥n de caracter√≠sticas consiste en identificar y retener √∫nicamente aquellas variables que presenten mayor relevancia estad√≠stica con el objetivo a predecir. Al aplicar esta pr√°ctica:

- Se simplifica el modelo, haciendo su interpretaci√≥n m√°s sencilla.
- Se eliminan variables irrelevantes que act√∫an como ruido.
- Mejora la capacidad de generalizaci√≥n y precisi√≥n del modelo.

#### ¬øC√≥mo realizar una selecci√≥n univariada con SelectKBest?

Utilizando herramientas del paquete *scikit-learn*, puedes aplicar SelectKBest para seleccionar aquellas variables con mejor rendimiento individual:

- Importa `SelectKBest` y `f_regression`.
- Usa `f_regression` para calcular la puntuaci√≥n F, evaluando qu√© tanto influye cada variable en tu objetivo.
- Define tu matriz de caracter√≠sticas X y tu vector objetivo Y.
- Selecciona las variables con mejores puntajes individuales y visualiza en orden decreciente cuales aportan m√°s:

```python
from sklearn.feature_selection import SelectKBest, f_regression
selector = SelectKBest(score_func=f_regression, k=2)
selector.fit(X, y)
```

#### ¬øPor qu√© utilizar √°rboles de decisi√≥n para evaluar importancia de variables?

Los √°rboles de decisi√≥n te permiten evaluar no solo correlaciones lineales, sino tambi√©n posibles interacciones o relaciones no lineales. Siguiendo estos pasos puedes beneficiarte de esta t√©cnica:

- Importa `DecisionTreeRegressor`.
- Instancia el modelo, define una semilla (`random_state`) para resultados reproducibles.
- Ajusta el modelo usando tus datos X e Y.
- Eval√∫a la importancia relativa de cada variable mediante la reducci√≥n total del error:

```python
from sklearn.tree import DecisionTreeRegressor
modelo_arbol = DecisionTreeRegressor(random_state=0)
modelo_arbol.fit(X, y)
```

#### ¬øQu√© aporta la visualizaci√≥n comparativa de t√©cnicas?

Una comparaci√≥n visual, mediante gr√°ficas de barras con seaborn y matplotlib, aclara la diferencia en aportaciones que cada variable tiene seg√∫n distintos m√©todos utilizados. Esto te permite validar conclusiones r√°pidamente y detectar variables consistentemente relevantes:

- Las t√©cnicas utilizadas fueron claramente comparadas:
- SelectKBest analiza correlaciones lineales.
- DecisionTreeRegressor eval√∫a relaciones complejas, incluyendo no lineales.

Aunque ambas t√©cnicas generaron valores espec√≠ficos diferentes, hubo coherencia en variables destacadas como posesi√≥n local y ratio tiros sobre posesi√≥n.

#### ¬øRealmente se necesitan todas las variables?

Este ejercicio pr√°ctico evidenci√≥ que menos variables pueden conseguir resultados equivalentes o superiores cuando est√°n correctamente elegidas:

- **Ratio de tiros sobre posesi√≥n**.
- **Porcentaje de posesi√≥n local**.

Estas variables han demostrado ser cruciales en la predicci√≥n eficaz de partidos.

**Lecturas recomendadas**

[1.13. Feature selection ‚Äî scikit-learn 1.7.0 documentation](https://scikit-learn.org/stable/modules/feature_selection.html "1.13. Feature selection ‚Äî scikit-learn 1.7.0 documentation")

[machine-learning/06_seleccion_caracteristicas_cebollitas.ipynb at main ¬∑ platzi/machine-learning ¬∑ GitHub](https://github.com/platzi/machine-learning/blob/main/06_seleccion_caracteristicas_cebollitas.ipynb "machine-learning/06_seleccion_caracteristicas_cebollitas.ipynb at main ¬∑ platzi/machine-learning ¬∑ GitHub")

[How to Choose a Feature Selection Method For Machine Learning](https://machinelearningmastery.com/feature-selection-with-real-and-categorical-data/ "How to Choose a Feature Selection Method For Machine Learning")