{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ai-platform.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ttYpeKKMYcxc"
      },
      "source": [
        "# Create a Python3 Notebook"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sBVypAhW9-GZ"
      },
      "source": [
        "import os\n",
        "os.mkdir(\"deploy\")\n",
        "os.mkdir(\"deploy/model\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tb-Em7uEAUKr"
      },
      "source": [
        "# Subir archivos de configuraciÃ³n\n",
        "!gsutil cp gs://curso-platzi-cv/fine_tuned_model.zip deploy/model/fine_tuned_model.zip\n",
        "!gsutil -m cp gs://curso-platzi-cv/label_map.pbtxt deploy/model/label_map.pbtxt\n",
        "\n",
        "!gsutil -m cp gs://curso-platzi-cv/dist/centroidtracker.py deploy/centroidtracker.py\n",
        "!gsutil -m cp gs://curso-platzi-cv/dist/trackableobject.py deploy/trackableobject.py"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g8KdSev5AaxZ"
      },
      "source": [
        "# Descomprimimos \n",
        "import zipfile\n",
        "\n",
        "local_zip = \"deploy/model/fine_tuned_model.zip\"\n",
        "zip_ref = zipfile.ZipFile(local_zip, \"r\")\n",
        "zip_ref.extractall(\"deploy/model/fine_tuned_model\")\n",
        "zip_ref.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xNx5BcjO74Jb"
      },
      "source": [
        "# Ignorar\n",
        "@app.route('/', methods = ['POST'])\n",
        "def parse_request():\n",
        "    video64 = requests.args.get(\"video64\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    app.run(debug = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kLbZD9K2AfnL"
      },
      "source": [
        "%%writefile deploy/app.py\n",
        "\n",
        "from flask import Flask, request, jsonify\n",
        "from prediction import smartcities\n",
        "\n",
        "app = Flask(__name__)\n",
        "\n",
        "@app.route('/', methods = ['POST'])\n",
        "def parse_request():\n",
        "    request_data = request.get_json()\n",
        "    videoBase64 = request_data['video']\n",
        "    sc = smartcities()\n",
        "    response_64 = sc.predict(videoBase64)\n",
        "    return jsonify(output=response_64)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    app.run(debug=True, host='0.0.0.0', port= 8000)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g7fa6SEhAimX"
      },
      "source": [
        "%%writefile deploy/prediction.py\n",
        "\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import imutils\n",
        "import time\n",
        "import dlib\n",
        "import cv2\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "from imutils.video import VideoStream\n",
        "from imutils.video import FPS\n",
        "from centroidtracker import CentroidTracker\n",
        "from trackableobject import TrackableObject\n",
        "import base64\n",
        "\n",
        "class smartcities:\n",
        "    def __init__(self):\n",
        "        detect_fn = tf.saved_model.load(\"model/fine_tuned_model/saved_model\")\n",
        "        self.detect_fn = detect_fn\n",
        "    \n",
        "    def predict(self, image_64_decode):\n",
        "        \n",
        "        PATH_VIDEO = \"/tmp/video_in.mp4\"\n",
        "        video_result = open(PATH_VIDEO, \"wb\")\n",
        "        video_result.write(base64.b64decode(image_64_decode))\n",
        "        \n",
        "        \n",
        "\n",
        "        PATH_OUTPUT = \"/tmp/output.mp4\"\n",
        "\n",
        "        SKIP_FPS = 30\n",
        "        TRESHOLD = 0.5\n",
        "\n",
        "        vs = cv2.VideoCapture(PATH_VIDEO)\n",
        "\n",
        "        writer = None\n",
        "\n",
        "        W = int(vs.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "        H = int(vs.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "\n",
        "        ct = CentroidTracker(maxDisappeared= 40, maxDistance = 50)\n",
        "\n",
        "        trackers = []\n",
        "        trackableObjects = {}\n",
        "\n",
        "        totalFrame = 0\n",
        "        totalDown = 0\n",
        "        totalUp = 0\n",
        "\n",
        "        DIRECTION_PEOPLE = True\n",
        "\n",
        "        POINT = [0, int((H/2)-H*0.1), W, int(H*0.1)]\n",
        "\n",
        "        fps = FPS().start()\n",
        "\n",
        "        fourcc = cv2.VideoWriter_fourcc(*'MP4V')\n",
        "        writer = cv2.VideoWriter(PATH_OUTPUT, fourcc, 20.0, (W, H), True)\n",
        "\n",
        "        while True:\n",
        "            ret, frame = vs.read()\n",
        "\n",
        "            if frame is None:\n",
        "                break\n",
        "\n",
        "            status = \"Waiting\"\n",
        "            rects = []\n",
        "\n",
        "\n",
        "            if totalFrame % SKIP_FPS == 0:\n",
        "                status = \"Detecting\"\n",
        "                trackers = []\n",
        "\n",
        "                image_np = np.array(frame)\n",
        "\n",
        "                input_tensor = tf.convert_to_tensor(image_np)\n",
        "                input_tensor = input_tensor[tf.newaxis, ...]\n",
        "\n",
        "                detections = self.detect_fn(input_tensor)\n",
        "\n",
        "                detection_scores = np.array(detections[\"detection_scores\"][0])\n",
        "\n",
        "                detection_clean = [x for x in detection_scores if x >= TRESHOLD]\n",
        "\n",
        "                for x in range(len(detection_clean)):\n",
        "                    idx = int(detections['detection_classes'][0][x])\n",
        "\n",
        "                    ymin, xmin, ymax, xmax = np.array(detections['detection_boxes'][0][x])\n",
        "                    box = [xmin, ymin, xmax, ymax] * np.array([W,H, W, H])\n",
        "\n",
        "                    (startX, startY, endX, endY) = box.astype(\"int\")\n",
        "                    tracker = dlib.correlation_tracker()\n",
        "                    rect = dlib.rectangle(startX, startY, endX, endY)\n",
        "                    tracker.start_track(frame, rect)\n",
        "\n",
        "                    trackers.append(tracker)\n",
        "            else:\n",
        "                for tracker in trackers:\n",
        "\n",
        "                    status = \"Tracking\"\n",
        "\n",
        "                    tracker.update(frame)\n",
        "                    pos = tracker.get_position()\n",
        "\n",
        "                    startX = int(pos.left())\n",
        "                    startY = int(pos.top())\n",
        "                    endX = int(pos.right())\n",
        "                    endY = int(pos.bottom())\n",
        "\n",
        "                    rects.append((startX, startY, endX, endY))\n",
        "\n",
        "            cv2.rectangle(frame, (POINT[0], POINT[1]), (POINT[0]+ POINT[2], POINT[1] + POINT[3]), (255, 0, 255), 2)\n",
        "\n",
        "            objects = ct.update(rects)\n",
        "\n",
        "            for (objectID, centroid) in objects.items():\n",
        "                to = trackableObjects.get(objectID, None)\n",
        "                if to is None:\n",
        "                    to = TrackableObject(objectID, centroid)\n",
        "\n",
        "                else:\n",
        "                    y = [c[1] for c in to.centroids]\n",
        "                    direction = centroid[1] - np.mean(y)\n",
        "                    to.centroids.append(centroid)\n",
        "\n",
        "                    if not to.counted:\n",
        "                        if centroid[0] > POINT[0] and centroid[0] < (POINT[0]+ POINT[2]) and centroid[1] > POINT[1] and centroid[1] < (POINT[1]+POINT[3]):\n",
        "                            if DIRECTION_PEOPLE:\n",
        "                                if direction >0:\n",
        "                                    totalUp += 1\n",
        "                                    to.counted = True\n",
        "                                else:\n",
        "                                    totalDown +=1\n",
        "                                    to.counted = True\n",
        "                            else:\n",
        "                                if direction <0:\n",
        "                                    totalUp += 1\n",
        "                                    to.counted = True\n",
        "                                else:\n",
        "                                    totalDown +=1\n",
        "                                    to.counted = True\n",
        "\n",
        "                trackableObjects[objectID] = to\n",
        "\n",
        "                text = \"ID {}\".format(objectID)\n",
        "                cv2.putText(frame, text, (centroid[0]-10, centroid[1]-10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0,255,0), 2)\n",
        "                cv2.circle(frame, (centroid[0], centroid[1]), 4, (0,255,0), -1)\n",
        "\n",
        "            info = [\n",
        "                  (\"Subiendo\", totalUp),\n",
        "                  (\"Bajando\", totalDown),\n",
        "                  (\"Estado\", status),\n",
        "            ]\n",
        "\n",
        "            for (i, (k,v)) in enumerate(info):\n",
        "                text = \"{}: {}\".format(k,v)\n",
        "                cv2.putText(frame, text, (10, H - ((i*20) + 20)), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0,0,255), 2)\n",
        "\n",
        "            writer.write(frame)\n",
        "\n",
        "            totalFrame += 1\n",
        "            fps.update()\n",
        "\n",
        "        fps.stop()\n",
        "\n",
        "        print(\"Tiempo completo {}\".format(fps.elapsed()))\n",
        "        print(\"Tiempo aproximado por frame {}\".format(fps.fps()))\n",
        "\n",
        "        writer.release()\n",
        "\n",
        "        vs.release()\n",
        "        \n",
        "        video = open(PATH_OUTPUT, \"rb\")\n",
        "        video_read = video.read()\n",
        "        image_64_encode = base64.b64encode(video_read)\n",
        "        image_64_encode_return = image_64_encode.decode() \n",
        "        return image_64_encode_return\n",
        "\n",
        "        "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9o0K6MRXiX7q"
      },
      "source": [
        "%%writefile deploy/requirements.txt\n",
        "tf_slim\n",
        "tf-models-official\n",
        "lvis\n",
        "Cython \n",
        "contextlib2 \n",
        "pillow \n",
        "lxml \n",
        "matplotlib\n",
        "pycocotools\n",
        "flask\n",
        "imutils\n",
        "numpy\n",
        "dlib\n",
        "opencv-contrib-python"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qg55BLulq-5q"
      },
      "source": [
        "%%writefile deploy/Dockerfile\n",
        "\n",
        "FROM python:3.7\n",
        "COPY . /app\n",
        "RUN apt-get update && yes | apt-get upgrade\n",
        "WORKDIR /app\n",
        "RUN mkdir -p /tensorflow/models\n",
        "RUN apt-get install -y git python3-pip\n",
        "RUN pip install --upgrade pip\n",
        "RUN pip install tensorflow\n",
        "RUN apt-get install -y protobuf-compiler python3-pil python3-lxml\n",
        "RUN pip install matplotlib\n",
        "RUN git clone https://github.com/tensorflow/models.git /tensorflow/models\n",
        "RUN apt-get update && apt-get install -y cmake\n",
        "RUN apt-get install ffmpeg libsm6 libxext6  -y\n",
        "\n",
        "WORKDIR /tensorflow/models/research\n",
        "RUN protoc object_detection/protos/*.proto --python_out=.\n",
        "RUN export PYTHONPATH=$PYTHONPATH:pwd:pwd/slim\n",
        "\n",
        "WORKDIR /app\n",
        "RUN pip install -r requirements.txt\n",
        "CMD [\"python3\", \"./app.py\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dLHumgtA1sA2"
      },
      "source": [
        "# Dockerizamos el proyecto\n",
        "docker build -t python-smartcity ."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vFYTJ8n-9W_T"
      },
      "source": [
        "# Validamos su funcionamiento.\n",
        "docker run python-smartcity"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dIa81EtI4tbA"
      },
      "source": [
        "gcloud auth login"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aV6tgdKR4t32"
      },
      "source": [
        "gcloud auth configure-docker"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "89JjHiLI4wU8"
      },
      "source": [
        "gcloud config set project windy-planet-330322"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rQ4939se42QV"
      },
      "source": [
        "# Open CLI\n",
        "# Open container registry\n",
        "gcloud builds submit --tag gcr.io/windy-planet-330322/python-smartcity --timeout=6000s"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LPPi6l-b5cYi"
      },
      "source": [
        "# Deploy in Cloud Run\n",
        "# Create services\n",
        "\n",
        "# Configure the server first version \n",
        "Container image.\n",
        "windy-planet-330322/python-smartcity --timeout=6000s\n",
        "# Finish and try."
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}