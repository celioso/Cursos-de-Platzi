{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "clase_entrenamiento_modelos_267d1fd3-7d57-4f28-a841-fe09654b0f45.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tvYO6VytCW4I"
      },
      "source": [
        "## Importamos librerías"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g07OmU69OIsJ",
        "outputId": "ac8c2c75-9a5f-4471-bbcb-fbf89c7c3a4d"
      },
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import json\n",
        "import pickle\n",
        "import zipfile\n",
        "import shutil\n",
        "\n",
        "# Instalamos los paquetes necesarios para que funcione desde la Colab\n",
        "!pip install avro-python3\n",
        "!pip install \n",
        "!pip install tf_slim==1.1.0\n",
        "!pip install tf-models-official==2.7.0\n",
        "!pip install lvis\n",
        "!pip install tensorflow_io==0.23.1\n",
        "!pip install keras==2.7.0\n",
        "!pip install opencv-python-headless==4.5.2.52\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting avro-python3\n",
            "  Downloading avro-python3-1.10.2.tar.gz (38 kB)\n",
            "Building wheels for collected packages: avro-python3\n",
            "  Building wheel for avro-python3 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for avro-python3: filename=avro_python3-1.10.2-py3-none-any.whl size=44010 sha256=5f4bba67164c96084d0cda39213cb3d6b0e591d1db8a0c6961ea1c826f6536c4\n",
            "  Stored in directory: /root/.cache/pip/wheels/d6/e5/b1/6b151d9b535ee50aaa6ab27d145a0104b6df02e5636f0376da\n",
            "Successfully built avro-python3\n",
            "Installing collected packages: avro-python3\n",
            "Successfully installed avro-python3-1.10.2\n",
            "\u001b[31mERROR: You must give at least one requirement to install (see \"pip help install\")\u001b[0m\n",
            "Collecting tf_slim==1.1.0\n",
            "  Downloading tf_slim-1.1.0-py2.py3-none-any.whl (352 kB)\n",
            "\u001b[K     |████████████████████████████████| 352 kB 5.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: absl-py>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from tf_slim==1.1.0) (1.0.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from absl-py>=0.2.2->tf_slim==1.1.0) (1.15.0)\n",
            "Installing collected packages: tf-slim\n",
            "Successfully installed tf-slim-1.1.0\n",
            "Collecting tf-models-official==2.7.0\n",
            "  Downloading tf_models_official-2.7.0-py2.py3-none-any.whl (1.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.8 MB 5.1 MB/s \n",
            "\u001b[?25hCollecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 63.0 MB/s \n",
            "\u001b[?25hCollecting tensorflow-model-optimization>=0.4.1\n",
            "  Downloading tensorflow_model_optimization-0.7.1-py2.py3-none-any.whl (234 kB)\n",
            "\u001b[K     |████████████████████████████████| 234 kB 72.9 MB/s \n",
            "\u001b[?25hCollecting tensorflow-addons\n",
            "  Downloading tensorflow_addons-0.15.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 56.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: Cython in /usr/local/lib/python3.7/dist-packages (from tf-models-official==2.7.0) (0.29.27)\n",
            "Collecting opencv-python-headless\n",
            "  Downloading opencv_python_headless-4.5.5.62-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (47.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 47.7 MB 1.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorflow-hub>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tf-models-official==2.7.0) (0.12.0)\n",
            "Requirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.7/dist-packages (from tf-models-official==2.7.0) (1.4.1)\n",
            "Requirement already satisfied: gin-config in /usr/local/lib/python3.7/dist-packages (from tf-models-official==2.7.0) (0.5.0)\n",
            "Requirement already satisfied: pycocotools in /usr/local/lib/python3.7/dist-packages (from tf-models-official==2.7.0) (2.0.4)\n",
            "Requirement already satisfied: google-api-python-client>=1.6.7 in /usr/local/lib/python3.7/dist-packages (from tf-models-official==2.7.0) (1.12.10)\n",
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 42.9 MB/s \n",
            "\u001b[?25hCollecting tensorflow-text>=2.7.0\n",
            "  Downloading tensorflow_text-2.8.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (4.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.9 MB 58.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: psutil>=5.4.3 in /usr/local/lib/python3.7/dist-packages (from tf-models-official==2.7.0) (5.4.8)\n",
            "Requirement already satisfied: tensorflow>=2.7.0 in /usr/local/lib/python3.7/dist-packages (from tf-models-official==2.7.0) (2.7.0)\n",
            "Requirement already satisfied: tf-slim>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tf-models-official==2.7.0) (1.1.0)\n",
            "Requirement already satisfied: oauth2client in /usr/local/lib/python3.7/dist-packages (from tf-models-official==2.7.0) (4.1.3)\n",
            "Collecting py-cpuinfo>=3.3.0\n",
            "  Downloading py-cpuinfo-8.0.0.tar.gz (99 kB)\n",
            "\u001b[K     |████████████████████████████████| 99 kB 9.6 MB/s \n",
            "\u001b[?25hCollecting sacrebleu\n",
            "  Downloading sacrebleu-2.0.0-py3-none-any.whl (90 kB)\n",
            "\u001b[K     |████████████████████████████████| 90 kB 12.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.7/dist-packages (from tf-models-official==2.7.0) (1.19.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from tf-models-official==2.7.0) (1.15.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from tf-models-official==2.7.0) (3.2.2)\n",
            "Requirement already satisfied: pandas>=0.22.0 in /usr/local/lib/python3.7/dist-packages (from tf-models-official==2.7.0) (1.3.5)\n",
            "Requirement already satisfied: tensorflow-datasets in /usr/local/lib/python3.7/dist-packages (from tf-models-official==2.7.0) (4.0.1)\n",
            "Collecting seqeval\n",
            "  Downloading seqeval-1.2.2.tar.gz (43 kB)\n",
            "\u001b[K     |████████████████████████████████| 43 kB 2.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from tf-models-official==2.7.0) (7.1.2)\n",
            "Requirement already satisfied: kaggle>=1.3.9 in /usr/local/lib/python3.7/dist-packages (from tf-models-official==2.7.0) (1.5.12)\n",
            "Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official==2.7.0) (3.0.1)\n",
            "Requirement already satisfied: httplib2<1dev,>=0.15.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official==2.7.0) (0.17.4)\n",
            "Requirement already satisfied: google-auth-httplib2>=0.0.3 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official==2.7.0) (0.0.4)\n",
            "Requirement already satisfied: google-api-core<3dev,>=1.21.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official==2.7.0) (1.26.3)\n",
            "Requirement already satisfied: google-auth<3dev,>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official==2.7.0) (1.35.0)\n",
            "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official==2.7.0) (2.23.0)\n",
            "Requirement already satisfied: protobuf>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official==2.7.0) (3.17.3)\n",
            "Requirement already satisfied: setuptools>=40.3.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official==2.7.0) (57.4.0)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official==2.7.0) (2018.9)\n",
            "Requirement already satisfied: packaging>=14.3 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official==2.7.0) (21.3)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official==2.7.0) (1.54.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3dev,>=1.16.0->google-api-python-client>=1.6.7->tf-models-official==2.7.0) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3dev,>=1.16.0->google-api-python-client>=1.6.7->tf-models-official==2.7.0) (4.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3dev,>=1.16.0->google-api-python-client>=1.6.7->tf-models-official==2.7.0) (4.2.4)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official==2.7.0) (2.8.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official==2.7.0) (4.62.3)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official==2.7.0) (1.24.3)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official==2.7.0) (2021.10.8)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official==2.7.0) (5.0.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=14.3->google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official==2.7.0) (3.0.7)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3dev,>=1.16.0->google-api-python-client>=1.6.7->tf-models-official==2.7.0) (0.4.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official==2.7.0) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official==2.7.0) (2.10)\n",
            "Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.7.0->tf-models-official==2.7.0) (1.0.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.7.0->tf-models-official==2.7.0) (1.1.0)\n",
            "Requirement already satisfied: keras<2.8,>=2.7.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.7.0->tf-models-official==2.7.0) (2.7.0)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.7.0->tf-models-official==2.7.0) (13.0.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.7.0->tf-models-official==2.7.0) (3.3.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.7.0->tf-models-official==2.7.0) (1.43.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.7.0->tf-models-official==2.7.0) (3.1.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.7.0->tf-models-official==2.7.0) (0.2.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.7.0->tf-models-official==2.7.0) (1.6.3)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.7.0->tf-models-official==2.7.0) (1.13.3)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.7.0->tf-models-official==2.7.0) (0.24.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.7.0->tf-models-official==2.7.0) (3.10.0.2)\n",
            "Requirement already satisfied: gast<0.5.0,>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.7.0->tf-models-official==2.7.0) (0.4.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.7.0->tf-models-official==2.7.0) (1.1.2)\n",
            "Requirement already satisfied: flatbuffers<3.0,>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.7.0->tf-models-official==2.7.0) (2.0)\n",
            "Requirement already satisfied: tensorboard~=2.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.7.0->tf-models-official==2.7.0) (2.7.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.32.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.7.0->tf-models-official==2.7.0) (0.37.1)\n",
            "Requirement already satisfied: tensorflow-estimator<2.8,~=2.7.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.7.0->tf-models-official==2.7.0) (2.7.0)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow>=2.7.0->tf-models-official==2.7.0) (1.5.2)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=2.7.0->tf-models-official==2.7.0) (3.3.6)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=2.7.0->tf-models-official==2.7.0) (0.6.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=2.7.0->tf-models-official==2.7.0) (1.8.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=2.7.0->tf-models-official==2.7.0) (0.4.6)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=2.7.0->tf-models-official==2.7.0) (1.0.1)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow>=2.7.0->tf-models-official==2.7.0) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.6->tensorflow>=2.7.0->tf-models-official==2.7.0) (4.10.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard~=2.6->tensorflow>=2.7.0->tf-models-official==2.7.0) (3.7.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow>=2.7.0->tf-models-official==2.7.0) (3.2.0)\n",
            "Requirement already satisfied: dm-tree~=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-model-optimization>=0.4.1->tf-models-official==2.7.0) (0.1.6)\n",
            "Collecting tensorflow>=2.7.0\n",
            "  Downloading tensorflow-2.8.0-cp37-cp37m-manylinux2010_x86_64.whl (497.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 497.5 MB 25 kB/s \n",
            "\u001b[?25hINFO: pip is looking at multiple versions of tensorflow-text to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting tensorflow-text>=2.7.0\n",
            "  Downloading tensorflow_text-2.7.3-cp37-cp37m-manylinux2010_x86_64.whl (4.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.9 MB 49.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->tf-models-official==2.7.0) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->tf-models-official==2.7.0) (1.3.2)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.7/dist-packages (from python-slugify->kaggle>=1.3.9->tf-models-official==2.7.0) (1.3)\n",
            "Collecting portalocker\n",
            "  Downloading portalocker-2.3.2-py2.py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.7/dist-packages (from sacrebleu->tf-models-official==2.7.0) (0.8.9)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from sacrebleu->tf-models-official==2.7.0) (2019.12.20)\n",
            "Collecting colorama\n",
            "  Downloading colorama-0.4.4-py2.py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.7/dist-packages (from seqeval->tf-models-official==2.7.0) (1.0.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official==2.7.0) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official==2.7.0) (1.1.0)\n",
            "Requirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow-addons->tf-models-official==2.7.0) (2.7.1)\n",
            "Requirement already satisfied: promise in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official==2.7.0) (2.3)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official==2.7.0) (0.16.0)\n",
            "Requirement already satisfied: attrs>=18.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official==2.7.0) (21.4.0)\n",
            "Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official==2.7.0) (1.6.0)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official==2.7.0) (5.4.0)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official==2.7.0) (0.3.4)\n",
            "Building wheels for collected packages: py-cpuinfo, seqeval\n",
            "  Building wheel for py-cpuinfo (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for py-cpuinfo: filename=py_cpuinfo-8.0.0-py3-none-any.whl size=22257 sha256=e750e824c1ef953be9d79cdae7985dca4e0ecc872bb37c253f28635e3e336917\n",
            "  Stored in directory: /root/.cache/pip/wheels/d2/f1/1f/041add21dc9c4220157f1bd2bd6afe1f1a49524c3396b94401\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16180 sha256=5e4ffe2782257fef1f3041509be3784036b067132e048667d0fd15d78d1dd2c6\n",
            "  Stored in directory: /root/.cache/pip/wheels/05/96/ee/7cac4e74f3b19e3158dce26a20a1c86b3533c43ec72a549fd7\n",
            "Successfully built py-cpuinfo seqeval\n",
            "Installing collected packages: portalocker, colorama, tensorflow-text, tensorflow-model-optimization, tensorflow-addons, seqeval, sentencepiece, sacrebleu, pyyaml, py-cpuinfo, opencv-python-headless, tf-models-official\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed colorama-0.4.4 opencv-python-headless-4.5.5.62 portalocker-2.3.2 py-cpuinfo-8.0.0 pyyaml-6.0 sacrebleu-2.0.0 sentencepiece-0.1.96 seqeval-1.2.2 tensorflow-addons-0.15.0 tensorflow-model-optimization-0.7.1 tensorflow-text-2.7.3 tf-models-official-2.7.0\n",
            "Collecting lvis\n",
            "  Downloading lvis-0.5.3-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: opencv-python>=4.1.0.25 in /usr/local/lib/python3.7/dist-packages (from lvis) (4.1.2.30)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from lvis) (1.15.0)\n",
            "Requirement already satisfied: kiwisolver>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from lvis) (1.3.2)\n",
            "Requirement already satisfied: matplotlib>=3.1.1 in /usr/local/lib/python3.7/dist-packages (from lvis) (3.2.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.0 in /usr/local/lib/python3.7/dist-packages (from lvis) (2.8.2)\n",
            "Requirement already satisfied: Cython>=0.29.12 in /usr/local/lib/python3.7/dist-packages (from lvis) (0.29.27)\n",
            "Requirement already satisfied: cycler>=0.10.0 in /usr/local/lib/python3.7/dist-packages (from lvis) (0.11.0)\n",
            "Requirement already satisfied: numpy>=1.18.2 in /usr/local/lib/python3.7/dist-packages (from lvis) (1.19.5)\n",
            "Requirement already satisfied: pyparsing>=2.4.0 in /usr/local/lib/python3.7/dist-packages (from lvis) (3.0.7)\n",
            "Installing collected packages: lvis\n",
            "Successfully installed lvis-0.5.3\n",
            "Collecting tensorflow_io==0.23.1\n",
            "  Downloading tensorflow_io-0.23.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (23.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 23.1 MB 640 kB/s \n",
            "\u001b[?25hCollecting tensorflow-io-gcs-filesystem==0.23.1\n",
            "  Downloading tensorflow_io_gcs_filesystem-0.23.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (2.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.1 MB 45.0 MB/s \n",
            "\u001b[?25hInstalling collected packages: tensorflow-io-gcs-filesystem, tensorflow-io\n",
            "  Attempting uninstall: tensorflow-io-gcs-filesystem\n",
            "    Found existing installation: tensorflow-io-gcs-filesystem 0.24.0\n",
            "    Uninstalling tensorflow-io-gcs-filesystem-0.24.0:\n",
            "      Successfully uninstalled tensorflow-io-gcs-filesystem-0.24.0\n",
            "Successfully installed tensorflow-io-0.23.1 tensorflow-io-gcs-filesystem-0.23.1\n",
            "Requirement already satisfied: keras==2.7.0 in /usr/local/lib/python3.7/dist-packages (2.7.0)\n",
            "Collecting opencv-python-headless==4.5.2.52\n",
            "  Downloading opencv_python_headless-4.5.2.52-cp37-cp37m-manylinux2014_x86_64.whl (38.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 38.2 MB 55 kB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from opencv-python-headless==4.5.2.52) (1.19.5)\n",
            "Installing collected packages: opencv-python-headless\n",
            "  Attempting uninstall: opencv-python-headless\n",
            "    Found existing installation: opencv-python-headless 4.5.5.62\n",
            "    Uninstalling opencv-python-headless-4.5.5.62:\n",
            "      Successfully uninstalled opencv-python-headless-4.5.5.62\n",
            "Successfully installed opencv-python-headless-4.5.2.52\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lf2DJHk5Ceh2"
      },
      "source": [
        "## Creamos nuestro archivo Label Map"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aN5e_Vc6OgS4"
      },
      "source": [
        "labels = [{'name':'carro', 'id': 1}, {'name': 'motos', 'id': 2}]\n",
        "with open(\"label_map.pbtxt\", \"w\") as f:\n",
        "  for label in labels:\n",
        "    f.write('item { \\n')\n",
        "    f.write('\\tname:\\'{}\\'\\n'.format(label['name']))\n",
        "    f.write('\\tid:{}\\n'.format(label['id']))\n",
        "    f.write('}\\n')"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QUenR7twCgmV"
      },
      "source": [
        "## Instalamos la librería de Object Detection en Google Colab"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KdqNMd5pPy1x",
        "outputId": "58c72a81-cae5-4674-bc7d-39ca010d571b"
      },
      "source": [
        "import os\n",
        "%cd /content\n",
        "!git clone --quiet https://github.com/tensorflow/models.git\n",
        "%cd /content/models/\n",
        "#!git checkout 58d19c67e1d30d905dd5c6e5092348658fed80af\n",
        "!apt-get update && apt-get install -y -qq protobuf-compiler python-pil python-lxml python-tk\n",
        "!pip install -q Cython contextlib2 pillow lxml matplotlib\n",
        "!pip install -q pycocotools\n",
        "%cd /content/models/research\n",
        "!protoc object_detection/protos/*.proto --python_out=.\n",
        "os.environ['PYTHONPATH'] += ':/content/models/research/:/content/models/research/slim/'\n",
        "!python object_detection/builders/model_builder_test.py"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "/content/models\n",
            "Ign:1 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "Get:2 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease [3,626 B]\n",
            "Ign:3 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Get:4 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease [15.9 kB]\n",
            "Get:5 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release [696 B]\n",
            "Hit:6 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Get:7 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release.gpg [836 B]\n",
            "Get:8 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n",
            "Hit:9 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n",
            "Hit:10 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Get:11 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
            "Get:13 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease [15.9 kB]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n",
            "Get:15 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Packages [917 kB]\n",
            "Get:16 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease [21.3 kB]\n",
            "Get:17 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main Sources [1,826 kB]\n",
            "Get:18 http://security.ubuntu.com/ubuntu bionic-security/main amd64 Packages [2,565 kB]\n",
            "Get:19 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [3,004 kB]\n",
            "Get:20 http://security.ubuntu.com/ubuntu bionic-security/restricted amd64 Packages [783 kB]\n",
            "Get:21 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main amd64 Packages [936 kB]\n",
            "Get:22 http://security.ubuntu.com/ubuntu bionic-security/universe amd64 Packages [1,470 kB]\n",
            "Get:23 http://archive.ubuntu.com/ubuntu bionic-updates/multiverse amd64 Packages [29.0 kB]\n",
            "Get:24 http://archive.ubuntu.com/ubuntu bionic-updates/restricted amd64 Packages [816 kB]\n",
            "Get:25 http://security.ubuntu.com/ubuntu bionic-security/multiverse amd64 Packages [21.1 kB]\n",
            "Get:26 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [2,248 kB]\n",
            "Get:27 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic/main amd64 Packages [45.3 kB]\n",
            "Get:28 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic/main amd64 Packages [42.8 kB]\n",
            "Fetched 15.0 MB in 3s (4,545 kB/s)\n",
            "Reading package lists... Done\n",
            "Selecting previously unselected package python-bs4.\n",
            "(Reading database ... 155113 files and directories currently installed.)\n",
            "Preparing to unpack .../0-python-bs4_4.6.0-1_all.deb ...\n",
            "Unpacking python-bs4 (4.6.0-1) ...\n",
            "Selecting previously unselected package python-pkg-resources.\n",
            "Preparing to unpack .../1-python-pkg-resources_39.0.1-2_all.deb ...\n",
            "Unpacking python-pkg-resources (39.0.1-2) ...\n",
            "Selecting previously unselected package python-chardet.\n",
            "Preparing to unpack .../2-python-chardet_3.0.4-1_all.deb ...\n",
            "Unpacking python-chardet (3.0.4-1) ...\n",
            "Selecting previously unselected package python-six.\n",
            "Preparing to unpack .../3-python-six_1.11.0-2_all.deb ...\n",
            "Unpacking python-six (1.11.0-2) ...\n",
            "Selecting previously unselected package python-webencodings.\n",
            "Preparing to unpack .../4-python-webencodings_0.5-2_all.deb ...\n",
            "Unpacking python-webencodings (0.5-2) ...\n",
            "Selecting previously unselected package python-html5lib.\n",
            "Preparing to unpack .../5-python-html5lib_0.999999999-1_all.deb ...\n",
            "Unpacking python-html5lib (0.999999999-1) ...\n",
            "Selecting previously unselected package python-lxml:amd64.\n",
            "Preparing to unpack .../6-python-lxml_4.2.1-1ubuntu0.6_amd64.deb ...\n",
            "Unpacking python-lxml:amd64 (4.2.1-1ubuntu0.6) ...\n",
            "Selecting previously unselected package python-olefile.\n",
            "Preparing to unpack .../7-python-olefile_0.45.1-1_all.deb ...\n",
            "Unpacking python-olefile (0.45.1-1) ...\n",
            "Selecting previously unselected package python-pil:amd64.\n",
            "Preparing to unpack .../8-python-pil_5.1.0-1ubuntu0.7_amd64.deb ...\n",
            "Unpacking python-pil:amd64 (5.1.0-1ubuntu0.7) ...\n",
            "Setting up python-pkg-resources (39.0.1-2) ...\n",
            "Setting up python-six (1.11.0-2) ...\n",
            "Setting up python-bs4 (4.6.0-1) ...\n",
            "Setting up python-lxml:amd64 (4.2.1-1ubuntu0.6) ...\n",
            "Setting up python-olefile (0.45.1-1) ...\n",
            "Setting up python-pil:amd64 (5.1.0-1ubuntu0.7) ...\n",
            "Setting up python-webencodings (0.5-2) ...\n",
            "Setting up python-chardet (3.0.4-1) ...\n",
            "Setting up python-html5lib (0.999999999-1) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "/content/models/research\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from object_detection.utils import config_util\n",
        "from object_detection.protos import pipeline_pb2\n",
        "from google.protobuf import text_format"
      ],
      "metadata": {
        "id": "9Ybwvo2Zd0xj"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bayx3MmFCk2M"
      },
      "source": [
        "## Clonamos el modelo SSD Mobilenet v2\n",
        "Si deseas puedes clonar cualquiera de los modelos pre entrenados"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ilsIQ97TP7sy",
        "outputId": "565faf2a-7d86-4ac9-94fe-894deef7fd3a"
      },
      "source": [
        "# Descargamos los modelos pre-enterenados en este caso SSD + MobileNetV2\n",
        "!wget --no-check-certificate http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz \\\n",
        "    -O /content/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-02-15 04:05:53--  http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz\n",
            "Resolving download.tensorflow.org (download.tensorflow.org)... 173.194.212.128, 2607:f8b0:400c:c11::80\n",
            "Connecting to download.tensorflow.org (download.tensorflow.org)|173.194.212.128|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 20515344 (20M) [application/x-tar]\n",
            "Saving to: ‘/content/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz’\n",
            "\n",
            "/content/ssd_mobile 100%[===================>]  19.56M  --.-KB/s    in 0.09s   \n",
            "\n",
            "2022-02-15 04:05:53 (216 MB/s) - ‘/content/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz’ saved [20515344/20515344]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "esovOBUBCt-W"
      },
      "source": [
        "#### Descromprimimos el modelo pre-entrenado"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QyGTZ8ARQ0Bb",
        "outputId": "250dda8d-ee2f-47d5-9154-2d24fb4ae457"
      },
      "source": [
        "!tar -zxvf /content/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz\n",
        "output_path = 'ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8'\n",
        "output_path = os.path.join(os.getcwd(), output_path)\n",
        "print(\"La carpeta se almaceno en {}\".format(output_path))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/\n",
            "ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/checkpoint/\n",
            "ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/checkpoint/ckpt-0.data-00000-of-00001\n",
            "ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/checkpoint/checkpoint\n",
            "ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/checkpoint/ckpt-0.index\n",
            "ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/pipeline.config\n",
            "ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/saved_model/\n",
            "ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/saved_model/saved_model.pb\n",
            "ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/saved_model/variables/\n",
            "ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/saved_model/variables/variables.data-00000-of-00001\n",
            "ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/saved_model/variables/variables.index\n",
            "La carpeta se almaceno en /content/models/research/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AlRXZft5CwkU"
      },
      "source": [
        "#### Definimos la ruta de nuestro modelo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TtRGY36SRSCL"
      },
      "source": [
        "path_training = '/content/ssd_mobilenet'\n",
        "os.mkdir(path_training)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s5PmKKxOC1BB"
      },
      "source": [
        "## Definimos la ruta del archivo original pipeline.config y en dónde vamos a almacenar nuestro pipeline.config"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "f_CPTM0cU7Xe",
        "outputId": "0804d6de-d228-4e15-d650-ce509d4fdbb6"
      },
      "source": [
        "source_config = \"{}/pipeline.config\".format(output_path)\n",
        "target_config = \"{}/pipeline.config\".format(path_training)\n",
        "shutil.copyfile(source_config, target_config)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/ssd_mobilenet/pipeline.config'"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oI8R_XSxC8BN"
      },
      "source": [
        "## Configuramos el archivo pipeline.config\n",
        "Inicialmente importamos librerías"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "X4afK6oNeg4T"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5C9feguSVLoL"
      },
      "source": [
        "import tensorflow as tf\n",
        "from object_detection.utils import config_util\n",
        "from object_detection.protos import pipeline_pb2\n",
        "from google.protobuf import text_format"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FX1LTNkAV0Qi"
      },
      "source": [
        "# Obtenemos la configuración del archivo pipeline\n",
        "config = config_util.get_configs_from_pipeline_file(target_config)\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wl9RQokZV8a2",
        "outputId": "b4233b62-f6d7-4e97-8a89-ab6209a2e455"
      },
      "source": [
        "# Visualizamos la configuración base\n",
        "config"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'eval_config': metrics_set: \"coco_detection_metrics\"\n",
              " use_moving_averages: false,\n",
              " 'eval_input_config': label_map_path: \"PATH_TO_BE_CONFIGURED\"\n",
              " shuffle: false\n",
              " num_epochs: 1\n",
              " tf_record_input_reader {\n",
              "   input_path: \"PATH_TO_BE_CONFIGURED\"\n",
              " },\n",
              " 'eval_input_configs': [label_map_path: \"PATH_TO_BE_CONFIGURED\"\n",
              " shuffle: false\n",
              " num_epochs: 1\n",
              " tf_record_input_reader {\n",
              "   input_path: \"PATH_TO_BE_CONFIGURED\"\n",
              " }\n",
              " ],\n",
              " 'model': ssd {\n",
              "   num_classes: 90\n",
              "   image_resizer {\n",
              "     fixed_shape_resizer {\n",
              "       height: 320\n",
              "       width: 320\n",
              "     }\n",
              "   }\n",
              "   feature_extractor {\n",
              "     type: \"ssd_mobilenet_v2_fpn_keras\"\n",
              "     depth_multiplier: 1.0\n",
              "     min_depth: 16\n",
              "     conv_hyperparams {\n",
              "       regularizer {\n",
              "         l2_regularizer {\n",
              "           weight: 3.9999998989515007e-05\n",
              "         }\n",
              "       }\n",
              "       initializer {\n",
              "         random_normal_initializer {\n",
              "           mean: 0.0\n",
              "           stddev: 0.009999999776482582\n",
              "         }\n",
              "       }\n",
              "       activation: RELU_6\n",
              "       batch_norm {\n",
              "         decay: 0.996999979019165\n",
              "         scale: true\n",
              "         epsilon: 0.0010000000474974513\n",
              "       }\n",
              "     }\n",
              "     use_depthwise: true\n",
              "     override_base_feature_extractor_hyperparams: true\n",
              "     fpn {\n",
              "       min_level: 3\n",
              "       max_level: 7\n",
              "       additional_layer_depth: 128\n",
              "     }\n",
              "   }\n",
              "   box_coder {\n",
              "     faster_rcnn_box_coder {\n",
              "       y_scale: 10.0\n",
              "       x_scale: 10.0\n",
              "       height_scale: 5.0\n",
              "       width_scale: 5.0\n",
              "     }\n",
              "   }\n",
              "   matcher {\n",
              "     argmax_matcher {\n",
              "       matched_threshold: 0.5\n",
              "       unmatched_threshold: 0.5\n",
              "       ignore_thresholds: false\n",
              "       negatives_lower_than_unmatched: true\n",
              "       force_match_for_each_row: true\n",
              "       use_matmul_gather: true\n",
              "     }\n",
              "   }\n",
              "   similarity_calculator {\n",
              "     iou_similarity {\n",
              "     }\n",
              "   }\n",
              "   box_predictor {\n",
              "     weight_shared_convolutional_box_predictor {\n",
              "       conv_hyperparams {\n",
              "         regularizer {\n",
              "           l2_regularizer {\n",
              "             weight: 3.9999998989515007e-05\n",
              "           }\n",
              "         }\n",
              "         initializer {\n",
              "           random_normal_initializer {\n",
              "             mean: 0.0\n",
              "             stddev: 0.009999999776482582\n",
              "           }\n",
              "         }\n",
              "         activation: RELU_6\n",
              "         batch_norm {\n",
              "           decay: 0.996999979019165\n",
              "           scale: true\n",
              "           epsilon: 0.0010000000474974513\n",
              "         }\n",
              "       }\n",
              "       depth: 128\n",
              "       num_layers_before_predictor: 4\n",
              "       kernel_size: 3\n",
              "       class_prediction_bias_init: -4.599999904632568\n",
              "       share_prediction_tower: true\n",
              "       use_depthwise: true\n",
              "     }\n",
              "   }\n",
              "   anchor_generator {\n",
              "     multiscale_anchor_generator {\n",
              "       min_level: 3\n",
              "       max_level: 7\n",
              "       anchor_scale: 4.0\n",
              "       aspect_ratios: 1.0\n",
              "       aspect_ratios: 2.0\n",
              "       aspect_ratios: 0.5\n",
              "       scales_per_octave: 2\n",
              "     }\n",
              "   }\n",
              "   post_processing {\n",
              "     batch_non_max_suppression {\n",
              "       score_threshold: 9.99999993922529e-09\n",
              "       iou_threshold: 0.6000000238418579\n",
              "       max_detections_per_class: 100\n",
              "       max_total_detections: 100\n",
              "       use_static_shapes: false\n",
              "     }\n",
              "     score_converter: SIGMOID\n",
              "   }\n",
              "   normalize_loss_by_num_matches: true\n",
              "   loss {\n",
              "     localization_loss {\n",
              "       weighted_smooth_l1 {\n",
              "       }\n",
              "     }\n",
              "     classification_loss {\n",
              "       weighted_sigmoid_focal {\n",
              "         gamma: 2.0\n",
              "         alpha: 0.25\n",
              "       }\n",
              "     }\n",
              "     classification_weight: 1.0\n",
              "     localization_weight: 1.0\n",
              "   }\n",
              "   encode_background_as_zeros: true\n",
              "   normalize_loc_loss_by_codesize: true\n",
              "   inplace_batchnorm_update: true\n",
              "   freeze_batchnorm: false\n",
              " },\n",
              " 'train_config': batch_size: 128\n",
              " data_augmentation_options {\n",
              "   random_horizontal_flip {\n",
              "   }\n",
              " }\n",
              " data_augmentation_options {\n",
              "   random_crop_image {\n",
              "     min_object_covered: 0.0\n",
              "     min_aspect_ratio: 0.75\n",
              "     max_aspect_ratio: 3.0\n",
              "     min_area: 0.75\n",
              "     max_area: 1.0\n",
              "     overlap_thresh: 0.0\n",
              "   }\n",
              " }\n",
              " sync_replicas: true\n",
              " optimizer {\n",
              "   momentum_optimizer {\n",
              "     learning_rate {\n",
              "       cosine_decay_learning_rate {\n",
              "         learning_rate_base: 0.07999999821186066\n",
              "         total_steps: 50000\n",
              "         warmup_learning_rate: 0.026666000485420227\n",
              "         warmup_steps: 1000\n",
              "       }\n",
              "     }\n",
              "     momentum_optimizer_value: 0.8999999761581421\n",
              "   }\n",
              "   use_moving_average: false\n",
              " }\n",
              " fine_tune_checkpoint: \"PATH_TO_BE_CONFIGURED\"\n",
              " num_steps: 50000\n",
              " startup_delay_steps: 0.0\n",
              " replicas_to_aggregate: 8\n",
              " max_number_of_boxes: 100\n",
              " unpad_groundtruth_tensors: false\n",
              " fine_tune_checkpoint_type: \"classification\"\n",
              " fine_tune_checkpoint_version: V2,\n",
              " 'train_input_config': label_map_path: \"PATH_TO_BE_CONFIGURED\"\n",
              " tf_record_input_reader {\n",
              "   input_path: \"PATH_TO_BE_CONFIGURED\"\n",
              " }}"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Keh1Y-uRXNBt"
      },
      "source": [
        "# Creamos una variable proto_str para poder modificar las variables del archivo pbtxt\n",
        "pipeline_config = pipeline_pb2.TrainEvalPipelineConfig()\n",
        "with tf.io.gfile.GFile(target_config, \"r\") as f:\n",
        "  proto_str = f.read()\n",
        "  text_format.Merge(proto_str, pipeline_config)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3qcQDGmjXiPq",
        "outputId": "1594724b-530d-42bc-b924-576bdb223e56"
      },
      "source": [
        "pipeline_config"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "model {\n",
              "  ssd {\n",
              "    num_classes: 90\n",
              "    image_resizer {\n",
              "      fixed_shape_resizer {\n",
              "        height: 320\n",
              "        width: 320\n",
              "      }\n",
              "    }\n",
              "    feature_extractor {\n",
              "      type: \"ssd_mobilenet_v2_fpn_keras\"\n",
              "      depth_multiplier: 1.0\n",
              "      min_depth: 16\n",
              "      conv_hyperparams {\n",
              "        regularizer {\n",
              "          l2_regularizer {\n",
              "            weight: 3.9999998989515007e-05\n",
              "          }\n",
              "        }\n",
              "        initializer {\n",
              "          random_normal_initializer {\n",
              "            mean: 0.0\n",
              "            stddev: 0.009999999776482582\n",
              "          }\n",
              "        }\n",
              "        activation: RELU_6\n",
              "        batch_norm {\n",
              "          decay: 0.996999979019165\n",
              "          scale: true\n",
              "          epsilon: 0.0010000000474974513\n",
              "        }\n",
              "      }\n",
              "      use_depthwise: true\n",
              "      override_base_feature_extractor_hyperparams: true\n",
              "      fpn {\n",
              "        min_level: 3\n",
              "        max_level: 7\n",
              "        additional_layer_depth: 128\n",
              "      }\n",
              "    }\n",
              "    box_coder {\n",
              "      faster_rcnn_box_coder {\n",
              "        y_scale: 10.0\n",
              "        x_scale: 10.0\n",
              "        height_scale: 5.0\n",
              "        width_scale: 5.0\n",
              "      }\n",
              "    }\n",
              "    matcher {\n",
              "      argmax_matcher {\n",
              "        matched_threshold: 0.5\n",
              "        unmatched_threshold: 0.5\n",
              "        ignore_thresholds: false\n",
              "        negatives_lower_than_unmatched: true\n",
              "        force_match_for_each_row: true\n",
              "        use_matmul_gather: true\n",
              "      }\n",
              "    }\n",
              "    similarity_calculator {\n",
              "      iou_similarity {\n",
              "      }\n",
              "    }\n",
              "    box_predictor {\n",
              "      weight_shared_convolutional_box_predictor {\n",
              "        conv_hyperparams {\n",
              "          regularizer {\n",
              "            l2_regularizer {\n",
              "              weight: 3.9999998989515007e-05\n",
              "            }\n",
              "          }\n",
              "          initializer {\n",
              "            random_normal_initializer {\n",
              "              mean: 0.0\n",
              "              stddev: 0.009999999776482582\n",
              "            }\n",
              "          }\n",
              "          activation: RELU_6\n",
              "          batch_norm {\n",
              "            decay: 0.996999979019165\n",
              "            scale: true\n",
              "            epsilon: 0.0010000000474974513\n",
              "          }\n",
              "        }\n",
              "        depth: 128\n",
              "        num_layers_before_predictor: 4\n",
              "        kernel_size: 3\n",
              "        class_prediction_bias_init: -4.599999904632568\n",
              "        share_prediction_tower: true\n",
              "        use_depthwise: true\n",
              "      }\n",
              "    }\n",
              "    anchor_generator {\n",
              "      multiscale_anchor_generator {\n",
              "        min_level: 3\n",
              "        max_level: 7\n",
              "        anchor_scale: 4.0\n",
              "        aspect_ratios: 1.0\n",
              "        aspect_ratios: 2.0\n",
              "        aspect_ratios: 0.5\n",
              "        scales_per_octave: 2\n",
              "      }\n",
              "    }\n",
              "    post_processing {\n",
              "      batch_non_max_suppression {\n",
              "        score_threshold: 9.99999993922529e-09\n",
              "        iou_threshold: 0.6000000238418579\n",
              "        max_detections_per_class: 100\n",
              "        max_total_detections: 100\n",
              "        use_static_shapes: false\n",
              "      }\n",
              "      score_converter: SIGMOID\n",
              "    }\n",
              "    normalize_loss_by_num_matches: true\n",
              "    loss {\n",
              "      localization_loss {\n",
              "        weighted_smooth_l1 {\n",
              "        }\n",
              "      }\n",
              "      classification_loss {\n",
              "        weighted_sigmoid_focal {\n",
              "          gamma: 2.0\n",
              "          alpha: 0.25\n",
              "        }\n",
              "      }\n",
              "      classification_weight: 1.0\n",
              "      localization_weight: 1.0\n",
              "    }\n",
              "    encode_background_as_zeros: true\n",
              "    normalize_loc_loss_by_codesize: true\n",
              "    inplace_batchnorm_update: true\n",
              "    freeze_batchnorm: false\n",
              "  }\n",
              "}\n",
              "train_config {\n",
              "  batch_size: 128\n",
              "  data_augmentation_options {\n",
              "    random_horizontal_flip {\n",
              "    }\n",
              "  }\n",
              "  data_augmentation_options {\n",
              "    random_crop_image {\n",
              "      min_object_covered: 0.0\n",
              "      min_aspect_ratio: 0.75\n",
              "      max_aspect_ratio: 3.0\n",
              "      min_area: 0.75\n",
              "      max_area: 1.0\n",
              "      overlap_thresh: 0.0\n",
              "    }\n",
              "  }\n",
              "  sync_replicas: true\n",
              "  optimizer {\n",
              "    momentum_optimizer {\n",
              "      learning_rate {\n",
              "        cosine_decay_learning_rate {\n",
              "          learning_rate_base: 0.07999999821186066\n",
              "          total_steps: 50000\n",
              "          warmup_learning_rate: 0.026666000485420227\n",
              "          warmup_steps: 1000\n",
              "        }\n",
              "      }\n",
              "      momentum_optimizer_value: 0.8999999761581421\n",
              "    }\n",
              "    use_moving_average: false\n",
              "  }\n",
              "  fine_tune_checkpoint: \"PATH_TO_BE_CONFIGURED\"\n",
              "  num_steps: 50000\n",
              "  startup_delay_steps: 0.0\n",
              "  replicas_to_aggregate: 8\n",
              "  max_number_of_boxes: 100\n",
              "  unpad_groundtruth_tensors: false\n",
              "  fine_tune_checkpoint_type: \"classification\"\n",
              "  fine_tune_checkpoint_version: V2\n",
              "}\n",
              "train_input_reader {\n",
              "  label_map_path: \"PATH_TO_BE_CONFIGURED\"\n",
              "  tf_record_input_reader {\n",
              "    input_path: \"PATH_TO_BE_CONFIGURED\"\n",
              "  }\n",
              "}\n",
              "eval_config {\n",
              "  metrics_set: \"coco_detection_metrics\"\n",
              "  use_moving_averages: false\n",
              "}\n",
              "eval_input_reader {\n",
              "  label_map_path: \"PATH_TO_BE_CONFIGURED\"\n",
              "  shuffle: false\n",
              "  num_epochs: 1\n",
              "  tf_record_input_reader {\n",
              "    input_path: \"PATH_TO_BE_CONFIGURED\"\n",
              "  }\n",
              "}"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mp04HtnNYe1f"
      },
      "source": [
        "# Definimos las rutas en donde se encuentra los TFRecords y el label map para agregarlos al archivo de configuración del pipeline.config\n",
        "label_map_pbtxt_fname = \"/content/label_map.pbtxt\"\n",
        "train_record_fname = \"/content/train.record\"\n",
        "test_record_fname = \"/content/test.record\""
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zWjTpZyAX26J"
      },
      "source": [
        "# Cantidad de clases del modelo\n",
        "pipeline_config.model.ssd.num_classes = 2\n",
        "\n",
        "# El tamaño del batch size, entre más grande mas costo computacional va a necesitar en el proceso de entrenamiento, pero a su vez entrenara más rapido.\n",
        "pipeline_config.train_config.batch_size = 4\n",
        "\n",
        "# Donde almacenaremos los resultados del entrenamiento\n",
        "pipeline_config.train_config.fine_tune_checkpoint =\"{}/checkpoint/ckpt-0\".format(output_path)\n",
        "\n",
        "# Qué tipo de deteción aplicaremos (Object detection)\n",
        "pipeline_config.train_config.fine_tune_checkpoint_type = \"detection\"\n",
        "\n",
        "# Dirección del label map\n",
        "pipeline_config.train_input_reader.label_map_path = label_map_pbtxt_fname\n",
        "\n",
        "# Dirección del train TFRecord\n",
        "pipeline_config.train_input_reader.tf_record_input_reader.input_path[0] = train_record_fname\n",
        "\n",
        "# Dirección del label map\n",
        "pipeline_config.eval_input_reader[0].label_map_path = label_map_pbtxt_fname\n",
        "\n",
        "# Dirección del test TFRecord\n",
        "pipeline_config.eval_input_reader[0].tf_record_input_reader.input_path[0] = test_record_fname"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xYnfRsQbcpA9",
        "outputId": "a9c422a9-713d-4c76-f5e5-b3b751401ece"
      },
      "source": [
        "# Visualizamos nuestro pipeline_config final.\n",
        "pipeline_config"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "model {\n",
              "  ssd {\n",
              "    num_classes: 2\n",
              "    image_resizer {\n",
              "      fixed_shape_resizer {\n",
              "        height: 320\n",
              "        width: 320\n",
              "      }\n",
              "    }\n",
              "    feature_extractor {\n",
              "      type: \"ssd_mobilenet_v2_fpn_keras\"\n",
              "      depth_multiplier: 1.0\n",
              "      min_depth: 16\n",
              "      conv_hyperparams {\n",
              "        regularizer {\n",
              "          l2_regularizer {\n",
              "            weight: 3.9999998989515007e-05\n",
              "          }\n",
              "        }\n",
              "        initializer {\n",
              "          random_normal_initializer {\n",
              "            mean: 0.0\n",
              "            stddev: 0.009999999776482582\n",
              "          }\n",
              "        }\n",
              "        activation: RELU_6\n",
              "        batch_norm {\n",
              "          decay: 0.996999979019165\n",
              "          scale: true\n",
              "          epsilon: 0.0010000000474974513\n",
              "        }\n",
              "      }\n",
              "      use_depthwise: true\n",
              "      override_base_feature_extractor_hyperparams: true\n",
              "      fpn {\n",
              "        min_level: 3\n",
              "        max_level: 7\n",
              "        additional_layer_depth: 128\n",
              "      }\n",
              "    }\n",
              "    box_coder {\n",
              "      faster_rcnn_box_coder {\n",
              "        y_scale: 10.0\n",
              "        x_scale: 10.0\n",
              "        height_scale: 5.0\n",
              "        width_scale: 5.0\n",
              "      }\n",
              "    }\n",
              "    matcher {\n",
              "      argmax_matcher {\n",
              "        matched_threshold: 0.5\n",
              "        unmatched_threshold: 0.5\n",
              "        ignore_thresholds: false\n",
              "        negatives_lower_than_unmatched: true\n",
              "        force_match_for_each_row: true\n",
              "        use_matmul_gather: true\n",
              "      }\n",
              "    }\n",
              "    similarity_calculator {\n",
              "      iou_similarity {\n",
              "      }\n",
              "    }\n",
              "    box_predictor {\n",
              "      weight_shared_convolutional_box_predictor {\n",
              "        conv_hyperparams {\n",
              "          regularizer {\n",
              "            l2_regularizer {\n",
              "              weight: 3.9999998989515007e-05\n",
              "            }\n",
              "          }\n",
              "          initializer {\n",
              "            random_normal_initializer {\n",
              "              mean: 0.0\n",
              "              stddev: 0.009999999776482582\n",
              "            }\n",
              "          }\n",
              "          activation: RELU_6\n",
              "          batch_norm {\n",
              "            decay: 0.996999979019165\n",
              "            scale: true\n",
              "            epsilon: 0.0010000000474974513\n",
              "          }\n",
              "        }\n",
              "        depth: 128\n",
              "        num_layers_before_predictor: 4\n",
              "        kernel_size: 3\n",
              "        class_prediction_bias_init: -4.599999904632568\n",
              "        share_prediction_tower: true\n",
              "        use_depthwise: true\n",
              "      }\n",
              "    }\n",
              "    anchor_generator {\n",
              "      multiscale_anchor_generator {\n",
              "        min_level: 3\n",
              "        max_level: 7\n",
              "        anchor_scale: 4.0\n",
              "        aspect_ratios: 1.0\n",
              "        aspect_ratios: 2.0\n",
              "        aspect_ratios: 0.5\n",
              "        scales_per_octave: 2\n",
              "      }\n",
              "    }\n",
              "    post_processing {\n",
              "      batch_non_max_suppression {\n",
              "        score_threshold: 9.99999993922529e-09\n",
              "        iou_threshold: 0.6000000238418579\n",
              "        max_detections_per_class: 100\n",
              "        max_total_detections: 100\n",
              "        use_static_shapes: false\n",
              "      }\n",
              "      score_converter: SIGMOID\n",
              "    }\n",
              "    normalize_loss_by_num_matches: true\n",
              "    loss {\n",
              "      localization_loss {\n",
              "        weighted_smooth_l1 {\n",
              "        }\n",
              "      }\n",
              "      classification_loss {\n",
              "        weighted_sigmoid_focal {\n",
              "          gamma: 2.0\n",
              "          alpha: 0.25\n",
              "        }\n",
              "      }\n",
              "      classification_weight: 1.0\n",
              "      localization_weight: 1.0\n",
              "    }\n",
              "    encode_background_as_zeros: true\n",
              "    normalize_loc_loss_by_codesize: true\n",
              "    inplace_batchnorm_update: true\n",
              "    freeze_batchnorm: false\n",
              "  }\n",
              "}\n",
              "train_config {\n",
              "  batch_size: 4\n",
              "  data_augmentation_options {\n",
              "    random_horizontal_flip {\n",
              "    }\n",
              "  }\n",
              "  data_augmentation_options {\n",
              "    random_crop_image {\n",
              "      min_object_covered: 0.0\n",
              "      min_aspect_ratio: 0.75\n",
              "      max_aspect_ratio: 3.0\n",
              "      min_area: 0.75\n",
              "      max_area: 1.0\n",
              "      overlap_thresh: 0.0\n",
              "    }\n",
              "  }\n",
              "  sync_replicas: true\n",
              "  optimizer {\n",
              "    momentum_optimizer {\n",
              "      learning_rate {\n",
              "        cosine_decay_learning_rate {\n",
              "          learning_rate_base: 0.07999999821186066\n",
              "          total_steps: 50000\n",
              "          warmup_learning_rate: 0.026666000485420227\n",
              "          warmup_steps: 1000\n",
              "        }\n",
              "      }\n",
              "      momentum_optimizer_value: 0.8999999761581421\n",
              "    }\n",
              "    use_moving_average: false\n",
              "  }\n",
              "  fine_tune_checkpoint: \"/content/models/research/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/checkpoint/ckpt-0\"\n",
              "  num_steps: 50000\n",
              "  startup_delay_steps: 0.0\n",
              "  replicas_to_aggregate: 8\n",
              "  max_number_of_boxes: 100\n",
              "  unpad_groundtruth_tensors: false\n",
              "  fine_tune_checkpoint_type: \"detection\"\n",
              "  fine_tune_checkpoint_version: V2\n",
              "}\n",
              "train_input_reader {\n",
              "  label_map_path: \"/content/label_map.pbtxt\"\n",
              "  tf_record_input_reader {\n",
              "    input_path: \"/content/train.record\"\n",
              "  }\n",
              "}\n",
              "eval_config {\n",
              "  metrics_set: \"coco_detection_metrics\"\n",
              "  use_moving_averages: false\n",
              "}\n",
              "eval_input_reader {\n",
              "  label_map_path: \"/content/label_map.pbtxt\"\n",
              "  shuffle: false\n",
              "  num_epochs: 1\n",
              "  tf_record_input_reader {\n",
              "    input_path: \"/content/test.record\"\n",
              "  }\n",
              "}"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DFTzmgaodE05"
      },
      "source": [
        "# Almacenamos nuestro archivo final\n",
        "config_text = text_format.MessageToString(pipeline_config)\n",
        "with tf.io.gfile.GFile(target_config, \"wb\") as f:\n",
        "  f.write(config_text)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T-lpTuX306Q7"
      },
      "source": [
        "## Entrenamiento de modelo de object detection"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Gljt3j11ijn3"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UBHrNgPDeUaw",
        "outputId": "8b3e708c-1d9d-49a5-8131-1806c14ad4bc"
      },
      "source": [
        "num_steps = 5000\n",
        "model_dir = \"/content/ssd_mobilenet\"\n",
        "\n",
        "# Utilizamos directamente la libreria de object detection para ejecutar el script model_main_tf2\n",
        "# Los argumentos principales son el archivo de configuración, la ubicación del modelo y la cantidad de steps que ejecutará.\n",
        "!python /content/models/research/object_detection/model_main_tf2.py \\\n",
        "--pipeline_config_path={target_config} \\\n",
        "--model_dir={model_dir} \\\n",
        "--num_train_steps={num_steps}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-02-15 04:06:02.654333: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n",
            "I0215 04:06:02.666415 140398825326464 mirrored_strategy.py:376] Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n",
            "INFO:tensorflow:Maybe overwriting train_steps: 5000\n",
            "I0215 04:06:02.673085 140398825326464 config_util.py:552] Maybe overwriting train_steps: 5000\n",
            "INFO:tensorflow:Maybe overwriting use_bfloat16: False\n",
            "I0215 04:06:02.673251 140398825326464 config_util.py:552] Maybe overwriting use_bfloat16: False\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/model_lib_v2.py:564: StrategyBase.experimental_distribute_datasets_from_function (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "rename to distribute_datasets_from_function\n",
            "W0215 04:06:02.729390 140398825326464 deprecation.py:347] From /content/models/research/object_detection/model_lib_v2.py:564: StrategyBase.experimental_distribute_datasets_from_function (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "rename to distribute_datasets_from_function\n",
            "INFO:tensorflow:Reading unweighted datasets: ['/content/train.record']\n",
            "I0215 04:06:02.740709 140398825326464 dataset_builder.py:163] Reading unweighted datasets: ['/content/train.record']\n",
            "INFO:tensorflow:Reading record datasets for input file: ['/content/train.record']\n",
            "I0215 04:06:02.740922 140398825326464 dataset_builder.py:80] Reading record datasets for input file: ['/content/train.record']\n",
            "INFO:tensorflow:Number of filenames to read: 1\n",
            "I0215 04:06:02.741012 140398825326464 dataset_builder.py:81] Number of filenames to read: 1\n",
            "WARNING:tensorflow:num_readers has been reduced to 1 to match input file shards.\n",
            "W0215 04:06:02.741096 140398825326464 dataset_builder.py:88] num_readers has been reduced to 1 to match input file shards.\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/builders/dataset_builder.py:105: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.deterministic`.\n",
            "W0215 04:06:02.747378 140398825326464 deprecation.py:347] From /content/models/research/object_detection/builders/dataset_builder.py:105: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.deterministic`.\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/builders/dataset_builder.py:237: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.map()\n",
            "W0215 04:06:02.778423 140398825326464 deprecation.py:347] From /content/models/research/object_detection/builders/dataset_builder.py:237: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.map()\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1096: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
            "W0215 04:06:09.777690 140398825326464 deprecation.py:347] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1096: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1096: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\n",
            "W0215 04:06:12.965243 140398825326464 deprecation.py:347] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1096: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py:465: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "W0215 04:06:14.531019 140398825326464 deprecation.py:347] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py:465: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "/usr/local/lib/python3.7/dist-packages/keras/backend.py:414: UserWarning: `tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n",
            "  warnings.warn('`tf.keras.backend.set_learning_phase` is deprecated and '\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0215 04:06:43.683515 140398825326464 cross_device_ops.py:621] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0215 04:06:43.684695 140398825326464 cross_device_ops.py:621] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0215 04:06:43.686757 140398825326464 cross_device_ops.py:621] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0215 04:06:43.687687 140398825326464 cross_device_ops.py:621] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0215 04:06:43.689624 140398825326464 cross_device_ops.py:621] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0215 04:06:43.690456 140398825326464 cross_device_ops.py:621] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0215 04:06:43.692375 140398825326464 cross_device_ops.py:621] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0215 04:06:43.693221 140398825326464 cross_device_ops.py:621] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0215 04:06:43.695138 140398825326464 cross_device_ops.py:621] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "I0215 04:06:43.695982 140398825326464 cross_device_ops.py:621] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/deprecation.py:620: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use fn_output_signature instead\n",
            "W0215 04:06:44.358268 140393552729856 deprecation.py:551] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/deprecation.py:620: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use fn_output_signature instead\n",
            "INFO:tensorflow:Step 100 per-step time 0.405s\n",
            "I0215 04:07:24.504864 140398825326464 model_lib_v2.py:707] Step 100 per-step time 0.405s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.31314582,\n",
            " 'Loss/localization_loss': 0.23969752,\n",
            " 'Loss/regularization_loss': 0.15449005,\n",
            " 'Loss/total_loss': 0.7073334,\n",
            " 'learning_rate': 0.0319994}\n",
            "I0215 04:07:24.505184 140398825326464 model_lib_v2.py:708] {'Loss/classification_loss': 0.31314582,\n",
            " 'Loss/localization_loss': 0.23969752,\n",
            " 'Loss/regularization_loss': 0.15449005,\n",
            " 'Loss/total_loss': 0.7073334,\n",
            " 'learning_rate': 0.0319994}\n",
            "INFO:tensorflow:Step 200 per-step time 0.101s\n",
            "I0215 04:07:34.636854 140398825326464 model_lib_v2.py:707] Step 200 per-step time 0.101s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.25189716,\n",
            " 'Loss/localization_loss': 0.3439089,\n",
            " 'Loss/regularization_loss': 0.15472591,\n",
            " 'Loss/total_loss': 0.750532,\n",
            " 'learning_rate': 0.0373328}\n",
            "I0215 04:07:34.637183 140398825326464 model_lib_v2.py:708] {'Loss/classification_loss': 0.25189716,\n",
            " 'Loss/localization_loss': 0.3439089,\n",
            " 'Loss/regularization_loss': 0.15472591,\n",
            " 'Loss/total_loss': 0.750532,\n",
            " 'learning_rate': 0.0373328}\n",
            "INFO:tensorflow:Step 300 per-step time 0.101s\n",
            "I0215 04:07:44.776649 140398825326464 model_lib_v2.py:707] Step 300 per-step time 0.101s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.1940477,\n",
            " 'Loss/localization_loss': 0.23164828,\n",
            " 'Loss/regularization_loss': 0.15481216,\n",
            " 'Loss/total_loss': 0.5805081,\n",
            " 'learning_rate': 0.0426662}\n",
            "I0215 04:07:44.776951 140398825326464 model_lib_v2.py:708] {'Loss/classification_loss': 0.1940477,\n",
            " 'Loss/localization_loss': 0.23164828,\n",
            " 'Loss/regularization_loss': 0.15481216,\n",
            " 'Loss/total_loss': 0.5805081,\n",
            " 'learning_rate': 0.0426662}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5kBnqsXMD8NB"
      },
      "source": [
        "## Análisis de los resultados con TensorBoard"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_A5zg8Usfi4r"
      },
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --logdir \"/content/ssd_mobilenet\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PvDuXyBiEBGo"
      },
      "source": [
        "## Exportación de modelo\n",
        "\n",
        "Exportamos nuestro modelo para poder utilizarlo en cualquier otro momento."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i_5qdZd3l-GM"
      },
      "source": [
        "\n",
        "output_directory = \"/content/fine_tuned_model\"\n",
        "\n",
        "!python /content/models/research/object_detection/exporter_main_v2.py \\\n",
        "--input_type image_tensor \\\n",
        "--pipeline_config_path {target_config} \\\n",
        "--trained_checkpoint_dir {model_dir} \\\n",
        "--output_directory {output_directory}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2JPWUBV0EFPk"
      },
      "source": [
        "## Compresión del modelo\n",
        "\n",
        "Comprimimos el modelo y lo descargamos para tenerlo local."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4CSkA62FmxJt"
      },
      "source": [
        "!zip -r /content/fine_tuned_model.zip /content/fine_tuned_model"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}