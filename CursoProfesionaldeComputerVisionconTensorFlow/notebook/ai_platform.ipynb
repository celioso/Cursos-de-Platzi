{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ILu-wViLcfBM"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.mjdir('deploy')\n",
        "os.mkdir('deploy/model')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!gsutil cp gs://curso-platzi-cv/fine_turned_model.zip deploy/model/fine_turned_model.zip\n",
        "!gsutil cp gs://curso-platzi-cv/label_map.pbtxt deploy/model/label_map.pbtxt"
      ],
      "metadata": {
        "id": "4Q98_KiTdsCn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!gsutil cp gs://curso-platzi-cv/dist/centroidtracker.py deploy/centroidtracker.py\n",
        "!gsutil cp gs://curso-platzi-cv/dist/trackableobject.py deploy/trackableobject.py"
      ],
      "metadata": {
        "id": "2eqnPxpde1gY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "local_zip = 'deploy/model/fine_turned_model.zip'\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall('deploy/model/fine_turned_model')\n",
        "zip_ref.close()"
      ],
      "metadata": {
        "id": "cI7WhZjVfvu9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile deploy/app.py\n",
        "\n",
        "from flask import Flask, requests\n",
        "from prediction import smartcities\n",
        "import base64\n",
        "\n",
        "app = Flask(__name__)\n",
        "\n",
        "@app.route('/', methods = ['POST'])\n",
        "def parse_request():\n",
        "    request_data = requests.get_json()\n",
        "    videoBase64 = request_data['video']\n",
        "    sc = smartcities()\n",
        "    response_64 = sc.predict(videoBase64)\n",
        "    return jsonify(response_64)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    app.run(debug=True, host = '0.0.0.0', port = 8000)"
      ],
      "metadata": {
        "id": "eVOHvKKPgn-B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile deploy/prediction.py\n",
        "\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "import imutils\n",
        "import time\n",
        "import dlib\n",
        "import cv2\n",
        "import base64\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "from imutils.video import VideoStream\n",
        "from imutils.video import FPS\n",
        "from centroidtracker import CentroidTracker\n",
        "from trackableobject import TrackableObject\n",
        "\n",
        "class smartcities:\n",
        "  def __init__(self):\n",
        "    detect_fn = tf.saved_model.load(\"model/fine_tuned_model/saved_model\")\n",
        "    self.detect_fn = detect_fn\n",
        "\n",
        "  def predict(self, image_64_decode):\n",
        "\n",
        "    PATH_VIDEO = \"/tmp/video_in.mp4\"\n",
        "    video_result = open(PATH_VIDEO, \"wb\")\n",
        "    video_result.write(base64.b64decode(image_64_decode))\n",
        "    #video_result.close()\n",
        "\n",
        "    PATH_OUTPUT = \"/tmp/output.mp4\"\n",
        "\n",
        "    SKIP_FPS = 30\n",
        "\n",
        "    TRESHOLD = 0.5\n",
        "\n",
        "    vs = cv2.VideoCapture(PATH_VIDEO)\n",
        "\n",
        "    writer = None\n",
        "\n",
        "    W = int(vs.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "    H = int(vs.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "\n",
        "    ct = CentroidTracker(maxDisappeared= 40, maxDistance = 50)\n",
        "\n",
        "    trackers = []\n",
        "    trackableObjects = {}\n",
        "\n",
        "    totalFrame = 0\n",
        "    totalDown = 0\n",
        "    totalUp = 0\n",
        "\n",
        "    DIRECTION_PEOPLE = True\n",
        "\n",
        "    POINT = [0, int((H/2)-H*0.1), W, int(H*0.1)]\n",
        "\n",
        "    fps = FPS().start()\n",
        "\n",
        "    fourcc = cv2.VideoWriter_fourcc(*'MP4V')\n",
        "    writer = cv2.VideoWriter(PATH_OUTPUT, fourcc, 20.0, (W, H), True)\n",
        "\n",
        "    while True:\n",
        "      ret, frame = vs.read()\n",
        "\n",
        "      if frame is None:\n",
        "        break\n",
        "\n",
        "      status = \"Waiting\"\n",
        "      rects = []\n",
        "\n",
        "      if totalFrame % SKIP_FPS == 0:\n",
        "        status = \"Detecting\"\n",
        "        trackers = []\n",
        "\n",
        "        image_np = np.array(frame)\n",
        "\n",
        "        input_tensor = tf.convert_to_tensor(image_np)\n",
        "        input_tensor = input_tensor[tf.newaxis, ...]\n",
        "\n",
        "        detections = self.detect_fn(input_tensor)\n",
        "\n",
        "        detection_scores = np.array(detections[\"detection_scores\"][0])\n",
        "\n",
        "        detection_clean = [x for x in detection_scores if x >= TRESHOLD]\n",
        "\n",
        "        for x in range(len(detection_clean)):\n",
        "          idx = int(detections['detection_classes'][0][x])\n",
        "\n",
        "          ymin, xmin, ymax, xmax = np.array(detections['detection_boxes'][0][x])\n",
        "          box = [xmin, ymin, xmax, ymax] * np.array([W,H, W, H])\n",
        "\n",
        "          (startX, startY, endX, endY) = box.astype(\"int\")\n",
        "\n",
        "          tracker = dlib.correlation_tracker()\n",
        "          rect = dlib.rectangle(startX, startY, endX, endY)\n",
        "          tracker.start_track(frame, rect)\n",
        "\n",
        "          trackers.append(tracker)\n",
        "      else:\n",
        "\n",
        "        for tracker in trackers:\n",
        "          status = \"Tracking\"\n",
        "\n",
        "          tracker.update(frame)\n",
        "          pos = tracker.get_position()\n",
        "\n",
        "          startX = int(pos.left())\n",
        "          startY = int(pos.top())\n",
        "          endX = int(pos.right())\n",
        "          endY = int(pos.bottom())\n",
        "\n",
        "          rects.append((startX, startY, endX, endY))\n",
        "\n",
        "\n",
        "      cv2.rectangle(frame, (POINT[0], POINT[1]), (POINT[0]+ POINT[2], POINT[1] + POINT[3]), (255, 0, 255), 2)\n",
        "\n",
        "      objects = ct.update(rects)\n",
        "\n",
        "      for (objectID, centroid) in objects.items():\n",
        "\n",
        "        to = trackableObjects.get(objectID, None)\n",
        "        if to is None:\n",
        "          to = TrackableObject(objectID, centroid)\n",
        "\n",
        "        else:\n",
        "          y = [c[1] for c in to.centroids]\n",
        "          direction = centroid[1] - np.mean(y)\n",
        "          to.centroids.append(centroid)\n",
        "          if not to.counted:\n",
        "            if centroid[0] > POINT[0] and centroid[0] < (POINT[0]+ POINT[2]) and centroid[1] > POINT[1] and centroid[1] < (POINT[1]+POINT[3]):\n",
        "              if DIRECTION_PEOPLE:\n",
        "                if direction >0:\n",
        "                  totalUp += 1\n",
        "                  to.counted = True\n",
        "                else:\n",
        "                  totalDown +=1\n",
        "                  to.counted = True\n",
        "              else:\n",
        "                if direction <0:\n",
        "                  totalUp += 1\n",
        "                  to.counted = True\n",
        "                else:\n",
        "                  totalDown +=1\n",
        "                  to.counted = True\n",
        "\n",
        "        trackableObjects[objectID] = to\n",
        "\n",
        "        text = \"ID {}\".format(objectID)\n",
        "        cv2.putText(frame, text, (centroid[0]-10, centroid[1]-10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0,255,0), 2)\n",
        "        cv2.circle(frame, (centroid[0], centroid[1]), 4, (0,255,0), -1)\n",
        "\n",
        "      info = [\n",
        "              (\"Subiendo\", totalUp),\n",
        "              (\"Bajando\", totalDown),\n",
        "              (\"Estado\", status),\n",
        "        ]\n",
        "\n",
        "        for (i, (k,v)) in enumerate(info):\n",
        "          text = \"{}: {}\".format(k,v)\n",
        "          cv2.putText(frame, text, (10, H - ((i*20) + 20)), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0,0,255), 2)\n",
        "\n",
        "        writer.write(frame)\n",
        "        totalFrame += 1\n",
        "        fps.update()\n",
        "\n",
        "\n",
        "    fps.stop()\n",
        "\n",
        "    print(\"Tiempo completo {}\".format(fps.elapsed()))\n",
        "    print(\"Tiempo aproximado por frame {}\".format(fps.fps()))\n",
        "\n",
        "\n",
        "    writer.release()\n",
        "    vs.release()\n",
        "\n",
        "    video = open(PATH_OUTPUT, \"rb\")\n",
        "    video_read = video.read()\n",
        "    image_64_encode = base64.b64encode(video_read)\n",
        "    image_64_encode_return = {1:image_64_encode}\n",
        "    return image_64_encode_return\n"
      ],
      "metadata": {
        "id": "315Y_9kymfz3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile deploy/requirements.txt\n",
        "tf_slim\n",
        "tf-models-official\n",
        "lvis\n",
        "Cython\n",
        "contextlib2\n",
        "pillow\n",
        "lxml\n",
        "matplotlib\n",
        "pycocotools\n",
        "flask\n",
        "imutils\n",
        "numpy\n",
        "dlib\n",
        "opencv-contrib-python"
      ],
      "metadata": {
        "id": "1_VsI15evF6x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile deploy/Dockerfile\n",
        "\n",
        "FROM python:3.7\n",
        "COPY . /app\n",
        "RUN apt-get update && yes | apt-get upgrade\n",
        "WORKDIR /app\n",
        "RUN mkdir -p /tensorflow/models\n",
        "RUN apt-get install -y git python3-pip\n",
        "RUN pip install --upgrade pip\n",
        "RUN pip install tensorflow\n",
        "RUN apt-get install -y protobuf-compiler python3-pil python3-lxml\n",
        "RUN pip install matplotlib\n",
        "RUN git clone https://github.com/tensorflow/models.git /tensorflow/models\n",
        "RUN apt-get update && apt-get install -y cmake\n",
        "RUN apt-get install ffmpeg libsm6 libxext6  -y\n",
        "\n",
        "WORKDIR /tensorflow/models/research\n",
        "RUN protoc object_detection/protos/*.proto --python_out=.\n",
        "RUN export PYTHONPATH=$PYTHONPATH:pwd:pwd/slim\n",
        "\n",
        "WORKDIR /app\n",
        "RUN pip install -r requirements.txt\n",
        "CMD [\"python3\", \"./app.py\"]"
      ],
      "metadata": {
        "id": "6HuHblRTysXl"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}