# Curso de Regresi√≥n Lineal con Python y scikit-learn

## Tu primera regresi√≥n lineal con scikit-learn

Vamos a hacer **tu primera regresi√≥n lineal** usando `scikit-learn`, una de las bibliotecas m√°s populares de Python para machine learning.

### üìà ¬øQu√© es una regresi√≥n lineal?

Es un modelo matem√°tico que **relaciona una variable independiente (X)** con **una variable dependiente (y)** a trav√©s de una **recta**:

$$
y = mX + b
$$

Donde:

* `m` es la **pendiente**
* `b` es la **intersecci√≥n** o t√©rmino independiente

### ‚úÖ Ejemplo paso a paso con c√≥digo

### 1. Importar bibliotecas necesarias

```python
import numpy as np
import matplotlib.pyplot as plt
from sklearn.linear_model import LinearRegression
```

### 2. Crear datos de ejemplo

```python
# Datos artificiales
X = np.array([[1], [2], [3], [4], [5]])  # variable independiente
y = np.array([2, 4, 5, 4, 5])           # variable dependiente
```

### 3. Crear y entrenar el modelo

```python
modelo = LinearRegression()
modelo.fit(X, y)
```

### 4. Ver los coeficientes del modelo

```python
print("Pendiente (coef_):", modelo.coef_)
print("Intersecci√≥n (intercept_):", modelo.intercept_)
```

### 5. Hacer predicciones

```python
X_nuevos = np.array([[6], [7]])
predicciones = modelo.predict(X_nuevos)
print("Predicciones:", predicciones)
```

### 6. Visualizar la regresi√≥n

```python
plt.scatter(X, y, color='blue', label='Datos reales')
plt.plot(X, modelo.predict(X), color='red', label='L√≠nea de regresi√≥n')
plt.xlabel("X")
plt.ylabel("y")
plt.legend()
plt.title("Regresi√≥n Lineal con scikit-learn")
plt.grid(True)
plt.show()
```

### üéì ¬øQu√© aprendiste?

Con esto lograste:

* Crear un modelo de regresi√≥n lineal
* Ajustarlo con datos reales
* Predecir nuevos valores
* Visualizar la l√≠nea de mejor ajuste

**Archivos de la clase**

[2-slides-1.pdf](https://static.platzi.com/media/public/uploads/2-slides-1_86e64012-0cea-4015-8896-adb2f9d8c966.pdf)
[primera-regresion-lineal.ipynb](https://static.platzi.com/media/public/uploads/primera_regresion_lineal_755953b4-3c16-42de-a9e3-78fe9742244f.ipynb)
[primera-regresion-lineal-template.ipynb](https://static.platzi.com/media/public/uploads/primera_regresion_lineal_template_42c71d99-6fdb-4af7-98f2-e3f8e2e76b7a.ipynb)
[housing.data](https://static.platzi.com/media/public/uploads/housing_edf82b23-51e2-4f57-887d-6be67da34d27.data)

## An√°lisis de datos para tu primera regresi√≥n lineal

vamos a realizar un **an√°lisis de datos** para nuestra primera **regresi√≥n lineal** utilizando el famoso dataset de **Housing de Boston** (aunque oficialmente retirado de `sklearn` por temas √©ticos, a√∫n puede usarse con cuidado desde UCI).

Este dataset contiene 506 filas y 14 columnas. La variable objetivo (`target`) es el precio medio de las viviendas en miles de d√≥lares.

### üîπ Paso 1: Cargar los datos

```python
import pandas as pd

# Cargar el dataset desde UCI
url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/housing/housing.data'
columnas = [
    'CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE',
    'DIS', 'RAD', 'TAX', 'PTRATIO', 'B', 'LSTAT', 'MEDV'
]
data = pd.read_csv(url, header=None, sep=r'\s+', names=columnas)
```

### üîπ Paso 2: Inspeccionar el dataset

```python
# Ver primeras filas
print(data.head())

# Resumen estad√≠stico
print(data.describe())

# Ver si hay valores nulos
print(data.isnull().sum())
```

### üîπ Paso 3: Visualizaci√≥n de correlaciones

Podemos usar `seaborn` para ver c√≥mo se relacionan las variables con la variable objetivo `MEDV`.

```python
import seaborn as sns
import matplotlib.pyplot as plt

# Mapa de calor de correlaciones
plt.figure(figsize=(12, 10))
sns.heatmap(data.corr(), annot=True, fmt=".2f", cmap="coolwarm")
plt.title("Matriz de Correlaci√≥n")
plt.show()
```

### üîπ Paso 4: Selecci√≥n de una variable para regresi√≥n simple

Vamos a elegir la variable m√°s correlacionada con `MEDV`. Por lo general, `LSTAT` (porcentaje de poblaci√≥n con bajos ingresos) tiene una fuerte correlaci√≥n negativa con el precio.

```python
sns.scatterplot(x='LSTAT', y='MEDV', data=data)
plt.title("Relaci√≥n entre LSTAT y MEDV")
plt.xlabel("LSTAT (% poblaci√≥n de bajos ingresos)")
plt.ylabel("Precio medio (MEDV)")
plt.show()
```

### ¬øQu√© sigue?

Con esta base ya podemos:

1. Dividir el dataset en entrenamiento y prueba.
2. Crear un modelo de regresi√≥n lineal con `scikit-learn`.
3. Entrenar el modelo.
4. Hacer predicciones y evaluar el desempe√±o.

## Entrenando un modelo de regresi√≥n lineal con scikit-learn

Entrenar un modelo de regresi√≥n lineal con **Scikit-learn** es sencillo. A continuaci√≥n te muestro un ejemplo completo, paso a paso, con explicaciones:

### ‚úÖ 1. Importar las librer√≠as necesarias

```python
import numpy as np
import pandas as pd
from sklearn.linear_model import LinearRegression
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score
```

### ‚úÖ 2. Crear o cargar los datos

Aqu√≠ vamos a crear datos sint√©ticos como ejemplo:

```python
# Datos de ejemplo (relaci√≥n lineal con algo de ruido)
np.random.seed(0)
X = 2 * np.random.rand(100, 1)
y = 4 + 3 * X + np.random.randn(100, 1)
```

### ‚úÖ 3. Dividir en entrenamiento y prueba

```python
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
```

### ‚úÖ 4. Entrenar el modelo

```python
model = LinearRegression()
model.fit(X_train, y_train)
```

### ‚úÖ 5. Ver los coeficientes del modelo

```python
print(f"Intercepto: {model.intercept_}")
print(f"Coeficientes: {model.coef_}")
```

### ‚úÖ 6. Realizar predicciones

```python
y_pred = model.predict(X_test)
```

### ‚úÖ 7. Evaluar el modelo

```python
print(f"Error cuadr√°tico medio (MSE): {mean_squared_error(y_test, y_pred):.2f}")
print(f"Coeficiente de determinaci√≥n (R¬≤): {r2_score(y_test, y_pred):.2f}")
```

### ‚úÖ 8. (Opcional) Visualizar resultados

```python
import matplotlib.pyplot as plt

plt.scatter(X_test, y_test, color='blue', label='Datos reales')
plt.plot(X_test, y_pred, color='red', linewidth=2, label='Regresi√≥n lineal')
plt.xlabel('X')
plt.ylabel('y')
plt.legend()
plt.title('Modelo de Regresi√≥n Lineal')
plt.show()
```

**Lecturas recomendadas**

[scikit-learn: machine learning in Python ‚Äî scikit-learn 1.0.2 documentation](https://scikit-learn.org/stable/)

[sklearn.linear_model.LinearRegression ‚Äî scikit-learn 1.0.2 documentation](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html)

[sklearn.preprocessing.StandardScaler ‚Äî scikit-learn 1.0.2 documentation](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html)

[Primera_regresi√≥n_lineal.ipynb - Google Drive](https://drive.google.com/file/d/1wh1T5AE1AgmgDcTaiziaeKYSuovVFQPk/view?usp=sharing)

[Primera_regresi√≥n_lineal_Template.ipynb - Google Drive](https://drive.google.com/file/d/1NkcOQg-BTEAD0ttGDcZcAZwYpD0jXPJd/view?usp=sharing)